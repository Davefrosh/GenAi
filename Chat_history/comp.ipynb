{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001FBD1CA17E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001FBD1CA2410>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key=os.getenv(\"GROQ_API\")\n",
    "llm=ChatGroq(groq_api_key=api_key,model=\"llama-3.3-70b-versatile\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage,HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STUFF_DOCUMENT_CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('Comparative_Analysis_of_Machine_Learning.pdf')\n",
    "f = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\new user\\anaconda3\\envs\\genv\\lib\\site-packages (from pypdf) (4.12.2)\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Comparative Analysis of Machine Learning Algorithms in Predicting Rate of \\nPenetration during Drilling\\nOlaosebikan Abidoye Olafadehan*, Ikenna David Ahaotu\\nDepartment of Chemical and Petroleum Engineering, University of Lagos, Akoka-Y aba, Lagos 101017, Nigeria\\nCitation: Olafadehan OA, Ahaotu  ID, Comparative Analysis of Machine Learning Algorithms in Predicting Rate of Penetration \\nduring Drilling. J Petro Chem Eng 2023;1(1): 32-47.\\nReceived: 14 October, 2023; Accepted: 31 October, 2023; Published: 07 November, 2023\\n*Corresponding author: Olafadehan OA, Department of Chemical and Petroleum Engineering, University of Lagos, Akoka-\\nY aba, Lagos 101017 Nigeria, Phone: +234802-912-9559, Email: oolafadehan@unilag.edu.ng\\nCopyright: © 2023 Olafadehan OA., et al., This is an open-access article published in J Petro Chem Eng (JPCE) and distributed \\nunder the terms of the Creative Commons Attribution License, which permits unrestricted use, dist ribution, and reproduction \\nin any medium, provided the original author and source are credited.\\n1\\n A B S T R A C T \\nDrilling for potential oil and gas reserves is one of the foremost practices in the petroleum industry. The dr illing process, \\nhowever, is quite expensive and can take quite some time to accomplish.  Hence, there has been a rise in the n eed to reduce \\ncost and time by optimizing the rate of penetration during drilling, which has led to the development of mathemat ical models \\nto describe and evaluate this process.  However, the accuracy of these models has varied owing to variat ion of the drilling \\nparameters accounted for in each model. This event has led to the usage of alternative approaches such as Data driven models.  In \\nthis study, the predictive capacities of the rate of penetration (ROP) during drilling using machine learning (ML) algorithms of \\nsupport vector machine regression (SVR), Random Forest regression (RF), Linear regression (LR), KNearest neighbors (KNN), \\nStacking technique, Voting technique and Convolution neural network (CNN), were compared.  Data from an oil well in Nigeria \\nwas used in this investigation. The data for the well was split into train–test sets in the ratio of 60:40.  The train data was used to \\ntrain and select the best model before making predictions on the test sets.  The Stacking technique was found t o have the best \\nperformance across both training and test data sets with respective accuracies of 99.8% and 97.5% in terms of the  –score. The \\nVoting technique also performed well, with respective accuracies of 93.6% and 92.6% in terms of the  –score across both sets of \\ndata. The CNN model equally performed well on the training and test data sets, with respective accuracies of 92.4% a nd 92.8% \\nin terms of the  –Score.  Generally, the machine learning models were able to detect patterns and gain valuable insights into the \\ndata. They can be employed for real time prediction of the rate of penetration during oil well drilling.\\nKeywords: Rate of penetration; Drilling; Artificial intelligence; Machine learning algorithms; train–test data.\\nAbbreviations\\nAI  Artificial Intelligence\\nANN            Artificial Neural Network\\nCNN            Convolutional Neural Network\\nDDR             Daily Drilling Report\\nKNN              KNearest Neighbors\\nMAE             Mean Absolute Error\\nML                  Machine Learning\\nR2                    Coefficient of determination\\nRMSE             Root mean squared Error.\\nROP                 Rate of penetration. \\nRPM            Rotary speed,\\nSVR                Support Vector Regressor\\nWOB              Weight on bit, kblf\\nResearch Article\\nVol: 1 & Iss: 1\\nhttps://urfpublishers.com/journal/petrochemical-engineering\\nJournal of Petroleum & Chemical Engineering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n2\\n1. Introduction\\nDrilling is a key aspect of the petroleum industry. It is the \\nprocess of boring a hole deep into the subsurface section of the \\nearth in order to reach formations with hydrocarbon reserves, \\nfor the aim of hydrocarbon recovery. The importance of this \\nprocess cannot be understated and as a result, a lot of different \\ndrilling technologies were implemented to maximize drilling \\noperations. The popular drilling method used today known \\nas the rotary drilling, which is applied in drilling the majority \\nof onshore and offshore wells and makes use of an applied \\naxial force on the rotating drill bit to achieve penetration. It is \\nimpossible to overstate the significance of this procedure, which \\nis why numerous drilling methods have been used to maximize \\ndrilling operations. The bulk of onshore and offshore wells are \\ndrilled using the widely used technique known as the rotary \\ndrilling, which applies an axial force to the revolving drill bit \\nto accomplish penetration. In a rotary drilling process, key \\nparameters need to be considered to ensure optimal operations, \\nand a key parameter among these is the rate of penetration, ROP. \\nIt is the depth of penetration accomplished per unit time, and is \\nusually measured as a factor of how many feet the bit can drill in \\nan hour (i.e., ft/h). However, evaluation of ROP is difficult due \\nto the complex relationship between other drilling parameters \\naffecting the ROP. The rate of penetration (ROP) prediction is \\na key task in drilling economical assessments\\n1. Not always is \\nthe lowest cost per foot provided by the fastest drilling pace. A \\nrise in the project’s overall cost may be caused by other factors. \\nThe characteristics of drilling fluid (such as mud viscosity, mud \\ndensity, filtration loss), mechanical characteristics (such as bit \\ntype and weight), and formation properties (such as porosity, rock \\nabrasivity, formation elasticity, formation stress, permeability) \\nare a few examples of the properties that affect penetration rate\\n2. \\nHence, it is important to maximize the rate of penetration in order \\nto mitigate some of the general cost associated with drilling for \\nextended periods. Therefore, it is necessary to understand the \\nrelationship between the ROP and other operational parameters.\\nMathematical models have been used to model the \\nrelationship between some operational parameters and ROP \\ne.g., Bourgoyne and Young\\n3 model and the Bingham 4. The \\naccuracy of these models has varied due to variation in the \\ndrilling parameters considered in each model. This has led to \\nthe usage of alternative approaches such as a data driven model \\ne.g., artificial intelligence (AI). Artificial intelligence methods \\nhave developed rapidly over the past decades and has led to it \\nbeen implemented in various sectors, including the oil and gas \\nindustry. Colossal amount of data is been generated on the oil \\nfield during operating hours. These data include drilling data, \\nproduction data, seismic data and mud log data, amongst others. \\nThese data sets can be trained using artificial intelligence \\nmethods to make future predictions and generate hidden insights \\ninto the data. The AI methods have been used extensively in \\napplications to the petroleum industry where they can provide \\nsolutions to drilling problems such as prediction of drill bit wear \\nfrom drilling parameters, real-time predictions of alterations in \\ndrilling fluid rheology\\n5, and the estimation of oil recovery factor \\nfor water drive sandy reservoirs6.\\n1.1 Artificial Intelligence\\nMachine Learning (ML) and Deep Learning (DL) are \\nbranches of artificial intelligence that deals with computerized \\nsystems and algorithms learning from previous data generated\\n7. \\nBy utilizing various algorithmic strategies, they enable the \\nsystems to perform computational tasks without requiring \\nexplicit programming and learn from the data. Finding patterns'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='7. \\nBy utilizing various algorithmic strategies, they enable the \\nsystems to perform computational tasks without requiring \\nexplicit programming and learn from the data. Finding patterns \\nin numerical data by applying computer algorithms to convert \\ndata into numerical form is known as machine learning. \\nAmongst other formats, the data may be in the form of pictures, \\nmusic, numbers, or alphabetical data. The algorithms used to \\nfind the patterns within these data are called machine learning \\nmodels. These models, which include linear regression, logistic \\nregression, decision Trees, random forest, K-Means, K-Nearest \\nNeighbors, are used for prediction, data sub-grouping and \\nsound-detection, amongst others. They have been applied to \\naid in the prediction of ROP values with better accuracy and \\ngeneralization. ML operations are divided into supervised and \\nunsupervised learning. Supervised learning is a paradigm in \\nmachine learning here input objects and a desired output value \\ntrain a model. The training data is processed, and builds a \\nfunction that maps new data on expected output values (e.g., \\nregression and classification). In unsupervised learning, the data \\nhas no target label, the machine learning model aims at finding \\nhidden patterns in the data using algorithms to make critical \\njudgments in the future (e.g., clustering and recommendation).\\nDeep learning is a branch of the machine learning and \\nartificial intelligence that mimics the operation of how the human \\nbrain receives, process and transmit information, as depicted in \\nFigure 1.\\nFigure 1: Human neuron model.\\nDeep learning (DL) is essentially a neural network with one \\nor more layers. The components of the human neural network \\nare modelled similar to the neural network operation\\n8. The \\ndendrites act as input nodes, cell body represents activation \\nfunction, synapse is the weightage of each input, and the axon \\nterminal is the output node as shown in Figure 2.\\nFigure 2: A typical feed forward neural network architecture9.\\nNeural networks (or deep learning) are massively parallel'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='3\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\ndistributed processor that store and make use of experiential \\nknowledge. It is classified into 3 parts: artificial neural network \\n(ANN), convolutional neural network (CNN), and recurrent \\nneural network (RNN), which are used to carry out different \\noperations. The ANN is mostly used to carry out regression \\nand classification problems. The CNN is mostly used to carry \\nout image processing and prediction while the RNN is mostly \\nused for forecasting operations. A convolutional neural network \\nand a few machine learning strategies are used in this work. \\nConvolutional layers, feature extractors (filters), pooling layers, \\nhidden layers, and one or more output layers are the components \\nof a convolutional neural network. Weights are used to connect \\nthe layers in the hidden layer of the CNN structure. These weights \\nfacilitate information flow between layers and aid in neural \\nnetwork training. An activation function is present in every \\nhidden layer, which helps to save computational time and cost \\nby converting the data into a more computer-interactive format. \\nTo extract important features from the data, convolutional layers \\nassist in performing convolutional operations on the data.\\nBefore the data is sent to the filter, which extracts the features \\nand patterns in the dataset, the convolutional layer typically \\nreceives the input in the form of length, breadth, height, and \\ncolor channels. CNNs have two feature extraction layers: one \\nthat makes use of pooling layers and the other that makes use of \\nfilters. To extract even more important insights from the dataset, \\na pooling layer made up of a pooling approach is employed to \\nperform pooling on the features that the filter helped extract. To \\nconduct out-pooling, different sorts of pooling techniques are \\nemployed, such as MaxPooling, Average Pooling, and Global \\nPooling.\\nBilgesu et al\\n10. used an artificial neural network to develop an \\nROP model, which was dependent on several operating \\nparameters. A data of 500 points was used, with nine features, \\nwhich were tooth wear, rotary speed, torque, weight on bit, \\npump flow rate, rotating time, bearing wear, formation \\ndrillability, and formation abrasiveness. A train-test ratio of 9:1, \\nwhich implies 90% of the data was used for training and 10% for \\nvalidating the model. A coefficient of determination (\\n2R ) \\nbetween 0.902 and 0.982 was achieved after cross-validation \\nacross the data. In the work of Arabjamaloei and Shadizadeh\\n11, \\nan artificial neural network with a single hidden layer of 10 \\nneurons was developed and combined with genetic algorithm \\n(GA) to create a model to predict ROP values. There were seven \\nfeatures and 300 points (rows) in the data. The bit type, formation \\nproperties, bit operating condition (rotary speed and bit weight), \\nbit tooth wear, bit hydraulics, hydrostatic head, and equivalent \\ncirculating density were the input features. A total of 224 points \\nwere used for model training, 56 points for validation, and 20 \\npoints for testing. The generic algorithm was employed to find \\nwhere the maximum rate of penetration occurred. With a low \\nmean-square error for both training and test set, it was concluded \\nthat the neural network is valid for other data sets that fall within \\nthe range of data set used for training the model\\n12.performed a \\ncomparative evaluation of models for estimating the rate of \\npenetration (ROP) by utilizing field data from a well located in \\nIran. The model used for this study were the Bingham\\n4, Warren13 \\nand, Bourgoyne and Young 3 models. They carried out ROP \\npredictions on wells that were drilled with roller cone and PDC \\nbits, and comparison was carried out on three separate drilling \\nsections. However, there was a short coming of this study, in that \\nthreshold \\noBW was neglected due to lack of drill-off test been \\ncarried out. The findings of this study demonstrated that among'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='sections. However, there was a short coming of this study, in that \\nthreshold \\noBW was neglected due to lack of drill-off test been \\ncarried out. The findings of this study demonstrated that among \\nthe models examined, the Bourgoyne and Young model exhibited \\nthe highest level of predictive performance. Mahasneh\\n14 \\ndeveloped a mathematical model to predict the rate of penetration \\n(ROP) in gas wells, considering the factors of weight on bit \\n(WOB), bit rotation speed (RPM), flow rate (FR), formation \\nstrength, depth, and formation compaction. He then used his \\nmodel to optimize the drilling parameters for a gas well in \\nJordan, increasing the ROP by 15% and reducing the cost of \\ndrilling by 10%. Mahasneh\\n14’s study demonstrated the \\nimportance of drilling optimization in improving the efficiency \\nand cost-effectiveness of drilling operations. Amar and Ibrahim\\n15 \\nworked on the comparative analysis of physics-based equations \\nwith artificial neural networks (ANN). They developed two \\nneural network models to evaluate the ROP values. The input \\nparameters into the neural networks were formation depth, ECD, \\nweight on bit, DSR, pore pressure gradient, drill bit tooth wear, \\nand Reynolds number function. The physics-based equations \\nused for the comparative analysis were the Bingham\\n4 model and \\nBourgoyne and Young3 model. A comparison of the predictive \\naccuracy of the developed ANN-based models with the available \\nempirical equations showed that both ANN-based models were \\nhighly accurate for estimating the ROP as compared with the \\nempirical equations. Shi et al.\\n16predicted the rate of penetration \\n(ROP) using the Extreme Learning Machine (ELM) and Upper-\\nlayer solution-ware (USA) techniques. To construct the \\npredictive models, various input parameters such as formation \\nproperties, rig hydraulics, bit specifications, weight on bit, rotary \\nspeed, and mud properties were utilized. These input features \\nwere selected based on reservoir data from Bohai Bay, China. \\nThe performance of the developed models using ELM and USA \\ntechniques was compared with an artificial neural network \\nmodel. The accuracy of these models was evaluated using \\nmetrics such as regression coefficient (\\n2R ), mean absolute error \\n(MAE), and root mean square error ( RMSE). The findings \\nindicated that the ROP model developed with the USA technique \\nexhibited the highest predictive performance compared to the \\nother models. Additionally, it was observed that the development \\nof the ROP model using the extreme learning technique required \\nthe most time investment. Ahmed et al.\\n17 investigated the \\napplication of a support vector machine model to estimate the \\nrate of penetration in a formation containing shale materials. The \\ninput features used in the model were hinged on drilling \\nparameters and mud properties such as weight on bit, rotary \\nspeed, pump flow rate, standpipe pressure, drilling torque, mud \\ndensity, plastic viscosity, funnel viscosity, yield point and solid \\ncontent (%). The support vector machine model and the \\nBourgoyne and Youngs model were trained on more than 400 \\nreal data in shale formation using these 10 features as inputs. \\nThe two models were both compared on their predictive \\nperformance on the test data. The Bourgoyne and Young (1974) \\nmodel produced a coefficient of determination (\\n2R ) of 0.0692 \\nand an absolute percentage error of 23.41%. By applying the \\nsupport vector machine (SVM) model, a coefficient of \\ndetermination (\\n2R ) of 0.995 and an absolute percentage error of \\n2.82% were obtained. It was concluded that SVM can be used to \\npredict ROP with higher accuracy and also generate ROP values \\nfaster than the Bourgoyne and Young\\n3 model. Elkatany 5 \\ndeveloped an artificial neural network (ANN) model to predict \\nthe rate of penetration (ROP) using data collected from three \\nvertical wells in an offshore oilfield. The ANN-ROP model was \\nobtained based on drilling parameters and drilling fluid'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='the rate of penetration (ROP) using data collected from three \\nvertical wells in an offshore oilfield. The ANN-ROP model was \\nobtained based on drilling parameters and drilling fluid \\nproperties. Two wells were utilized for training the model, and \\nthe third well was used to evaluate the accuracy of the model.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n4\\nThe performance of the ANN-ROP model was compared to \\nother ROP models of Bingham (1965), Bourgoyne and Young\\n3, \\nand Maurer18. Elkatany5 concluded that the proposed ANN-ROP \\nmodel exhibited superior performance over others considered in \\nhis work. The training data consisted of 3333 data points and \\nyielded a coefficient of determination (\\n2R ) of 0.99, with an \\naverage absolute percentage error ( AAPE) of 5%. The test set, \\nconsisting of 2700 unseen data points from the third well, \\nresulted in the ANN-ROP model predicting the rate of penetration \\nwith \\n99. 02 =R and AAPE = 4%. Zhang et al. 19 proposed a deep \\nconvolutional neural network (CNN) model for predicting the \\nrate of penetration (ROP) during drilling operations. The authors \\nargued that existing models for predicting ROP are often \\ninaccurate and unreliable, and that deep learning methods could \\nprovide a more accurate and practical solution. They collected \\ndata from drilling operations in two different fields and used it to \\ntrain and test the proposed deep CNN model in their work. The \\nmodel consists of six convolutional layers and is trained using a \\nmean absolute percentage error (MAPE) loss function. The \\nauthors compared the performance of their deep CNN model to \\nother machine learning models and found that it outperformed \\nthese models in terms of accuracy and reliability. They also \\nconducted sensitivity analyses to determine the most important \\nfeatures for predicting ROP. They found that the weight on bit, \\nthe rotary speed, and the mud flow rate were the most important \\nfeatures for predicting ROP. Zhao et al.\\n20 focused on developing \\nmultiple artificial neural network (ANN) models for predicting \\nthe rate of penetration (ROP) using data collected from a gas \\nwell located in the southern region of Iran. A dataset comprising \\n3180 data points was obtained from various drilling sections, \\ninvolving one run of a roller-cone bit and three runs of PDC bits. \\nTo construct the ANN-ROP models, several input variables were \\nconsidered, including depth, rotary speed of the bit, weight on \\nbit (WOB), shut-in pipe pressure, fluid rate, mud weight, the \\nratio of yield point to plastic viscosity, and the ratio of 10-minute \\ngel strength to 10-second gel strength. Three different training \\nfunctions, namely Levenberg-Marquardt (LM), Scaled \\nConjugate Gradient (SCG), and One-Step Secant (OSS), were \\nemployed in combination with the neural networks to estimate \\nthe penetration rates. It was concluded that the ANN-ROP model \\nutilizing the Levenberg-Marquardt (LM) function demonstrated \\nthe best prediction performance, achieving a regression \\ncoefficient (\\n2R ) of 0.91 in training and 0.89 in testing. \\nFurthermore, they also applied the Artificial Bee Colony (ABC) \\nalgorithm to optimize the ROP. The optimization process \\nresulted in an approximate improvement of 20–30% in the rate \\nof penetration. Abdulmalek et al.\\n21 carried out a comparative \\nanalysis between artificial intelligence techniques and some \\ntraditional models for ROP prediction in shaley formations. An \\nartificial neural network was developed for the ROP prediction \\nin the shale formation. The parameters considered for the \\nprediction of the rate of penetration (ROP) included torque, \\nstandpipe pressure, pump rate, mud weight, funnel and plastic \\nviscosities, solid content, and yield point. The traditional ROP \\nmodels such as those proposed by Bingham\\n4, Warren 13, \\nBourgoyne and Young3, Maurer18 and Hareland and Hoberock22, \\nwere selected for comparison. Both the artificial neural network–\\nROP (ANN-ROP) model and the traditional models underwent \\ntraining and testing using a dataset consisting of 347 data points \\nfrom a deep shale formation in an onshore oilfield. Additionally, \\n200 new data points from an upper shale formation were utilized \\nto validate the models. The results indicated that the ANN-ROP'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='from a deep shale formation in an onshore oilfield. Additionally, \\n200 new data points from an upper shale formation were utilized \\nto validate the models. The results indicated that the ANN-ROP \\nmodel outperformed the other models in comprehending the \\nintricate relationships within the data and making accurate \\npredictions. The ANN-ROP model achieved a rate of penetration \\nprediction with an average absolute percentage error (AAPE) of \\n5.776% and a regression coefficient (\\n2R ) of 0.996. Ashrafi et \\nal.23 explored the prediction of rate of penetration (ROP) using \\nvarious optimization algorithms and neural network architectures. \\nThe optimization algorithms employed included Genetic \\nAlgorithm (GA), Particle Swarm Optimization (PSO), \\nBiogeography-based Optimizer (BBO), and Imperialist \\nCompetitive Algorithm (ICA). These algorithms were combined \\nwith different neural network architectures to develop hybrid \\nROP models. To evaluate the performance of the hybrid models, \\nthe results were compared with two other models: Non-linear \\nMultiple Regression (NLMR) and Linear Multiple Regression \\n(LMR) techniques. For the hybrid models, two popular neural \\nnetwork architectures, namely Multi-Layer Perception (MLP) \\nand Radial-Based Function (RBF), were utilized. These \\narchitectures consisted of two hidden layers with 4 and 6 \\nneurons, respectively. The activation function used in the hidden \\nlayers and output layer was tan-sigmoid. The input features were \\nweight on bit, rotational speed of the drill bit, pump inlet flow \\nrate, pore pressure pump pressure, gamma ray, density log, and \\nshear wave velocity. The dataset used for the study consisted of \\n1000 data points, collected from the Marun oilfield in Iran. It \\nwas concluded in their study that the hybrid models utilizing \\nPSO-MLP and PSO-RBF neural networks exhibited the best \\npredictive accuracy for ROP. The root mean square error (RMSE) \\nvalues for these models were 1.12 and 1.4, respectively, \\nindicating their superior performance compared to the other \\ndeveloped models. Iqbal\\n24 developed a mathematical model to \\npredict the rate of penetration (ROP) in drilling operations, \\nconsidering the factors of weight on bit (WOB), bit rotation \\nspeed (RPM), flow rate (FR), formation strength, depth, and \\nformation compaction. He then used his model to optimize the \\ndrilling parameters for a real-time drilling dataset from a Middle \\nEastern oil field, increasing the ROP by 10% and reducing the \\ncost of drilling by 5%. Iqbal’s study demonstrates the importance \\nof using real-time drilling parameters to optimize drilling \\noperations and provides a valuable contribution to the field of \\ndrilling engineering. Burgos et. al.\\n25 developed a convolutional \\nneural network (CNN) model to predict the rate of penetration \\n(ROP) during rotary drilling operations. The model takes in 10 \\ndrilling parameters as inputs, such as weight on bit, rotary speed, \\nflow rate, and hook load. The inputs are normalized between 0 \\nand 1. The CNN architecture consists of 3 convolutional layers \\nfollowed by 2 fully connected layers. The output layer has a \\nsingle node with a linear activation to predict the ROP value. \\nThe model was trained on data from over 600 wells. It achieved \\na mean absolute percentage error (MAPE) of 9.3% on the test \\nset, outperforming traditional machine learning models like \\nlinear regression, random forests, and support vector regression. \\nAn ablation study showed that the CNN’s ability to learn \\ncomplex non-linear relationships between the drilling parameters \\nallowed it to accurately predict ROP, whereas simply averaging \\nthe inputs did not work as well. The model was able to generalize \\nthe data from 50 additional wells, with the MAPE only increasing \\nslightly to 10.2%. This shows the model has good generalization \\nperformance. In conclusion, the CNN approach effectively \\nmodelled the complexity between drilling parameters and ROP,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='slightly to 10.2%. This shows the model has good generalization \\nperformance. In conclusion, the CNN approach effectively \\nmodelled the complexity between drilling parameters and ROP, \\noutperformed traditional models, and generalized well to new \\ndata. This could enable more efficient drilling operations through \\naccurate ROP predictions. Monazami et al.\\n26 used an artificial \\nneural network (ANN) to predict the rate of penetration (ROP) \\nin drilling operations. The ANN model took cognizance of'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='5\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nformation strength, depth, formation compaction, pressure \\ndifferential, bit diameter, weight on bit (WOB), bit rotation \\n(RPM), and bit hydraulics. The authors evaluated the performance \\nof their ANN model on a test dataset of ROP data. They found \\nthat the model was able to predict ROP with high accuracy. The \\naverage error between the predicted and actual ROP values was \\nless than 5%. The model was able to predict ROP with high \\naccuracy, suggesting that ANN is a promising tool for optimizing \\ndrilling parameters and improving the efficiency and cost-\\neffectiveness of drilling operations. Abbas et al.\\n27 employed an \\nartificial neural network (ANN) approach to develop a \\ncomputational-based method for predicting the rate of \\npenetration (ROP). Through a thorough analysis of feature \\nselection, it was determined that out of the 25 input variables \\nexamined, 19 variables had the greatest influence on the ROP. A \\ndataset consisting of 13,125 data points from 14 deviated wells \\nin a formation located in southern Iraq was collected for the \\nstudy. The data specifically pertained to the 8 ½” production \\ncasing section, which was drilled using a drag bit and a \\nconventional bottom hole assembly (BHA) with a water-based \\nmud circulating system. It was concluded that the ROP model \\nbased on the artificial neural network, utilizing three hidden \\nlayers and employing the tan–sigmoid activation function, \\nexhibited the highest efficiency in predicting ROP. The model \\nachieved a regression coefficient of 0.92 during training and \\n0.97 during testing, with mean absolute percentage errors \\n(MAPE) of 9.1% and 8.8% in training and testing, respectively. \\nFurthermore, the model demonstrated good performance on \\nunseen data and did not exhibit overfitting issues. Miyora\\n28 \\nstudied the factors that affect the rate of penetration (ROP) in \\ngeothermal drilling and developed a mathematical model to \\npredict ROP based on these factors. The model includes \\nformation strength, depth, formation compaction, pressure \\ndifferential, bit diameter, weight on bit (WOB), bit rotation \\n(RPM), and bit hydraulics. Miyora () found that all these factors \\nhave a significant impact on ROP and used his model to optimize \\nthe drilling parameters for Well MW-17 in Menengai, Kenya, \\nincreasing the ROP by up to 20%. Al-AbdulJabbar et al.\\n29 utilized \\nan artificial neural network (ANN) in combination with self-\\nadaptive differential evolution (SADE) to predict the rate of \\npenetration (ROP) specifically in horizontal carbonate reservoirs. \\nThe model incorporated six input variables, including rotary \\nspeed, torque, weight on bit, as well as formation petrophysical \\nproperties such as gamma ray, resistivity, and bulk density data. \\nThe developed model demonstrated strong performance, \\nachieving a regression coefficient (\\n2R ) of 0.96 and a mean \\nabsolute percentage error (MAPE) of 5.12%. To further evaluate \\nthe accuracy of the model, an unseen well was used as test data. \\nThe resulting regression coefficient (\\n2R ) and MAPE values \\nwere 0.95 and 5.8%, respectively. Furthermore, their study \\naimed to enhance the interpretability of the ROP model by \\nextracting the weights and biases in a matrix form, effectively \\ntransforming it from a black box model to a white box model. \\nWang et al.\\n30 proposed a hybrid ensemble learning approach for \\npredicting the rate of penetration (ROP) during oil and gas \\ndrilling operations. They argued that existing models for \\npredicting ROP are often inaccurate and unreliable, and that \\nensemble learning methods can provide a more accurate and \\npractical solution. They collected data from drilling operations \\nin the Gulf of Mexico and used it to train and test their hybrid \\nensemble learning model. The model consisted of several \\nmachine learning algorithms, including support vector regression \\n(SVR), random forest regression (RFR), and gradient boosting'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='ensemble learning model. The model consisted of several \\nmachine learning algorithms, including support vector regression \\n(SVR), random forest regression (RFR), and gradient boosting \\nregression (GBR), which were combined using a weighted \\naverage ensemble method. The authors compared the \\nperformance of their hybrid ensemble learning model to other \\nmachine learning models and found that it outperformed these \\nmodels in terms of accuracy and reliability. The authors also \\nconducted sensitivity analyses to determine the most important \\nfeatures for predicting ROP. They found that the weight on bit, \\nthe rotary speed, and the mud flow rate were the most important \\nfeatures for predicting ROP. Liu et al.\\n31 proposed a stacked \\ngeneralization ensemble model for predicting the rate of \\npenetration (ROP) in gas well drilling. The model is trained on a \\ndataset of historical ROP data and drilling parameters from a \\nshale gas survey well in Xinjiang, China. The model combined \\nthe predictions of six machine learning models: support vector \\nregression (SVR), extremely randomized trees (XRT), random \\nforest (RF), gradient boosting machine (GBM), light gradient \\nboosting machine (LightGBM), and extreme gradient boosting \\n(XGB). They first used Pearson correlation analysis to identify \\nthe most important features from the dataset. Then, they used a \\nSavitzky-Golay smoothing filter to reduce noise in the dataset. \\nFinally, they trained the stacked generalization ensemble model \\nusing the leave-one-out cross-validation method. The results \\nshowed that the stacked generalization ensemble model can \\nsignificantly improve the accuracy of ROP prediction. The root \\nmean square error (RMSE) of the model on the testing dataset is \\n0.4853 m/h, which is lower than the RMSE of any of the \\nindividual models. The model also has a high \\n2R value of \\n0.9568. They also used the model to optimize the ROP \\nparameters. They use particle swarm optimization (PSO) to \\nsearch for the optimal combination of ROP parameters. The \\nresults show that the optimized ROP parameters can significantly \\nimprove the ROP. It was thus concluded that the stacked \\ngeneralization ensemble model is a promising approach for \\npredicting ROP in gas well drilling. The model is accurate and \\ncan be used to optimize the ROP parameters. Moraveji and \\nNaderi32investigated the simultaneous effect of six variables on \\npenetration rate using real field drilling data via response surface \\nmethodology (RSM). The important variables included well \\ndepth (D), weight on bit (WOB), bit rotation speed ( N), bit jet \\nimpact force (IF), yield point, \\npY , to plastic viscosity ratio, PVR\\n, ( PVRYp ), 10 min to 10 s gel strength ratio (10MGS/10SGS). \\nEqually, bat algorithm (BA) was used to identify optimal range \\nof factors in order to maximize drilling rate of penetration. Their \\nresults indicated that the derived statistical model provides an \\nefficient tool for estimation of ROP and determining optimum \\ndrilling conditions.\\nThe aim of this study is to analyze the performance of \\nmachine learning and deep learning techniques in predicting the \\nrate of penetration during drilling, which is crucial in optimizing \\ndrilling operations. The results of this study can contribute \\nto drilling planning and optimization of future wells. Exact \\nprediction of the rate of penetration during drilling will save the \\noil and gas industry a large amount of expenses during drilling \\noperation and reduce the amount of non-productive time (NPT) \\nencountered during drilling operation.\\n1.2 Approaches to Rate of Penetration Modelling\\nOver the past few years, a large amount of research has gone \\ninto ways in which ROP can be modelled with its dependent \\ndrilling parameters (controllable and uncontrollable). A key \\ndrive that leads to further research regarding this field is the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n6\\nnon-comprehensiveness of previous models developed. This \\nis because not all of the known ROP-affecting factors have \\nbeen accounted for in a single model, which has led to poor \\naccuracy and generalizability of the estimated models\\n33. The \\nseemingly large number of factors affecting the ROP and \\nessential requirement for a model with high accuracy and \\nreliable generalization has led to development of various ROP \\nestimation models. An approach to carry out this modelling is \\nhinged on two patterns, which are physics-based approach, and \\ndata-driven approach. The physics-based approach involves \\nthe use of mathematical modelling techniques to evaluate \\nrelationships between dependent parameter (ROP) and the \\nindependent parameters, so as to estimate accurate ROP values. \\nThese mathematical relationships are developed based on the \\nphysics of the borehole. There are various models used for ROP \\nestimation that are created using the physics-based approach \\ne.g., Cunningham model, Bingham\\n4 model, Maurer 19 model, \\nMotahhari et al. model33 and Hareland and Rampersad model 34. \\nThe Cunningham model is given by:\\n          (1)\\nwhere R  is the rate of penetration (ft/h), K  the constant of \\nproportionality, 0W  the threshold weight on bit (lb f) and N  \\nrotary speed (rpm).\\nBingham4 model: \\n  (2)\\nwhere  is the weight-on bit (klb), BD  is the bit diameter \\n(in), a and b are the dimensionless constants for each rock \\nformation.\\nMaurer\\n18 model: \\n   (3)\\nwhere  is the rate of penetration (ft/h), W  the weight (Ibf), s  \\nthe confined rock strength (psi) and D the depth (ft).\\nMotahhari et al. model33: \\n  (4)\\nwhere fw  is the dimensionless wear function, G is a model \\ncoefficient related to bit-rock interactions and bit geometry, \\nα  and γ  are ROP model exponents. The bit coefficient, G, \\nis determined by the bit design, cutter size, cutter rock friction \\ncoefficient and the bit geometry. In this model, a decrease in \\nthe value of the wear function, while keeping other model \\nparameters constant leads to a decrease in ROP. In the case of \\nthe bit size or compressive strength, when its value is decreased \\nan inverse occurs. The relationship between \\nN ,  and R  is \\nnon-linear. Hence, the exponents can yield an optimum value for \\n and N due to the exponential nature of the relationship.\\nHareland and Rampersad Model34: \\n    (5)\\nwhere cN  is the number of cutters and vA  the area of rock \\ncompressed ahead of a cutter (in2 ).\\nOther models used for ROP estimation are as follows:\\nBourgoyne and Young\\n3 model: \\n     (6)\\nwhere  is the weight-on bit (klb), BD  is the bit diamete r \\n(in), a and bare the dimensionless constants for each rock \\nformation.\\n Bourgoyne et al. 35 aimed at seeking to optimize the \\ncontrollable parameters during drilling operation. They proposed \\nthe development of an ROP model based on the application \\nof multiple linear regression technique. The controllable \\nparameters used in developing this model were eight: strength \\nof formation, normal compaction function, weight on bit, \\nbit teeth wear, rotary speed function, bit hydraulic function, \\ndifferential pressure function, and under compaction function. \\nThese parameters were treated as independent parameters on the \\nROP (the dependent parameter). The developed model was then \\napplied to estimate ROP for wells drilled vertically using roller \\ncone bits, and it was concluded that the application of the ROP \\nmodel could help reduce drilling operational cost by 10%. On \\ninception, the model was basically created for modelling ROP \\nfor roller cone bits, but overtime has also shown effectiveness \\nin modelling ROP for PDC bits. The Bourgoyne et al.\\n35 model \\nis given by:\\n∏\\n=\\n=\\n8\\n1i\\niFR            (7)\\nwhere )( 1\\n1\\naeF =  is the formation strength function for \\nBourgyone and Young model, ( )[ ] DaeF −= 10000\\n2\\n2 the normal \\ncompaction function for Bourgyone and Young model, \\n the under compaction function'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='1\\naeF =  is the formation strength function for \\nBourgyone and Young model, ( )[ ] DaeF −= 10000\\n2\\n2 the normal \\ncompaction function for Bourgyone and Young model, \\n the under compaction function \\nfor Bourgyone and Young model, ( )[ ]{ } cpg D aF ρ−= 44 exp  the \\npressure differential function for Bourgyone and Young model, \\n( ) ( )\\n( ) \\uf8fa\\n\\uf8fa\\n\\uf8fb\\n\\uf8f9\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\n\\uf8ee\\n\\uf8f4\\n\\uf8fe\\n\\uf8f4\\n\\uf8fd\\n\\uf8fc\\n\\uf8f4\\n\\uf8f3\\n\\uf8f4\\n\\uf8f2\\n\\uf8f1\\n\\uf8fa\\n\\uf8fb\\n\\uf8f9\\n\\uf8ef\\n\\uf8f0\\n\\uf8ee\\n−\\n−=\\nt\\nt\\nd w\\nd wd wInaF 4exp 55  the weight on bit function \\nfor Bourgyone and Young model, \\nthe r otary speed function for Bourgyone and Young model, \\n( )[ ]{ } haF −= 77 exp  the bit tooth wear function for Bourgyone \\nand Young model and \\n  the bit hydraulic \\nfunction for Bourgyone and Young model.\\n The physics-based approach has limitations due to the failure \\nto consider all the parameters affecting the drilling operation and \\nin the choice of an empirical constant for the ROP estimation \\nwith respect to the well/borehole in operation. This gave rise \\nto the use of data-driven approaches, which make use of data \\ngenerated during drilling (Logging While Drilling (LWD)) \\nand artificial intelligence techniques for ROP estimation\\n17. The \\napplication of AI models for ROP estimation was suggested by \\nBilgesu et al.\\n10, so as to get over the weakness of the physics-\\nbased approach and improve the accuracy of ROP predictability. \\n2. Methodology\\n2.1 Methods\\nFigure 3 shows the proposed methodology, adopted in this \\nstudy.\\n2.2 Data Collection\\nThe data utilized for this study was obtained from the Daily \\nDrilling Report (DDR) for an oil well in Nigeria. It contains \\nparameters that ROP depends on, which will help make a robust \\nmodel. Such parameters are weight on bit, pump flow rate, mud \\nweight, mud type, drill bit diameter and wellbore trajectory, \\namongst others. After data collection, the uncertainties within \\nthe dataset and the suitable parameters are defined. This leads \\nto filtration of the dataset. The well contains data of 27 columns \\n(the number of variables), 17280 rows, 0% missing cells, and \\n0% duplicate rows.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='7\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\n2.3 Data Processing\\nThe data preprocessing phase is also known as Feature \\nEngineering Phase. The data set used for the study is subjected to \\nvarious statistical manipulations and transformations in order to \\nextract relationships and insights between parameters in the data \\nand, process the data into forms that are more understandable \\nby the algorithms, hence, producing better model performances. \\nSuch techniques include exploratory data analysis, missing \\ndata imputation, outlier handling, feature scaling, variable \\ntransformation, and discretization, amongst others. These \\nprocesses help the model match key relationships between the \\ninput parameters and the target variable. In this study, the data \\npreprocessing techniques used were outlier handling, variable \\ntransformation and feature scaling.\\nOutlier handling: This refers to the process involved in dealing \\nwith outliers found in a dataset. Outliers are simply data point \\nthat vary significantly to majority of the dataset. Outliers must \\nbe dealt with since they can significantly affect the outcomes \\nand precision of statistical models. Outlier treatment can be done \\nin a number of ways, such as by removing outliers, capping, \\nor imputing more representative values. The method utilized in \\nthis study was the capping technique, which involved imputing \\nthe interquartile range of the variable with the outlier where the \\noutliers are in the variable. Figures 4 and \\n5 show the box plot of \\nROP data before and after outlier.\\nFigure 4: Box plot of ROP data before outlier.\\nVariable Transformation: This technique was employed in \\nthis study to treat the variables that were skewed either to the \\nleft or to the right. It involves changing a variable’s scale or \\ndistribution to satisfy requirements or enhance the performance \\nof statistical models. This preprocessing technique was \\nperformed on variables that were skewed either to the left or \\nright, so as to equalize variances and establish linearization \\namong the variables, which makes it easier to interpret and \\nmodel. The variable transformation technique use in this study \\nwere LogTransformer and BoxCoxTransformer.\\nFigure 5: Box plot of ROP data after outlier removal. removal.\\nFeature Scaling: This involves changing the scale of \\nnumerical features in a dataset. To make the features similar and \\nprevent some from predominating others based only on their \\ninitial scale, the range or distribution of the features must be \\nchanged. This preprocessing technique is so important as it helps \\nthe machine learning models to better understand the features as \\nthey will usually be within the range of 0 to 1, which the models \\nusually prefer. For some particular models, it is a necessary \\nrequirement to perform feature scaling on the dataset before \\npassing it into them e.g., ANN and CNN, while some models \\nare not influenced when the dataset is scaled or not e.g., Random \\nForest and Extra Trees. There are many types of Feature scaling \\ntechniques e.g., Standard Scaler, MinMax Scaler and Robust \\nscaling. Each of these techniques has their rules of engagement, \\nso as to get better model performance. These rules depend on \\ndataset and model to be used. In this study, the standard scaler \\nwas utilized so as to scale features to have a mean of 0 and a \\nstandard deviation of 1. \\nTable 1 shows the features definition \\nwith the data types used. \\nTable 1: Features definition, unit, and data types.\\nFeature Definition Units Data type\\nDepth The actual depth at which the drilling \\nis taking place.\\nm Numerical\\nLag Depth Time delay or lag between the mea -\\nsured depth and the corresponding \\nROP value.\\nm Numerical\\nWHO Weight on String. klb Numerical\\nROP Rate of Penetration. m/h Numerical\\nRPM  \\nTURBIN\\nTurbine Speed. rev/\\nmin\\nNumerical\\nTorque Rotational force of drill string. klb.ft Numerical\\nSPP Standpipe Pressure. psi Numerical\\nFlow Inflow rate of drilling. fluid pumped into'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='RPM  \\nTURBIN\\nTurbine Speed. rev/\\nmin\\nNumerical\\nTorque Rotational force of drill string. klb.ft Numerical\\nSPP Standpipe Pressure. psi Numerical\\nFlow Inflow rate of drilling. fluid pumped into \\nthe wellbore during drilling.\\ngpm Numerical\\nMw In total volume of drilling mud pumped \\ninto the wellbore during a specific pe-\\nriod of time.\\npcf Numerical\\nMw out total volume of drilling mud pumped \\nout of a wellbore during a specific pe-\\nriod of time.\\npcf Numerical\\nPIT#1 mud pit volume in the first mud pit or \\nmud tank.\\nBbl Numerical\\nPIT#2 mud pit volume in the second mud pit \\nor mud tank.\\nBbl Numerical'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n8\\nPIT#3 mud pit volume in the third mud pit \\nor mud tank.\\nBbl Numerical\\nPIT#4 mud pit volume in the fourth mud pit \\nor mud tank.\\nBbl Numerical\\nPIT#5 mud pit volume in the fifth mud pit or \\nmud tank.\\nBbl Numerical\\nPIT#6 mud pit volume in the Sixth mud pit \\nor mud tank.\\nBbl Numerical\\nTOT ACT Total Actual Time. Bbl Numerical\\nSteel V ol-\\nume\\nThe volume of steel that is used or \\nconsumed during the drilling process.\\nBbl Numerical\\nOver pull Additional force applied to the drilling \\nassembly in order to increase the drill-\\ning efficiency. \\nklb Numerical\\nFlow Pad-\\ndle\\nPercentage of drilling fluid that cir -\\nculates through the wellbore during \\ndrilling.\\n% Numerical\\nBit Posi -\\ntion\\nIt refers to the vertical depth at which \\nthe drilling bit is located within the \\nwellbore.\\nm Numerical\\nHook Po -\\nsition\\nVertical position of the drilling hook \\nor traveling block.\\nm Numerical\\nString  \\nWeight\\nTotal weight of the drill string, includ-\\ning the drill pipe, bottom hole assem -\\nbly (BHA), and any other components \\nattached to it.\\nklb Numerical\\nDrag Resistance encountered by the drill \\nstring and drill bit as they are ad-\\nvanced through the formation.\\nklb Numerical\\nTable 2 gives information on the statistic of ROP variable.\\nTable 2: Descriptive Statistics of ROP variable.\\nStatistic Mean Standard \\ndeviation\\nMini -\\nmum\\n25% 50% 75% Maxi -\\nmum\\nROP 3.964 4.317 0.000 0.000 2.880 7.410 18.525\\nTable 3 gives the Pearson correlation of the oil well features and \\ntheir values.\\nTable 3: Pearson correlation of features with rate of penetration.\\nFeatures Well data\\nDepth -0.37\\nLag depth 0.98\\nWHO 0.15\\nRPM TURBIN0.57\\nTorque 0.70\\nSPP 0.64\\nFlow in 0.57\\nMw in -0.08\\nMw out 0.20\\nPIT#1 0.24\\nPIT#2 -0.14\\nPIT#3 -0.10\\nPIT#4 -0.26\\nPIT#5 0.05\\nPIT#6 0.23\\nTOT ACT-0.25\\nSteel volume 0.20\\nFlow paddle 0.75\\nBit position 0.20\\nHook position 0.26\\nString eight -0.01\\nDrag -0.53\\nThe correlation heat map of the well data is depicted in \\nFigure 6.\\nFigure 6: Correlation heat map of the well data.\\n2.4 Feature Selection\\nThe defined input parameters from the dataset must pass \\nthrough the feature selection phase. The feature selection is \\nthe process of selecting a subset of relevant features (variable, \\npredictors) for usage in building machine learning algorithms. It \\ninvolves selecting the pool of features that has significant impact \\non making prediction with the machine learning algorithm. It is \\na crucial phase, in the bid that a good machine learning model \\nis developed. The feature selection algorithms are divided into \\nthree main categories: filter, wrapper, and embedded methods. \\nThe feature selection helps a user to better interpret the model \\ne.g., a model of 10 input parameters is much easier to interpret \\nthan that of 100 parameters. It also shortens training time for \\nthe machine learning algorithm and enhances generalization \\nby reducing overfitting. In this study, a filter method known \\nas mutual information was used to select optimal features for \\nmodel building. Mutual information is a statistical measure of \\nthe mutual dependence of 2 variables. In other words, mutual \\ninformation quantifies the amount of information gained about \\none random variable through observing another random variable. \\nThe mutual information algorithm is given by: \\n{ }∑∑ ××= )]() (/[) , (log) , () ; ( y px pyx py x pYX I  (8)\\nwhere I is the ranking score, X  and Ythe respective input and'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='9\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\noutput nodes, x and y are the dependent and target variables \\nrespectively.\\nThe algorithm selects the highest-ranking features that best \\ndescribes the target variable and separates them into percentiles \\ne.g., 10th, 20 th, 30 th etc., depending on the highest ranking. In \\nthis study, the features in the top 50 th (50 percentile), which \\ntranslated to 13 features out of the possible 27, were selected to \\nbe used to the build the machine learning models. The features \\nselected after future selection are depth, lag depth, WOB, SPP, \\nMW IN, PIT#2, PIT#3, PIT#4, PIT#6, TOT ACT, steel volume, \\nbit position and hunk position \\n2.5 Data Splitting\\nData splitting (otherwise known as cross validation) is a \\nprocess utilized in the building of artificial intelligence models. \\nHere, data is partitioned into two or more ways to enable the \\nmodel identify the patterns within the data set and predict its \\nperformance on unseen (real world) data. Two sets of the dataset \\nare created: a training set and a testing set. The training set is \\nused to train the artificial intelligence model on the data while \\nthe testing set is used to assess the model’s performance in real \\nworld scenarios. This is because there is a probability that the \\nbuilt model may not be robust enough to perform successfully on \\nunknown (real world) data. There are various methods used for \\ncross validation operation viz. holdout method, K-fold method, \\nStratified K-fold method, Leave One-Out method, amongst \\nothers. The K-fold cross validation technique was implemented \\nin this study using the Python Sklearn package.\\nA 60:40 split of the oil well data was made into train and \\ntest sets. There are 10368 rows and 13 columns in the training \\nset and 6912 rows and 13 columns in the test set. The training \\nresults were obtained by training the model on the train data \\nand using the resulting model to predict the training set. The \\ntest results were obtained by training the model on the train set \\nbefore predicting the test set.\\n3. Model Development and Training\\nSeven machine learning techniques were analyzed in this \\nwork, to be trained to make predictions of the rate of penetration \\nfor the oil well. The machine learning models that were employed \\nfor this analysis are outlined as follows and their written codes \\ncan be found in the Appendix.\\n3.1 Random Forest Regression\\nRandom forest can be applied to both classification and \\nregression problems. It is an ensemble learning technique that \\ncreates a large number of decision trees during training period \\nand utilizes averaging to improve the prediction accuracy \\nand control over-fitting. Random forests are widely used for \\napplications (such as credit scoring and spam filtering) because \\nthey can handle both categorical and continuous data. During \\ntraining, random forests create a lot of decision trees\\n36. Each \\ntree is constructed using a random subset of the features and \\na sample of the training data. The individual decision trees \\npredictions are combined by the random forest algorithm to \\nprovide a prediction. For a wide range of applications, random \\nforests are a potent and useful machine learning technique. They \\nare often good performers and are quite simple to teach and tune.\\n A schematic of the decision tree regression is depicted in \\nFigure. 7.\\nFigure 7: Decision tree regression schematic37.\\nA random forest model works by training multiple decision \\ntrees in parallel and uses a bagging technique to obtain a robust \\nmodel. Usually, machine learning models have hyperparameters, \\nthat is, parameters in the algorithm that are constant throughout \\ntraining that help the algorithm better understand the data \\npatterns. Hyperparameters in random forest algorithm include \\nmax_depth, max_features, min_samples_leaf, min_samples_\\nsplit, n_estimators. To obtain optimal performance of the \\nrandom forest algorithm, optimal values must be selected for'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='max_depth, max_features, min_samples_leaf, min_samples_\\nsplit, n_estimators. To obtain optimal performance of the \\nrandom forest algorithm, optimal values must be selected for \\nthese hyperparameters. To get the optimal values of the random \\nforest algorithm, a hyperparameter search algorithm (known as \\nthe randomized search algorithm) must be used. This algorithm \\nhelps to generate the optimal hyperparameter value for the \\nhyperparameter to be utilized in the model. After implementing \\nrandomized search algorithm on the well data, the optimal value \\nof the hyperparameters were max_depth = 31, max_features \\n= sqrt, min_samples_leaf = 3, min_samples_split = 13, n_\\nestimators = 666.\\n3.2 Linear Regression\\nLinear regression is a supervised method of machine learning \\nthat uses one or more input features to predict a continuous target \\nvariable. It is assumed that there is a linear relationship between \\nthe input variables and the goal variables. Linear regression \\nis intended to establish the optimal line according to the data, \\nminimizing the difference in predicted and real values. The \\nalgorithm operates by generating the coefficients of the line’s \\nlinear equation. Some hyperparameters in linear regression \\nare copy_X and fit_Intercept. After implementing randomized \\nsearch algorithm on the well data using linear regression as \\nthe base model, the optimal value of the hyperparameters were \\ncopy_X = True, and fit_Intercept = True. \\n3.3 KNearest Neighbor\\nKNearest Neighbor (KNN), as shown in Figure 8, is a \\nsupervised model-based machine learning technique that can \\nbe applied to both classification and regression models. KNN is \\nnot a parametric algorithm, meaning that it does not make any \\nassumptions about the distribution of data. The KNN method \\nis based on the hypothesis that similar occurrences will share \\nsimilar labels. The KNN technique identifies the K closest \\nneighbors to a given data point by reference to a distance metric, \\ntypically Euclidean, and assigns the label to the majority of these \\nK neighbors for a given data point. When the algorithm is doing \\na regression, it takes the weighted average of all the target values \\nfrom the K neighbor and uses it to predict the new value for the \\ngiven data point. The number of neighbors is a hyperparameter \\nthat can be changed. Some hyperparameters in KNN algorithms \\nare algorithm, leaf_size, p, weights, and n_neighbours. After'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n10\\nimplementing randomized search algorithm on the well data \\nusing KNearest neighbor as the base model, the optimal value of \\nthe hyperparameters were algorithm= auto, leaf_size = 10, p = 1, \\nweights = distance and n_neighbours = 3.\\nFigure 8: KNearest Neighbor38.\\nFigure 9: SVM schematic39.\\n3.4 Support Vector Machine Regression\\nSupport vector machine (SVM) regression is a supervised \\nlearning algorithm that is primarily used in classification tasks. \\nIt is derived from the concepts of support vector machines \\n(SVM), as shown in Figure 9. The goal of SVM regression is \\nto identify a function that best matches the relationship between \\nthe input and target variables. The SVM regression generates a \\nhigh-dimensional hyperplane with each data point as a feature \\nvector in the hyperplane space. The objective of the algorithm \\nis to find the hyperplane with the greatest margin, i.e., the \\ndistance from the hyperplane to the nearest data point in each \\nclass. In the regression case, SVM chooses the hyperplane that \\ncontains the most data points within the given range. The range \\nis the margin of tolerance, which allows some data points to fall \\noutside of the range. The support vectors are the data points that \\nfall within or cross the range. Some hyperparameters in support \\nvector regression algorithm are C, epsilon, and kernel. After \\nthe implementation of the randomized search algorithm on the \\nwell data using support vector regression algorithm as the base \\nmodel, the optimal values of the hyperparameters were C = 10, \\nepsilon = 1 and kernel = rbf. \\n3.5 Stacking Technique\\nStacking is a type of machine learning technique, whose \\nalgorithm is shown in Figure 10, that uses the predictive power of \\ndifferent machine learning algorithms to make better predictions \\non datasets. The stacking technique typically involves the use \\nof base models and a meta model. The base models are usually \\ncommon machine learning algorithms such as decision trees, \\nrandom forests, and support vector machines. These base models \\nare trained on a dataset and are used to make predictions; these \\npredictions are then combined in a meta model, which can be \\nlinear regression or a neural network to make final predictions. \\nIt is a powerful machine learning technique since it utilizes the \\ndiverse knowledge of the base models. The base models used for \\nthis study are random forests, or support vector machines, linear \\nregression, and nearest neighbors, while the meta model used is \\nthe linear regression model.\\nFigure 10: Stacking algorithm 40.\\n3.6 Voting Technique\\nV oting is a machine learning technique that involves the \\nintegration of predictions from multiple independent models to \\nform a final prediction, as shown in Figure 11. \\nFigure 11: V oting Algorithm (LevelUpCoding).\\nV oting technique is commonly referred to as ensemble \\nvoting, or majority voting, and is based on the principle that the \\nintegration of the opinions of multiple models can often lead \\nto greater prediction accuracy than the use of a single model. \\nUnder the V oting algorithm, each base model is trained on \\nthe same data set, but with different algorithms or settings. \\nDuring the prediction phase, each base model makes its own \\nprediction based on the data it has been trained on. Finally, the \\nfinal prediction is calculated by adding up all the predictions \\nusing a voting system. The base models used for this study are \\nrandom forests, or support vector machines, linear regression, \\nand nearest neighbors, while the meta model used is the linear \\nregression model.\\n3.7 Convolutional Neural Network\\nConvolution Neural Networks (CNNs) are a type of deep \\nlearning algorithm that is commonly employed in the analysis \\nand interpretation of visual data, including images and videos. \\nCNNs are widely used for image classification, object recognition \\nand image segmentation. However, not only can CNNs be used'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='and interpretation of visual data, including images and videos. \\nCNNs are widely used for image classification, object recognition \\nand image segmentation. However, not only can CNNs be used \\nfor image classification, but they can also be used in regression-\\nbased projects, where it is purposed to predict continuous \\nvariables. A convolution neural network (CNN) usually consists \\nof four components: convolutional layers, pooling layers, fully \\nconnected layers, and output layers, as shown in Figure 12. \\nThese four components usually make for the architecture of \\nCNNs. The main difference between a CNN and a regression-\\nbased CNN is the output layer (output layer) and loss function \\n(loss function). The output layer in a CNN based on regression is \\ndistinct from that of a Softmax-based CNN. Instead of predicting \\nclass probabilities using a function of a Softmax, an output layer \\nis typically composed of an individual neuron with a function'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='11\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nof a linear activation. This allows the network to produce a \\ncontinuous value immediately as a regression prediction. For \\nregression tasks, a loss function is often used to measure the \\ndifference between predicted and actual target values. Examples \\nof loss functions that are commonly used include MSE (mean \\nsquared error) and MAE (mean absolute error). \\nFigure 12: Convolutional neural network39.\\n3.8 Model Evaluation\\nThere are metrics usually used to reflect how well the \\nmodel has learnt patterns in the data and the performance of the \\nmodel on the unseen (test) data set. There are metrics used for \\nevaluating the performance of \\nmachine learning models. These \\nmetrics show how far a model’s prediction is from the true \\nvalues. In this study, four error metrics are used to estimate a \\nmodel performance on the learning patterns in the dataset and \\nunseen data (test data). They are the mean absolute error (MAE), \\nroot mean squared error (RMSE), mean squared error (MSE) and \\ncoefficient of determination,\\n2R –score, given by Equations (9) \\nto (12) respectively. \\n∑\\n=\\n−=\\nn\\ni\\ni\\nn\\nyyMAE\\n1\\nˆ              (9)\\n( )∑\\n=\\n−=\\nn\\ni\\ni\\nn\\nyyRMSE\\n1\\n2\\nˆ        (10)\\n∑\\n=\\n−=\\nn\\ni i\\ni\\ny\\nyy\\nnMSE\\n1\\nˆ1               (11)\\n( )\\n( )∑\\n∑\\n=\\n=\\n−\\n−\\n= n\\ni\\ni\\nn\\ni\\nyy\\nyy\\nR\\n1\\n2\\n1\\n2\\n2\\nˆ\\n           (12)\\nwhere yˆ , iy  and y  are the respective predicted, actual and \\nmean values and n the number of observations.\\n4. Results and Discussion\\nThe well data after carrying out various statistical analyses, \\nthe features were reduced from the previous 27 columns to 13 \\ncolumns, , as displayed in Table 4, which is an excerpt of the well \\ndata used for both training and testing. It shows a sample of the \\ndata utilized after feature selection has been carried out, leaving \\n17280 rows and 13 columns. These data were then separated \\nusing cross validation to train and test data respectively. The \\ntrain data contained 10368 rows and 13 columns, while the test \\ndata contained 6912 rows and 13 columns. The linear regression \\nmodel was applied to the training data and test data after the \\noptimal hyperparameters had been generated. The train and \\ntest data were standardized such that data has a mean of 0 and \\nstandard deviation of 1. The results obtained using the linear \\nregression model are presented in Table 5.\\nThe random forest regression, KNearest neighbor, and \\nsupport vector regression (SVR) model were applied to the \\ntraining data and test data after the optimal hyperparameters had \\nbeen generated using the randomized search cv algorithm. The \\ntrain and test data were standardized such that data has a mean \\nof 0 and standard deviation of 1. The random forest, KNearest \\nneighbor, and support vector regression (SVR) models’ results \\nare presented in Tables 6–8 respectively.\\nEqually, the stacking and voting techniques were applied to \\nthe training data and test data after the optimal hyperparameters \\nhad been generated using the randomized search cv algorithm \\nfor the base model used in the technique. The train and test data \\nwere standardized such that data has a mean of 0 and standard \\ndeviation of 1. The results obtained using the stacking and voting \\ntechniques are presented in Tables 9 and 10 respectively.\\nThe convolutional neural network (CNN) model was applied \\nto the training data and test data using an epoch of 120 and a batch \\nsize of 32 together with an output layer of 1. The architecture of \\nthe CNN model created is as follows: two 1–D (one dimensional \\nconvolutional layers), filters (32 and 64), kernel size of two, one \\nGlobal MaxPooling Layer, 5 hidden layers and 1 output layer. \\nThe train and test data were standardized such that data has a \\nmean of 0 and standard deviation of 1. The results obtained \\nusing the CNN model are presented in Table 11.\\nTable 4: Sample taken from well data used to build ML models.\\nTable 5: Linear regression model results.\\nError metric Training data Test data\\nRMSE 2.611 2.565'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Table 4: Sample taken from well data used to build ML models.\\nTable 5: Linear regression model results.\\nError metric Training data Test data\\nRMSE 2.611 2.565\\nMSE 6.819 6.582\\nMAE 1.773 1.744\\n2R  Score 0.639 0.639\\nTable 6: Random Forest model results.\\nError Metric Training Data Test Data\\nRMSE 0.469 0.676\\nMSE 0.220 0.458\\nMAE 0.207 0.300\\nScore \\n2R\\n0.988 0.975\\nTable 7: KNearest neighbor model results.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n12\\nError Metric Training Data Test Data\\nRMSE 0.523 0.724\\nMSE 0.309 0.524\\nMAE 0.201 0.239\\nScore\\n 2R\\n0.984 0.971\\nTable 8: SVM model results.\\nError Metric Training Data Test Data\\nRMSE 1.724 1.669\\nMSE 2.972 2.784\\nMAE 0.841 0.832\\nScore 0.843 0.847\\nTable 9: Stacking technique results.\\nError Metric Training Data Test Data\\nRMSE 0.306 0.548\\nMSE 0.033 0.423\\nMAE 0.094 0.300\\nScore \\n2R\\n0.98 0.976\\nTable 10: V oting Technique results.\\nError Metric Training Data Test Data\\nRMSE 0.803 0.826\\nMSE 1.167 1.331\\nMAE 0.646 0.681\\nScore \\n2R\\n0.938 0.926\\nTable 11: CNN results.\\nError Metric Training Data Test Data\\nRMSE 0.797 0.751\\nMSE 1.167 1.331\\nMAE 0.636 0.564\\nScore \\n2R\\n0.924 0.928\\n From the results displayed in Tables 5–11, the stacking \\ntechnique performed better than all the models and techniques \\nemployed in this study for the training data. Hence, the decreasing \\norder of performance of the models for the training data is as \\nfollows: stacking technique > random forest model > KNearest \\nneighbor model > CNN model > V oting technique > SVR model \\n> linear regression model. In terms of the RMSE, the stacking \\ntechnique was 35% better than the random forest model, 41% \\nbetter than the KNearest neighbor model, 62% better than the \\nCNN model and V oting technique, 82% better than the SVR \\nmodel and 88% better than the linear regression model. In terms \\nof the MAE, the stacking technique was 55% better than the \\nRandom Forest model, 53% better than the KNearest Neighbour \\nmodel, 85% better than the CNN model and V oting technique, \\n89% better than the SVR model and 95% better than the linear \\nregression model.\\nFor the testing data, generalizing across the four metrics, \\nthe stacking technique yet again out-performed other models. It \\nwas only in terms of the MAE that the KNearest neighbor model \\noutperformed the stacking technique by 20%, but in terms of the \\nRMSE, MSE, \\n2R  Score, the stacking technique outperformed \\nthe KNearest Neighbour model. SVR model and linear \\nregression model performed better on the test data compared to \\ntheir performances on the train data, indicating generalization of \\nthe models and lack of overfitting on the training data.\\nIn terms of the test (unseen) data, the stacking technique \\nperformed better than all the traditional ML models employed \\nin this study. The next to it on the ranking of the model that \\nbest performed on the test data was the Random Forest model, \\nfollowed by the KNearest Neighbour model, then the CNN \\nmodel, then the V oting technique, then the SVR model and lastly \\nthe linear regression model. \\nIn terms of the RMSE, the stacking technique was 19% better \\nthan the Random Forest model, 24% better than the KNearest \\nNeighbour model, 27% better than the CNN model, 34% better \\nthan the V oting technique, 67% better than the SVR model and \\n79% better than the linear regression model.\\nIn terms of the MAE, the stacking technique and the Random \\nForest model had the same performance score of 0.30. The \\nstacking technique was still 47% better than the CNN model, \\n56% better than the V oting technique, 64% better than the SVR \\nmodel and 83% better than the linear regression model.\\nOur findings in this investigation that the complex ML models \\nof Stacking, V oting and CNN have the capacity to perform better \\nthan the traditional ML model was buttressed in the work of \\nBurgos et al, which was equally corroborated in the study of \\nZhang et. al.\\n19, where the CNN model developed outperformed \\nall the traditional ML models in terms of accuracy and reliability. \\nIt can equally be deduced from this study that irrespective of the \\narchitecture and predictive capacity of the ML model, traditional \\nML models, with proper feature engineering and hyperparameter \\ntuning, can perform better than more complex machine learning \\nmodels.\\n5. Conclusions\\nA comparative analysis of machine learning algorithms in \\npredicting rate of penetration during drilling was carried out in'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='models.\\n5. Conclusions\\nA comparative analysis of machine learning algorithms in \\npredicting rate of penetration during drilling was carried out in \\nthis study. Data was obtained from the Daily Drilling Report \\n(DDR) for an oil well. The well contains data of 17280 rows \\nand 27 columns. The data preprocessing techniques of outlier \\nhandling, variable transformation and feature scaling were \\nemployed. Each of the seven machine learning techniques \\nemployed to predict the rate of penetration during drilling was \\nable to extract meaningful information and patterns from the oil \\nwell data. However, some models outperformed other models by \\na distance, which reflects the predictive power of the algorithms. \\nThe capacity of the stacking algorithm to combine the predictive \\npower of each base model gave it an edge over the rest of the \\nmodels. The voting technique performed well, but not measured \\nup to the performance of the stacking technique. Hence, the \\nstacking technique is a more powerful ensembling technique \\nthan the voting technique. Amongst the base models, the random \\nforest and KNearest Neighbors models are robust since they \\nperformed well on both the train and test data, while the SVM \\nand linear regression models gave the highest errors on both \\nthe train and test data but they also showed their generalization \\ncapability and lower tendency to overfit. The CNN model has \\nthe capacity to perform well on regression-based task like rate \\nof penetration predictions since it performed well on the test and \\ntrain data.\\nStatements and Declarations'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='13\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nConflict of interest The authors declare that there is no conflict \\nof interest regarding the publication of this article.\\nFunding The authors received no specific funding for this \\nwork. Hence, the corresponding author confirms that there are \\nno financial and personal relationships with other people or \\norganizations that could inappropriately influence this study.\\n6. References\\n1. Azar HF, Saksala T, Jalali SME. Artificial neural networks models \\nfor rate of penetration prediction in rock drilling. J Structural \\nMechanics 2017;50(3):252-255. \\n2. Rupert JP, Padro CW, Blattel SR. The effects of weight material \\ntype and mud formulation on penetration rate using invert oil \\nsystems. Paper presented at the Society of Petroleum Engineers \\n(SPE) Annual Technical Conference and Exhibition 1981. \\n3. Bourgoyne Jr AT, Young Jr FS. A multiple regression approach \\nto optimal drilling and abnormal pressure detection. SPE J \\n1974;14(04):371-384.\\n4. Bingham MG. A new approach to interpreting rock drillability. \\nTechnical Manual Reprint Oil & Gas Journal 1965: 1-93.\\n5. Elkatatny S. Real time prediction of rheological parameters of \\nKCl water-based drilling fluid using artificial neural networks. \\nArabian Journal for Science and Engineering 2017;42:1655-\\n1665.\\n6. Mahmoud AA, Elkatatny S, Chen W, Abdulraheem A. Estimation \\nof oil recovery factor for water drive sandy reservoirs through \\napplications of artificial intelligence. Energies 2019;12(9):3671.\\n7. Connor Shorten “Machine Learning vs. Deep Learning” Towards  \\nData Science. 2018.\\n8. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature \\n2015;521(7553):436–444.\\n9. Otchere DA, Ganat TOA, Gholami R, Ridha S. Application \\nof supervised machine learning paradigms in the prediction \\nof petroleum reservoir properties: Comparative analysis of \\nANN and SVM models. Journal of Petroleum Science and \\nEngineering 2021;200:108182. \\n10. Bilgesu HI, Tetrick LT, Altmis U, Mohaghegh S, Ameri S. A new \\napproach for the prediction of rate of penetration (ROP) values. \\nPaper presented at the Society of Petroleum Engineers (SPE) \\nEastern Regional Meeting 1997; SPE–39231–MS.\\n11. Arabjamaloei R, Shadizadeh S. Modeling and optimizing rate \\nof penetration using intelligent systems in an Iranian southern \\noil field (Ahwaz oil field). Petroleum Science and Technology \\n2011;29(16):1637–1648.\\n12.  Bataee M, Mohseni S. Application of artificial intelligent systems \\nin ROP optimization: a case study in Shadegan oil field. Paper \\npresented at the Society of Petroleum Engineers (SPE) \\nMiddle East Unconventional Gas Conference and Exhibition \\n2011;SPE-140029-MS.\\n13. Warren TM. Penetration-rate performance of roller-cone bits. \\nSPE Drill Eng 1987;2(01):9–18.\\n14. AL-Mahasneh MA. Optimization Drilling Parameters \\nPerformance during Drilling in Gas Wells. International Journal \\nof Oil, Gas and Coal Engineering 2017;5:19-26. \\n15. Amar K, Ibrahim, A. Rate of penetration prediction and \\noptimization using advances in artificial neural networks, a  \\ncomparative study. In Proceedings of the 4th International Joint \\nConference on Computational Intelligence 2012;1:647-652.\\n16. Shi X, Liu G, Gong X, Zhang J, Wang J, Zhang H. An efficient \\napproach for real-time prediction of rate of penetration in offshore \\ndrilling. Mathematical Problems in Engineering 2016;(Article ID \\n3575380):1–13.\\n17. Ahmed A, Elkatatny S, Abdulraheem A, Mohammed M, Ali A , \\nMohamed I. Prediction of rate of penetration of deep and tight \\nformation using support vector machine. In Proceedings of the \\nSPE Kingdom of Saudi Arabia Annual Technical Symposium \\nand Exhibition, Dammam, Saudi Arabia. 2018; SPE–192316–\\nMS.\\n18. Maurer WC. The, “perfect-cleaning” theory of rotary drilling. J \\nPet Technol 1962;14(11):1270-1274.\\n19. Zhang Y, Zhang X, Chen Y. Deep neural networks for predicting \\nrate of penetration in drilling. Journal of Petroleum Science and \\nEngineering 2018;165:734-743.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Pet Technol 1962;14(11):1270-1274.\\n19. Zhang Y, Zhang X, Chen Y. Deep neural networks for predicting \\nrate of penetration in drilling. Journal of Petroleum Science and \\nEngineering 2018;165:734-743.\\n20.  Zhao Y, Noorbakhsh A, Koopialipoor M, Azizi A, Tahir MM. \\nA new methodology for optimization and prediction of rate \\nof penetration during drilling operations. Engineering with \\nComputers 2020;36:587-595.\\n21. Abdulmalek A, Abdulwahab A, Salaheldin E, Abdulazeez A. New \\nartificial neural networks model for predicting rate of penetration \\nin deep shale formation. Sustainability 2019;11(22): 6527. \\n22. Hareland G, Hoberock LL. Use of drilling parameters to predict \\nin-situ stress bounds. Paperpresented at the SPE/IADC Drilling \\nConference. Netherlands 1993:SPE-25727-MS. \\n23. Ashrafi SB, Anemangely M, Sabah M, Ameri MJ. Application of \\nhybrid artificial neural networks for predicting rate of penetration \\n(ROP): a case study from Marun oil field. Journal of Petroleum \\nScience and Engineering 2019;175:604-623.\\n24. Iqbal F. Drilling optimization technique using real time \\nparameters. SPE Russian Oil & Gas Technical Conference and \\nExhibition, Moscow, Russia, 2008. \\n25. Burgos CE, Zhang T, Li J, Zhang C, Chen S. ROP prediction \\nusing convolutional neural networks for Paleozoic shale drilling. \\nJournal of Petroleum Science and Engineering 2019;17:633-\\n641.\\n26. Monazami M, Hashemi A, Shahbazian M. Drilling rate of \\npenetration prediction using artificial neural network: A case \\nstudy of one of Iranian Southern oil fields. Journal of Oil and \\nGas Business 2012.\\n27. Abbas AK, Rushdi S, Alsaba M, Al Dushaishi MF. Drilling rate of \\npenetration prediction of high-angled wells using artificial neural \\nnetworks. J. Energy Resour. Technol 2019;141(11):112904.\\n28. Miyora TO. 2014. Modeling and optimization of geothermal \\ndrilling parameters: A case study of well MW-17 in Menengai \\nKenya, MS Thesis. University of Iceland 2014.\\n29. Al-AbdulJabbar A, Elkatatny S, Mahmoud AA, et al. Prediction \\nof the rate of penetration while drilling horizontal carbonate \\nreservoirs using the self-adaptive artificial neural networks \\ntechnique. Sustainability 2020;12(4):1376.\\n30. Wang K, Zhang Y, Zhang X, Wang Y. A hybrid ensemble \\nlearning approach for rate of penetration prediction in oil and \\ngas drilling. Journal of Petroleum Science and Engineering \\n2020;194:107424.\\n31.  Liu N, Gao H, Zhen Z, Hu Y, Duan L. A stacked generalization  \\nensemble model for optimization and prediction of the gas well  \\nrate of penetration: a case study in Xinjiang. Journal of Petroleum \\nExploration and Production Technology 2021;6:1595-1608.\\n32. Moraveji MK, Naderi M. Drilling rate of penetration prediction \\nand optimization using response surface methodology and bat \\nalgorithm. Journal of National Gas Science and Engineering \\n2016;31:829–841. \\n33. Motahhari HR, Hareland G, Nygaard R, Bond B. Method of \\noptimizing motor and bit performance for maximum ROP. J Can \\nPet Technol 2009;48(06):44-49. \\n34. Hareland G, Rampersad PR. Drag - Bit Model Including Wear. \\nAmerica/Caribbean Petroleum Engineering Conference 1994: \\nSPE-26957-MS.\\n35. Bourgoyne Jr AT, Millheim KK, Chenevert ME, Young Jr FS.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n14\\nApplied drilling engineering. SPE Textbook Series 1991;2:ISBN: \\n978-1-55563-001-0.\\n36. Quinlan JR. Induction of decision trees. Machine Learning \\n1986;1(1):81-106. \\n37. SametGirgin, Decision Tree Regression in 6 Steps with Python, \\nPursuitData (Medium). 2019.\\n38. Javat (2022).  \\n39. Pandey YN, Rastogi A, Kainkaryam S, Bhattacharya S, Saputelli \\nL. Overview of Machine Learning and Deep Learning Concepts. \\nMachine Learning in the Oil and Gas Industry 2020:75-152.\\n40. GeeksForGeeks (2022)\\n7 Appendix: Codes for the different algorithms employed in this work.\\nRandom Forest Algorithm\\nLinear Regression Algorithm\\nK Nearest Neighbour Algorithm'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='15\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nSVR Algorithm\\nStacking Algorithm\\nVoting Algorithm'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 15, 'page_label': '16'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n16\\nCNN Algorithm Code')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "f_o = RecursiveCharacterTextSplitter(chunk_size = 2000,chunk_overlap=400).split_documents(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Comparative Analysis of Machine Learning Algorithms in Predicting Rate of \\nPenetration during Drilling\\nOlaosebikan Abidoye Olafadehan*, Ikenna David Ahaotu\\nDepartment of Chemical and Petroleum Engineering, University of Lagos, Akoka-Y aba, Lagos 101017, Nigeria\\nCitation: Olafadehan OA, Ahaotu  ID, Comparative Analysis of Machine Learning Algorithms in Predicting Rate of Penetration \\nduring Drilling. J Petro Chem Eng 2023;1(1): 32-47.\\nReceived: 14 October, 2023; Accepted: 31 October, 2023; Published: 07 November, 2023\\n*Corresponding author: Olafadehan OA, Department of Chemical and Petroleum Engineering, University of Lagos, Akoka-\\nY aba, Lagos 101017 Nigeria, Phone: +234802-912-9559, Email: oolafadehan@unilag.edu.ng\\nCopyright: © 2023 Olafadehan OA., et al., This is an open-access article published in J Petro Chem Eng (JPCE) and distributed \\nunder the terms of the Creative Commons Attribution License, which permits unrestricted use, dist ribution, and reproduction \\nin any medium, provided the original author and source are credited.\\n1\\n A B S T R A C T \\nDrilling for potential oil and gas reserves is one of the foremost practices in the petroleum industry. The dr illing process, \\nhowever, is quite expensive and can take quite some time to accomplish.  Hence, there has been a rise in the n eed to reduce \\ncost and time by optimizing the rate of penetration during drilling, which has led to the development of mathemat ical models \\nto describe and evaluate this process.  However, the accuracy of these models has varied owing to variat ion of the drilling \\nparameters accounted for in each model. This event has led to the usage of alternative approaches such as Data driven models.  In \\nthis study, the predictive capacities of the rate of penetration (ROP) during drilling using machine learning (ML) algorithms of \\nsupport vector machine regression (SVR), Random Forest regression (RF), Linear regression (LR), KNearest neighbors (KNN),'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='parameters accounted for in each model. This event has led to the usage of alternative approaches such as Data driven models.  In \\nthis study, the predictive capacities of the rate of penetration (ROP) during drilling using machine learning (ML) algorithms of \\nsupport vector machine regression (SVR), Random Forest regression (RF), Linear regression (LR), KNearest neighbors (KNN), \\nStacking technique, Voting technique and Convolution neural network (CNN), were compared.  Data from an oil well in Nigeria \\nwas used in this investigation. The data for the well was split into train–test sets in the ratio of 60:40.  The train data was used to \\ntrain and select the best model before making predictions on the test sets.  The Stacking technique was found t o have the best \\nperformance across both training and test data sets with respective accuracies of 99.8% and 97.5% in terms of the  –score. The \\nVoting technique also performed well, with respective accuracies of 93.6% and 92.6% in terms of the  –score across both sets of \\ndata. The CNN model equally performed well on the training and test data sets, with respective accuracies of 92.4% a nd 92.8% \\nin terms of the  –Score.  Generally, the machine learning models were able to detect patterns and gain valuable insights into the \\ndata. They can be employed for real time prediction of the rate of penetration during oil well drilling.\\nKeywords: Rate of penetration; Drilling; Artificial intelligence; Machine learning algorithms; train–test data.\\nAbbreviations\\nAI  Artificial Intelligence\\nANN            Artificial Neural Network\\nCNN            Convolutional Neural Network\\nDDR             Daily Drilling Report\\nKNN              KNearest Neighbors\\nMAE             Mean Absolute Error\\nML                  Machine Learning\\nR2                    Coefficient of determination\\nRMSE             Root mean squared Error.\\nROP                 Rate of penetration. \\nRPM            Rotary speed,\\nSVR                Support Vector Regressor'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='CNN            Convolutional Neural Network\\nDDR             Daily Drilling Report\\nKNN              KNearest Neighbors\\nMAE             Mean Absolute Error\\nML                  Machine Learning\\nR2                    Coefficient of determination\\nRMSE             Root mean squared Error.\\nROP                 Rate of penetration. \\nRPM            Rotary speed,\\nSVR                Support Vector Regressor\\nWOB              Weight on bit, kblf\\nResearch Article\\nVol: 1 & Iss: 1\\nhttps://urfpublishers.com/journal/petrochemical-engineering\\nJournal of Petroleum & Chemical Engineering'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n2\\n1. Introduction\\nDrilling is a key aspect of the petroleum industry. It is the \\nprocess of boring a hole deep into the subsurface section of the \\nearth in order to reach formations with hydrocarbon reserves, \\nfor the aim of hydrocarbon recovery. The importance of this \\nprocess cannot be understated and as a result, a lot of different \\ndrilling technologies were implemented to maximize drilling \\noperations. The popular drilling method used today known \\nas the rotary drilling, which is applied in drilling the majority \\nof onshore and offshore wells and makes use of an applied \\naxial force on the rotating drill bit to achieve penetration. It is \\nimpossible to overstate the significance of this procedure, which \\nis why numerous drilling methods have been used to maximize \\ndrilling operations. The bulk of onshore and offshore wells are \\ndrilled using the widely used technique known as the rotary \\ndrilling, which applies an axial force to the revolving drill bit \\nto accomplish penetration. In a rotary drilling process, key \\nparameters need to be considered to ensure optimal operations, \\nand a key parameter among these is the rate of penetration, ROP. \\nIt is the depth of penetration accomplished per unit time, and is \\nusually measured as a factor of how many feet the bit can drill in \\nan hour (i.e., ft/h). However, evaluation of ROP is difficult due \\nto the complex relationship between other drilling parameters \\naffecting the ROP. The rate of penetration (ROP) prediction is \\na key task in drilling economical assessments\\n1. Not always is \\nthe lowest cost per foot provided by the fastest drilling pace. A \\nrise in the project’s overall cost may be caused by other factors. \\nThe characteristics of drilling fluid (such as mud viscosity, mud \\ndensity, filtration loss), mechanical characteristics (such as bit \\ntype and weight), and formation properties (such as porosity, rock'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='1. Not always is \\nthe lowest cost per foot provided by the fastest drilling pace. A \\nrise in the project’s overall cost may be caused by other factors. \\nThe characteristics of drilling fluid (such as mud viscosity, mud \\ndensity, filtration loss), mechanical characteristics (such as bit \\ntype and weight), and formation properties (such as porosity, rock \\nabrasivity, formation elasticity, formation stress, permeability) \\nare a few examples of the properties that affect penetration rate\\n2. \\nHence, it is important to maximize the rate of penetration in order \\nto mitigate some of the general cost associated with drilling for \\nextended periods. Therefore, it is necessary to understand the \\nrelationship between the ROP and other operational parameters.\\nMathematical models have been used to model the \\nrelationship between some operational parameters and ROP \\ne.g., Bourgoyne and Young\\n3 model and the Bingham 4. The \\naccuracy of these models has varied due to variation in the \\ndrilling parameters considered in each model. This has led to \\nthe usage of alternative approaches such as a data driven model \\ne.g., artificial intelligence (AI). Artificial intelligence methods \\nhave developed rapidly over the past decades and has led to it \\nbeen implemented in various sectors, including the oil and gas \\nindustry. Colossal amount of data is been generated on the oil \\nfield during operating hours. These data include drilling data, \\nproduction data, seismic data and mud log data, amongst others. \\nThese data sets can be trained using artificial intelligence \\nmethods to make future predictions and generate hidden insights \\ninto the data. The AI methods have been used extensively in \\napplications to the petroleum industry where they can provide \\nsolutions to drilling problems such as prediction of drill bit wear \\nfrom drilling parameters, real-time predictions of alterations in \\ndrilling fluid rheology\\n5, and the estimation of oil recovery factor \\nfor water drive sandy reservoirs6.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='into the data. The AI methods have been used extensively in \\napplications to the petroleum industry where they can provide \\nsolutions to drilling problems such as prediction of drill bit wear \\nfrom drilling parameters, real-time predictions of alterations in \\ndrilling fluid rheology\\n5, and the estimation of oil recovery factor \\nfor water drive sandy reservoirs6.\\n1.1 Artificial Intelligence\\nMachine Learning (ML) and Deep Learning (DL) are \\nbranches of artificial intelligence that deals with computerized \\nsystems and algorithms learning from previous data generated\\n7. \\nBy utilizing various algorithmic strategies, they enable the \\nsystems to perform computational tasks without requiring \\nexplicit programming and learn from the data. Finding patterns'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='7. \\nBy utilizing various algorithmic strategies, they enable the \\nsystems to perform computational tasks without requiring \\nexplicit programming and learn from the data. Finding patterns \\nin numerical data by applying computer algorithms to convert \\ndata into numerical form is known as machine learning. \\nAmongst other formats, the data may be in the form of pictures, \\nmusic, numbers, or alphabetical data. The algorithms used to \\nfind the patterns within these data are called machine learning \\nmodels. These models, which include linear regression, logistic \\nregression, decision Trees, random forest, K-Means, K-Nearest \\nNeighbors, are used for prediction, data sub-grouping and \\nsound-detection, amongst others. They have been applied to \\naid in the prediction of ROP values with better accuracy and \\ngeneralization. ML operations are divided into supervised and \\nunsupervised learning. Supervised learning is a paradigm in \\nmachine learning here input objects and a desired output value \\ntrain a model. The training data is processed, and builds a \\nfunction that maps new data on expected output values (e.g., \\nregression and classification). In unsupervised learning, the data \\nhas no target label, the machine learning model aims at finding \\nhidden patterns in the data using algorithms to make critical \\njudgments in the future (e.g., clustering and recommendation).\\nDeep learning is a branch of the machine learning and \\nartificial intelligence that mimics the operation of how the human \\nbrain receives, process and transmit information, as depicted in \\nFigure 1.\\nFigure 1: Human neuron model.\\nDeep learning (DL) is essentially a neural network with one \\nor more layers. The components of the human neural network \\nare modelled similar to the neural network operation\\n8. The \\ndendrites act as input nodes, cell body represents activation \\nfunction, synapse is the weightage of each input, and the axon \\nterminal is the output node as shown in Figure 2.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 1, 'page_label': '2'}, page_content='Figure 1.\\nFigure 1: Human neuron model.\\nDeep learning (DL) is essentially a neural network with one \\nor more layers. The components of the human neural network \\nare modelled similar to the neural network operation\\n8. The \\ndendrites act as input nodes, cell body represents activation \\nfunction, synapse is the weightage of each input, and the axon \\nterminal is the output node as shown in Figure 2.\\nFigure 2: A typical feed forward neural network architecture9.\\nNeural networks (or deep learning) are massively parallel'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='3\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\ndistributed processor that store and make use of experiential \\nknowledge. It is classified into 3 parts: artificial neural network \\n(ANN), convolutional neural network (CNN), and recurrent \\nneural network (RNN), which are used to carry out different \\noperations. The ANN is mostly used to carry out regression \\nand classification problems. The CNN is mostly used to carry \\nout image processing and prediction while the RNN is mostly \\nused for forecasting operations. A convolutional neural network \\nand a few machine learning strategies are used in this work. \\nConvolutional layers, feature extractors (filters), pooling layers, \\nhidden layers, and one or more output layers are the components \\nof a convolutional neural network. Weights are used to connect \\nthe layers in the hidden layer of the CNN structure. These weights \\nfacilitate information flow between layers and aid in neural \\nnetwork training. An activation function is present in every \\nhidden layer, which helps to save computational time and cost \\nby converting the data into a more computer-interactive format. \\nTo extract important features from the data, convolutional layers \\nassist in performing convolutional operations on the data.\\nBefore the data is sent to the filter, which extracts the features \\nand patterns in the dataset, the convolutional layer typically \\nreceives the input in the form of length, breadth, height, and \\ncolor channels. CNNs have two feature extraction layers: one \\nthat makes use of pooling layers and the other that makes use of \\nfilters. To extract even more important insights from the dataset, \\na pooling layer made up of a pooling approach is employed to \\nperform pooling on the features that the filter helped extract. To \\nconduct out-pooling, different sorts of pooling techniques are \\nemployed, such as MaxPooling, Average Pooling, and Global \\nPooling.\\nBilgesu et al\\n10. used an artificial neural network to develop an'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='filters. To extract even more important insights from the dataset, \\na pooling layer made up of a pooling approach is employed to \\nperform pooling on the features that the filter helped extract. To \\nconduct out-pooling, different sorts of pooling techniques are \\nemployed, such as MaxPooling, Average Pooling, and Global \\nPooling.\\nBilgesu et al\\n10. used an artificial neural network to develop an \\nROP model, which was dependent on several operating \\nparameters. A data of 500 points was used, with nine features, \\nwhich were tooth wear, rotary speed, torque, weight on bit, \\npump flow rate, rotating time, bearing wear, formation \\ndrillability, and formation abrasiveness. A train-test ratio of 9:1, \\nwhich implies 90% of the data was used for training and 10% for \\nvalidating the model. A coefficient of determination (\\n2R ) \\nbetween 0.902 and 0.982 was achieved after cross-validation \\nacross the data. In the work of Arabjamaloei and Shadizadeh\\n11, \\nan artificial neural network with a single hidden layer of 10 \\nneurons was developed and combined with genetic algorithm \\n(GA) to create a model to predict ROP values. There were seven \\nfeatures and 300 points (rows) in the data. The bit type, formation \\nproperties, bit operating condition (rotary speed and bit weight), \\nbit tooth wear, bit hydraulics, hydrostatic head, and equivalent \\ncirculating density were the input features. A total of 224 points \\nwere used for model training, 56 points for validation, and 20 \\npoints for testing. The generic algorithm was employed to find \\nwhere the maximum rate of penetration occurred. With a low \\nmean-square error for both training and test set, it was concluded \\nthat the neural network is valid for other data sets that fall within \\nthe range of data set used for training the model\\n12.performed a \\ncomparative evaluation of models for estimating the rate of \\npenetration (ROP) by utilizing field data from a well located in \\nIran. The model used for this study were the Bingham\\n4, Warren13'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='mean-square error for both training and test set, it was concluded \\nthat the neural network is valid for other data sets that fall within \\nthe range of data set used for training the model\\n12.performed a \\ncomparative evaluation of models for estimating the rate of \\npenetration (ROP) by utilizing field data from a well located in \\nIran. The model used for this study were the Bingham\\n4, Warren13 \\nand, Bourgoyne and Young 3 models. They carried out ROP \\npredictions on wells that were drilled with roller cone and PDC \\nbits, and comparison was carried out on three separate drilling \\nsections. However, there was a short coming of this study, in that \\nthreshold \\noBW was neglected due to lack of drill-off test been \\ncarried out. The findings of this study demonstrated that among'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='sections. However, there was a short coming of this study, in that \\nthreshold \\noBW was neglected due to lack of drill-off test been \\ncarried out. The findings of this study demonstrated that among \\nthe models examined, the Bourgoyne and Young model exhibited \\nthe highest level of predictive performance. Mahasneh\\n14 \\ndeveloped a mathematical model to predict the rate of penetration \\n(ROP) in gas wells, considering the factors of weight on bit \\n(WOB), bit rotation speed (RPM), flow rate (FR), formation \\nstrength, depth, and formation compaction. He then used his \\nmodel to optimize the drilling parameters for a gas well in \\nJordan, increasing the ROP by 15% and reducing the cost of \\ndrilling by 10%. Mahasneh\\n14’s study demonstrated the \\nimportance of drilling optimization in improving the efficiency \\nand cost-effectiveness of drilling operations. Amar and Ibrahim\\n15 \\nworked on the comparative analysis of physics-based equations \\nwith artificial neural networks (ANN). They developed two \\nneural network models to evaluate the ROP values. The input \\nparameters into the neural networks were formation depth, ECD, \\nweight on bit, DSR, pore pressure gradient, drill bit tooth wear, \\nand Reynolds number function. The physics-based equations \\nused for the comparative analysis were the Bingham\\n4 model and \\nBourgoyne and Young3 model. A comparison of the predictive \\naccuracy of the developed ANN-based models with the available \\nempirical equations showed that both ANN-based models were \\nhighly accurate for estimating the ROP as compared with the \\nempirical equations. Shi et al.\\n16predicted the rate of penetration \\n(ROP) using the Extreme Learning Machine (ELM) and Upper-\\nlayer solution-ware (USA) techniques. To construct the \\npredictive models, various input parameters such as formation \\nproperties, rig hydraulics, bit specifications, weight on bit, rotary \\nspeed, and mud properties were utilized. These input features \\nwere selected based on reservoir data from Bohai Bay, China.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='(ROP) using the Extreme Learning Machine (ELM) and Upper-\\nlayer solution-ware (USA) techniques. To construct the \\npredictive models, various input parameters such as formation \\nproperties, rig hydraulics, bit specifications, weight on bit, rotary \\nspeed, and mud properties were utilized. These input features \\nwere selected based on reservoir data from Bohai Bay, China. \\nThe performance of the developed models using ELM and USA \\ntechniques was compared with an artificial neural network \\nmodel. The accuracy of these models was evaluated using \\nmetrics such as regression coefficient (\\n2R ), mean absolute error \\n(MAE), and root mean square error ( RMSE). The findings \\nindicated that the ROP model developed with the USA technique \\nexhibited the highest predictive performance compared to the \\nother models. Additionally, it was observed that the development \\nof the ROP model using the extreme learning technique required \\nthe most time investment. Ahmed et al.\\n17 investigated the \\napplication of a support vector machine model to estimate the \\nrate of penetration in a formation containing shale materials. The \\ninput features used in the model were hinged on drilling \\nparameters and mud properties such as weight on bit, rotary \\nspeed, pump flow rate, standpipe pressure, drilling torque, mud \\ndensity, plastic viscosity, funnel viscosity, yield point and solid \\ncontent (%). The support vector machine model and the \\nBourgoyne and Youngs model were trained on more than 400 \\nreal data in shale formation using these 10 features as inputs. \\nThe two models were both compared on their predictive \\nperformance on the test data. The Bourgoyne and Young (1974) \\nmodel produced a coefficient of determination (\\n2R ) of 0.0692 \\nand an absolute percentage error of 23.41%. By applying the \\nsupport vector machine (SVM) model, a coefficient of \\ndetermination (\\n2R ) of 0.995 and an absolute percentage error of \\n2.82% were obtained. It was concluded that SVM can be used to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='performance on the test data. The Bourgoyne and Young (1974) \\nmodel produced a coefficient of determination (\\n2R ) of 0.0692 \\nand an absolute percentage error of 23.41%. By applying the \\nsupport vector machine (SVM) model, a coefficient of \\ndetermination (\\n2R ) of 0.995 and an absolute percentage error of \\n2.82% were obtained. It was concluded that SVM can be used to \\npredict ROP with higher accuracy and also generate ROP values \\nfaster than the Bourgoyne and Young\\n3 model. Elkatany 5 \\ndeveloped an artificial neural network (ANN) model to predict \\nthe rate of penetration (ROP) using data collected from three \\nvertical wells in an offshore oilfield. The ANN-ROP model was \\nobtained based on drilling parameters and drilling fluid'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 2, 'page_label': '3'}, page_content='the rate of penetration (ROP) using data collected from three \\nvertical wells in an offshore oilfield. The ANN-ROP model was \\nobtained based on drilling parameters and drilling fluid \\nproperties. Two wells were utilized for training the model, and \\nthe third well was used to evaluate the accuracy of the model.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n4\\nThe performance of the ANN-ROP model was compared to \\nother ROP models of Bingham (1965), Bourgoyne and Young\\n3, \\nand Maurer18. Elkatany5 concluded that the proposed ANN-ROP \\nmodel exhibited superior performance over others considered in \\nhis work. The training data consisted of 3333 data points and \\nyielded a coefficient of determination (\\n2R ) of 0.99, with an \\naverage absolute percentage error ( AAPE) of 5%. The test set, \\nconsisting of 2700 unseen data points from the third well, \\nresulted in the ANN-ROP model predicting the rate of penetration \\nwith \\n99. 02 =R and AAPE = 4%. Zhang et al. 19 proposed a deep \\nconvolutional neural network (CNN) model for predicting the \\nrate of penetration (ROP) during drilling operations. The authors \\nargued that existing models for predicting ROP are often \\ninaccurate and unreliable, and that deep learning methods could \\nprovide a more accurate and practical solution. They collected \\ndata from drilling operations in two different fields and used it to \\ntrain and test the proposed deep CNN model in their work. The \\nmodel consists of six convolutional layers and is trained using a \\nmean absolute percentage error (MAPE) loss function. The \\nauthors compared the performance of their deep CNN model to \\nother machine learning models and found that it outperformed \\nthese models in terms of accuracy and reliability. They also \\nconducted sensitivity analyses to determine the most important \\nfeatures for predicting ROP. They found that the weight on bit, \\nthe rotary speed, and the mud flow rate were the most important \\nfeatures for predicting ROP. Zhao et al.\\n20 focused on developing \\nmultiple artificial neural network (ANN) models for predicting \\nthe rate of penetration (ROP) using data collected from a gas \\nwell located in the southern region of Iran. A dataset comprising \\n3180 data points was obtained from various drilling sections,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='the rotary speed, and the mud flow rate were the most important \\nfeatures for predicting ROP. Zhao et al.\\n20 focused on developing \\nmultiple artificial neural network (ANN) models for predicting \\nthe rate of penetration (ROP) using data collected from a gas \\nwell located in the southern region of Iran. A dataset comprising \\n3180 data points was obtained from various drilling sections, \\ninvolving one run of a roller-cone bit and three runs of PDC bits. \\nTo construct the ANN-ROP models, several input variables were \\nconsidered, including depth, rotary speed of the bit, weight on \\nbit (WOB), shut-in pipe pressure, fluid rate, mud weight, the \\nratio of yield point to plastic viscosity, and the ratio of 10-minute \\ngel strength to 10-second gel strength. Three different training \\nfunctions, namely Levenberg-Marquardt (LM), Scaled \\nConjugate Gradient (SCG), and One-Step Secant (OSS), were \\nemployed in combination with the neural networks to estimate \\nthe penetration rates. It was concluded that the ANN-ROP model \\nutilizing the Levenberg-Marquardt (LM) function demonstrated \\nthe best prediction performance, achieving a regression \\ncoefficient (\\n2R ) of 0.91 in training and 0.89 in testing. \\nFurthermore, they also applied the Artificial Bee Colony (ABC) \\nalgorithm to optimize the ROP. The optimization process \\nresulted in an approximate improvement of 20–30% in the rate \\nof penetration. Abdulmalek et al.\\n21 carried out a comparative \\nanalysis between artificial intelligence techniques and some \\ntraditional models for ROP prediction in shaley formations. An \\nartificial neural network was developed for the ROP prediction \\nin the shale formation. The parameters considered for the \\nprediction of the rate of penetration (ROP) included torque, \\nstandpipe pressure, pump rate, mud weight, funnel and plastic \\nviscosities, solid content, and yield point. The traditional ROP \\nmodels such as those proposed by Bingham\\n4, Warren 13,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='artificial neural network was developed for the ROP prediction \\nin the shale formation. The parameters considered for the \\nprediction of the rate of penetration (ROP) included torque, \\nstandpipe pressure, pump rate, mud weight, funnel and plastic \\nviscosities, solid content, and yield point. The traditional ROP \\nmodels such as those proposed by Bingham\\n4, Warren 13, \\nBourgoyne and Young3, Maurer18 and Hareland and Hoberock22, \\nwere selected for comparison. Both the artificial neural network–\\nROP (ANN-ROP) model and the traditional models underwent \\ntraining and testing using a dataset consisting of 347 data points \\nfrom a deep shale formation in an onshore oilfield. Additionally, \\n200 new data points from an upper shale formation were utilized \\nto validate the models. The results indicated that the ANN-ROP'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='from a deep shale formation in an onshore oilfield. Additionally, \\n200 new data points from an upper shale formation were utilized \\nto validate the models. The results indicated that the ANN-ROP \\nmodel outperformed the other models in comprehending the \\nintricate relationships within the data and making accurate \\npredictions. The ANN-ROP model achieved a rate of penetration \\nprediction with an average absolute percentage error (AAPE) of \\n5.776% and a regression coefficient (\\n2R ) of 0.996. Ashrafi et \\nal.23 explored the prediction of rate of penetration (ROP) using \\nvarious optimization algorithms and neural network architectures. \\nThe optimization algorithms employed included Genetic \\nAlgorithm (GA), Particle Swarm Optimization (PSO), \\nBiogeography-based Optimizer (BBO), and Imperialist \\nCompetitive Algorithm (ICA). These algorithms were combined \\nwith different neural network architectures to develop hybrid \\nROP models. To evaluate the performance of the hybrid models, \\nthe results were compared with two other models: Non-linear \\nMultiple Regression (NLMR) and Linear Multiple Regression \\n(LMR) techniques. For the hybrid models, two popular neural \\nnetwork architectures, namely Multi-Layer Perception (MLP) \\nand Radial-Based Function (RBF), were utilized. These \\narchitectures consisted of two hidden layers with 4 and 6 \\nneurons, respectively. The activation function used in the hidden \\nlayers and output layer was tan-sigmoid. The input features were \\nweight on bit, rotational speed of the drill bit, pump inlet flow \\nrate, pore pressure pump pressure, gamma ray, density log, and \\nshear wave velocity. The dataset used for the study consisted of \\n1000 data points, collected from the Marun oilfield in Iran. It \\nwas concluded in their study that the hybrid models utilizing \\nPSO-MLP and PSO-RBF neural networks exhibited the best \\npredictive accuracy for ROP. The root mean square error (RMSE) \\nvalues for these models were 1.12 and 1.4, respectively,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='shear wave velocity. The dataset used for the study consisted of \\n1000 data points, collected from the Marun oilfield in Iran. It \\nwas concluded in their study that the hybrid models utilizing \\nPSO-MLP and PSO-RBF neural networks exhibited the best \\npredictive accuracy for ROP. The root mean square error (RMSE) \\nvalues for these models were 1.12 and 1.4, respectively, \\nindicating their superior performance compared to the other \\ndeveloped models. Iqbal\\n24 developed a mathematical model to \\npredict the rate of penetration (ROP) in drilling operations, \\nconsidering the factors of weight on bit (WOB), bit rotation \\nspeed (RPM), flow rate (FR), formation strength, depth, and \\nformation compaction. He then used his model to optimize the \\ndrilling parameters for a real-time drilling dataset from a Middle \\nEastern oil field, increasing the ROP by 10% and reducing the \\ncost of drilling by 5%. Iqbal’s study demonstrates the importance \\nof using real-time drilling parameters to optimize drilling \\noperations and provides a valuable contribution to the field of \\ndrilling engineering. Burgos et. al.\\n25 developed a convolutional \\nneural network (CNN) model to predict the rate of penetration \\n(ROP) during rotary drilling operations. The model takes in 10 \\ndrilling parameters as inputs, such as weight on bit, rotary speed, \\nflow rate, and hook load. The inputs are normalized between 0 \\nand 1. The CNN architecture consists of 3 convolutional layers \\nfollowed by 2 fully connected layers. The output layer has a \\nsingle node with a linear activation to predict the ROP value. \\nThe model was trained on data from over 600 wells. It achieved \\na mean absolute percentage error (MAPE) of 9.3% on the test \\nset, outperforming traditional machine learning models like \\nlinear regression, random forests, and support vector regression. \\nAn ablation study showed that the CNN’s ability to learn \\ncomplex non-linear relationships between the drilling parameters'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='The model was trained on data from over 600 wells. It achieved \\na mean absolute percentage error (MAPE) of 9.3% on the test \\nset, outperforming traditional machine learning models like \\nlinear regression, random forests, and support vector regression. \\nAn ablation study showed that the CNN’s ability to learn \\ncomplex non-linear relationships between the drilling parameters \\nallowed it to accurately predict ROP, whereas simply averaging \\nthe inputs did not work as well. The model was able to generalize \\nthe data from 50 additional wells, with the MAPE only increasing \\nslightly to 10.2%. This shows the model has good generalization \\nperformance. In conclusion, the CNN approach effectively \\nmodelled the complexity between drilling parameters and ROP,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 3, 'page_label': '4'}, page_content='slightly to 10.2%. This shows the model has good generalization \\nperformance. In conclusion, the CNN approach effectively \\nmodelled the complexity between drilling parameters and ROP, \\noutperformed traditional models, and generalized well to new \\ndata. This could enable more efficient drilling operations through \\naccurate ROP predictions. Monazami et al.\\n26 used an artificial \\nneural network (ANN) to predict the rate of penetration (ROP) \\nin drilling operations. The ANN model took cognizance of'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='5\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nformation strength, depth, formation compaction, pressure \\ndifferential, bit diameter, weight on bit (WOB), bit rotation \\n(RPM), and bit hydraulics. The authors evaluated the performance \\nof their ANN model on a test dataset of ROP data. They found \\nthat the model was able to predict ROP with high accuracy. The \\naverage error between the predicted and actual ROP values was \\nless than 5%. The model was able to predict ROP with high \\naccuracy, suggesting that ANN is a promising tool for optimizing \\ndrilling parameters and improving the efficiency and cost-\\neffectiveness of drilling operations. Abbas et al.\\n27 employed an \\nartificial neural network (ANN) approach to develop a \\ncomputational-based method for predicting the rate of \\npenetration (ROP). Through a thorough analysis of feature \\nselection, it was determined that out of the 25 input variables \\nexamined, 19 variables had the greatest influence on the ROP. A \\ndataset consisting of 13,125 data points from 14 deviated wells \\nin a formation located in southern Iraq was collected for the \\nstudy. The data specifically pertained to the 8 ½” production \\ncasing section, which was drilled using a drag bit and a \\nconventional bottom hole assembly (BHA) with a water-based \\nmud circulating system. It was concluded that the ROP model \\nbased on the artificial neural network, utilizing three hidden \\nlayers and employing the tan–sigmoid activation function, \\nexhibited the highest efficiency in predicting ROP. The model \\nachieved a regression coefficient of 0.92 during training and \\n0.97 during testing, with mean absolute percentage errors \\n(MAPE) of 9.1% and 8.8% in training and testing, respectively. \\nFurthermore, the model demonstrated good performance on \\nunseen data and did not exhibit overfitting issues. Miyora\\n28 \\nstudied the factors that affect the rate of penetration (ROP) in \\ngeothermal drilling and developed a mathematical model to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='0.97 during testing, with mean absolute percentage errors \\n(MAPE) of 9.1% and 8.8% in training and testing, respectively. \\nFurthermore, the model demonstrated good performance on \\nunseen data and did not exhibit overfitting issues. Miyora\\n28 \\nstudied the factors that affect the rate of penetration (ROP) in \\ngeothermal drilling and developed a mathematical model to \\npredict ROP based on these factors. The model includes \\nformation strength, depth, formation compaction, pressure \\ndifferential, bit diameter, weight on bit (WOB), bit rotation \\n(RPM), and bit hydraulics. Miyora () found that all these factors \\nhave a significant impact on ROP and used his model to optimize \\nthe drilling parameters for Well MW-17 in Menengai, Kenya, \\nincreasing the ROP by up to 20%. Al-AbdulJabbar et al.\\n29 utilized \\nan artificial neural network (ANN) in combination with self-\\nadaptive differential evolution (SADE) to predict the rate of \\npenetration (ROP) specifically in horizontal carbonate reservoirs. \\nThe model incorporated six input variables, including rotary \\nspeed, torque, weight on bit, as well as formation petrophysical \\nproperties such as gamma ray, resistivity, and bulk density data. \\nThe developed model demonstrated strong performance, \\nachieving a regression coefficient (\\n2R ) of 0.96 and a mean \\nabsolute percentage error (MAPE) of 5.12%. To further evaluate \\nthe accuracy of the model, an unseen well was used as test data. \\nThe resulting regression coefficient (\\n2R ) and MAPE values \\nwere 0.95 and 5.8%, respectively. Furthermore, their study \\naimed to enhance the interpretability of the ROP model by \\nextracting the weights and biases in a matrix form, effectively \\ntransforming it from a black box model to a white box model. \\nWang et al.\\n30 proposed a hybrid ensemble learning approach for \\npredicting the rate of penetration (ROP) during oil and gas \\ndrilling operations. They argued that existing models for \\npredicting ROP are often inaccurate and unreliable, and that'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='extracting the weights and biases in a matrix form, effectively \\ntransforming it from a black box model to a white box model. \\nWang et al.\\n30 proposed a hybrid ensemble learning approach for \\npredicting the rate of penetration (ROP) during oil and gas \\ndrilling operations. They argued that existing models for \\npredicting ROP are often inaccurate and unreliable, and that \\nensemble learning methods can provide a more accurate and \\npractical solution. They collected data from drilling operations \\nin the Gulf of Mexico and used it to train and test their hybrid \\nensemble learning model. The model consisted of several \\nmachine learning algorithms, including support vector regression \\n(SVR), random forest regression (RFR), and gradient boosting'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='ensemble learning model. The model consisted of several \\nmachine learning algorithms, including support vector regression \\n(SVR), random forest regression (RFR), and gradient boosting \\nregression (GBR), which were combined using a weighted \\naverage ensemble method. The authors compared the \\nperformance of their hybrid ensemble learning model to other \\nmachine learning models and found that it outperformed these \\nmodels in terms of accuracy and reliability. The authors also \\nconducted sensitivity analyses to determine the most important \\nfeatures for predicting ROP. They found that the weight on bit, \\nthe rotary speed, and the mud flow rate were the most important \\nfeatures for predicting ROP. Liu et al.\\n31 proposed a stacked \\ngeneralization ensemble model for predicting the rate of \\npenetration (ROP) in gas well drilling. The model is trained on a \\ndataset of historical ROP data and drilling parameters from a \\nshale gas survey well in Xinjiang, China. The model combined \\nthe predictions of six machine learning models: support vector \\nregression (SVR), extremely randomized trees (XRT), random \\nforest (RF), gradient boosting machine (GBM), light gradient \\nboosting machine (LightGBM), and extreme gradient boosting \\n(XGB). They first used Pearson correlation analysis to identify \\nthe most important features from the dataset. Then, they used a \\nSavitzky-Golay smoothing filter to reduce noise in the dataset. \\nFinally, they trained the stacked generalization ensemble model \\nusing the leave-one-out cross-validation method. The results \\nshowed that the stacked generalization ensemble model can \\nsignificantly improve the accuracy of ROP prediction. The root \\nmean square error (RMSE) of the model on the testing dataset is \\n0.4853 m/h, which is lower than the RMSE of any of the \\nindividual models. The model also has a high \\n2R value of \\n0.9568. They also used the model to optimize the ROP \\nparameters. They use particle swarm optimization (PSO) to'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='significantly improve the accuracy of ROP prediction. The root \\nmean square error (RMSE) of the model on the testing dataset is \\n0.4853 m/h, which is lower than the RMSE of any of the \\nindividual models. The model also has a high \\n2R value of \\n0.9568. They also used the model to optimize the ROP \\nparameters. They use particle swarm optimization (PSO) to \\nsearch for the optimal combination of ROP parameters. The \\nresults show that the optimized ROP parameters can significantly \\nimprove the ROP. It was thus concluded that the stacked \\ngeneralization ensemble model is a promising approach for \\npredicting ROP in gas well drilling. The model is accurate and \\ncan be used to optimize the ROP parameters. Moraveji and \\nNaderi32investigated the simultaneous effect of six variables on \\npenetration rate using real field drilling data via response surface \\nmethodology (RSM). The important variables included well \\ndepth (D), weight on bit (WOB), bit rotation speed ( N), bit jet \\nimpact force (IF), yield point, \\npY , to plastic viscosity ratio, PVR\\n, ( PVRYp ), 10 min to 10 s gel strength ratio (10MGS/10SGS). \\nEqually, bat algorithm (BA) was used to identify optimal range \\nof factors in order to maximize drilling rate of penetration. Their \\nresults indicated that the derived statistical model provides an \\nefficient tool for estimation of ROP and determining optimum \\ndrilling conditions.\\nThe aim of this study is to analyze the performance of \\nmachine learning and deep learning techniques in predicting the \\nrate of penetration during drilling, which is crucial in optimizing \\ndrilling operations. The results of this study can contribute \\nto drilling planning and optimization of future wells. Exact \\nprediction of the rate of penetration during drilling will save the \\noil and gas industry a large amount of expenses during drilling \\noperation and reduce the amount of non-productive time (NPT) \\nencountered during drilling operation.\\n1.2 Approaches to Rate of Penetration Modelling'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 4, 'page_label': '5'}, page_content='to drilling planning and optimization of future wells. Exact \\nprediction of the rate of penetration during drilling will save the \\noil and gas industry a large amount of expenses during drilling \\noperation and reduce the amount of non-productive time (NPT) \\nencountered during drilling operation.\\n1.2 Approaches to Rate of Penetration Modelling\\nOver the past few years, a large amount of research has gone \\ninto ways in which ROP can be modelled with its dependent \\ndrilling parameters (controllable and uncontrollable). A key \\ndrive that leads to further research regarding this field is the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n6\\nnon-comprehensiveness of previous models developed. This \\nis because not all of the known ROP-affecting factors have \\nbeen accounted for in a single model, which has led to poor \\naccuracy and generalizability of the estimated models\\n33. The \\nseemingly large number of factors affecting the ROP and \\nessential requirement for a model with high accuracy and \\nreliable generalization has led to development of various ROP \\nestimation models. An approach to carry out this modelling is \\nhinged on two patterns, which are physics-based approach, and \\ndata-driven approach. The physics-based approach involves \\nthe use of mathematical modelling techniques to evaluate \\nrelationships between dependent parameter (ROP) and the \\nindependent parameters, so as to estimate accurate ROP values. \\nThese mathematical relationships are developed based on the \\nphysics of the borehole. There are various models used for ROP \\nestimation that are created using the physics-based approach \\ne.g., Cunningham model, Bingham\\n4 model, Maurer 19 model, \\nMotahhari et al. model33 and Hareland and Rampersad model 34. \\nThe Cunningham model is given by:\\n          (1)\\nwhere R  is the rate of penetration (ft/h), K  the constant of \\nproportionality, 0W  the threshold weight on bit (lb f) and N  \\nrotary speed (rpm).\\nBingham4 model: \\n  (2)\\nwhere  is the weight-on bit (klb), BD  is the bit diameter \\n(in), a and b are the dimensionless constants for each rock \\nformation.\\nMaurer\\n18 model: \\n   (3)\\nwhere  is the rate of penetration (ft/h), W  the weight (Ibf), s  \\nthe confined rock strength (psi) and D the depth (ft).\\nMotahhari et al. model33: \\n  (4)\\nwhere fw  is the dimensionless wear function, G is a model \\ncoefficient related to bit-rock interactions and bit geometry, \\nα  and γ  are ROP model exponents. The bit coefficient, G, \\nis determined by the bit design, cutter size, cutter rock friction \\ncoefficient and the bit geometry. In this model, a decrease in'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='Motahhari et al. model33: \\n  (4)\\nwhere fw  is the dimensionless wear function, G is a model \\ncoefficient related to bit-rock interactions and bit geometry, \\nα  and γ  are ROP model exponents. The bit coefficient, G, \\nis determined by the bit design, cutter size, cutter rock friction \\ncoefficient and the bit geometry. In this model, a decrease in \\nthe value of the wear function, while keeping other model \\nparameters constant leads to a decrease in ROP. In the case of \\nthe bit size or compressive strength, when its value is decreased \\nan inverse occurs. The relationship between \\nN ,  and R  is \\nnon-linear. Hence, the exponents can yield an optimum value for \\n and N due to the exponential nature of the relationship.\\nHareland and Rampersad Model34: \\n    (5)\\nwhere cN  is the number of cutters and vA  the area of rock \\ncompressed ahead of a cutter (in2 ).\\nOther models used for ROP estimation are as follows:\\nBourgoyne and Young\\n3 model: \\n     (6)\\nwhere  is the weight-on bit (klb), BD  is the bit diamete r \\n(in), a and bare the dimensionless constants for each rock \\nformation.\\n Bourgoyne et al. 35 aimed at seeking to optimize the \\ncontrollable parameters during drilling operation. They proposed \\nthe development of an ROP model based on the application \\nof multiple linear regression technique. The controllable \\nparameters used in developing this model were eight: strength \\nof formation, normal compaction function, weight on bit, \\nbit teeth wear, rotary speed function, bit hydraulic function, \\ndifferential pressure function, and under compaction function. \\nThese parameters were treated as independent parameters on the \\nROP (the dependent parameter). The developed model was then \\napplied to estimate ROP for wells drilled vertically using roller \\ncone bits, and it was concluded that the application of the ROP \\nmodel could help reduce drilling operational cost by 10%. On \\ninception, the model was basically created for modelling ROP'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='These parameters were treated as independent parameters on the \\nROP (the dependent parameter). The developed model was then \\napplied to estimate ROP for wells drilled vertically using roller \\ncone bits, and it was concluded that the application of the ROP \\nmodel could help reduce drilling operational cost by 10%. On \\ninception, the model was basically created for modelling ROP \\nfor roller cone bits, but overtime has also shown effectiveness \\nin modelling ROP for PDC bits. The Bourgoyne et al.\\n35 model \\nis given by:\\n∏\\n=\\n=\\n8\\n1i\\niFR            (7)\\nwhere )( 1\\n1\\naeF =  is the formation strength function for \\nBourgyone and Young model, ( )[ ] DaeF −= 10000\\n2\\n2 the normal \\ncompaction function for Bourgyone and Young model, \\n the under compaction function'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='1\\naeF =  is the formation strength function for \\nBourgyone and Young model, ( )[ ] DaeF −= 10000\\n2\\n2 the normal \\ncompaction function for Bourgyone and Young model, \\n the under compaction function \\nfor Bourgyone and Young model, ( )[ ]{ } cpg D aF ρ−= 44 exp  the \\npressure differential function for Bourgyone and Young model, \\n( ) ( )\\n( ) \\uf8fa\\n\\uf8fa\\n\\uf8fb\\n\\uf8f9\\n\\uf8ef\\n\\uf8ef\\n\\uf8f0\\n\\uf8ee\\n\\uf8f4\\n\\uf8fe\\n\\uf8f4\\n\\uf8fd\\n\\uf8fc\\n\\uf8f4\\n\\uf8f3\\n\\uf8f4\\n\\uf8f2\\n\\uf8f1\\n\\uf8fa\\n\\uf8fb\\n\\uf8f9\\n\\uf8ef\\n\\uf8f0\\n\\uf8ee\\n−\\n−=\\nt\\nt\\nd w\\nd wd wInaF 4exp 55  the weight on bit function \\nfor Bourgyone and Young model, \\nthe r otary speed function for Bourgyone and Young model, \\n( )[ ]{ } haF −= 77 exp  the bit tooth wear function for Bourgyone \\nand Young model and \\n  the bit hydraulic \\nfunction for Bourgyone and Young model.\\n The physics-based approach has limitations due to the failure \\nto consider all the parameters affecting the drilling operation and \\nin the choice of an empirical constant for the ROP estimation \\nwith respect to the well/borehole in operation. This gave rise \\nto the use of data-driven approaches, which make use of data \\ngenerated during drilling (Logging While Drilling (LWD)) \\nand artificial intelligence techniques for ROP estimation\\n17. The \\napplication of AI models for ROP estimation was suggested by \\nBilgesu et al.\\n10, so as to get over the weakness of the physics-\\nbased approach and improve the accuracy of ROP predictability. \\n2. Methodology\\n2.1 Methods\\nFigure 3 shows the proposed methodology, adopted in this \\nstudy.\\n2.2 Data Collection\\nThe data utilized for this study was obtained from the Daily \\nDrilling Report (DDR) for an oil well in Nigeria. It contains \\nparameters that ROP depends on, which will help make a robust \\nmodel. Such parameters are weight on bit, pump flow rate, mud \\nweight, mud type, drill bit diameter and wellbore trajectory, \\namongst others. After data collection, the uncertainties within \\nthe dataset and the suitable parameters are defined. This leads \\nto filtration of the dataset. The well contains data of 27 columns'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 5, 'page_label': '6'}, page_content='parameters that ROP depends on, which will help make a robust \\nmodel. Such parameters are weight on bit, pump flow rate, mud \\nweight, mud type, drill bit diameter and wellbore trajectory, \\namongst others. After data collection, the uncertainties within \\nthe dataset and the suitable parameters are defined. This leads \\nto filtration of the dataset. The well contains data of 27 columns \\n(the number of variables), 17280 rows, 0% missing cells, and \\n0% duplicate rows.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='7\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\n2.3 Data Processing\\nThe data preprocessing phase is also known as Feature \\nEngineering Phase. The data set used for the study is subjected to \\nvarious statistical manipulations and transformations in order to \\nextract relationships and insights between parameters in the data \\nand, process the data into forms that are more understandable \\nby the algorithms, hence, producing better model performances. \\nSuch techniques include exploratory data analysis, missing \\ndata imputation, outlier handling, feature scaling, variable \\ntransformation, and discretization, amongst others. These \\nprocesses help the model match key relationships between the \\ninput parameters and the target variable. In this study, the data \\npreprocessing techniques used were outlier handling, variable \\ntransformation and feature scaling.\\nOutlier handling: This refers to the process involved in dealing \\nwith outliers found in a dataset. Outliers are simply data point \\nthat vary significantly to majority of the dataset. Outliers must \\nbe dealt with since they can significantly affect the outcomes \\nand precision of statistical models. Outlier treatment can be done \\nin a number of ways, such as by removing outliers, capping, \\nor imputing more representative values. The method utilized in \\nthis study was the capping technique, which involved imputing \\nthe interquartile range of the variable with the outlier where the \\noutliers are in the variable. Figures 4 and \\n5 show the box plot of \\nROP data before and after outlier.\\nFigure 4: Box plot of ROP data before outlier.\\nVariable Transformation: This technique was employed in \\nthis study to treat the variables that were skewed either to the \\nleft or to the right. It involves changing a variable’s scale or \\ndistribution to satisfy requirements or enhance the performance \\nof statistical models. This preprocessing technique was \\nperformed on variables that were skewed either to the left or'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='Variable Transformation: This technique was employed in \\nthis study to treat the variables that were skewed either to the \\nleft or to the right. It involves changing a variable’s scale or \\ndistribution to satisfy requirements or enhance the performance \\nof statistical models. This preprocessing technique was \\nperformed on variables that were skewed either to the left or \\nright, so as to equalize variances and establish linearization \\namong the variables, which makes it easier to interpret and \\nmodel. The variable transformation technique use in this study \\nwere LogTransformer and BoxCoxTransformer.\\nFigure 5: Box plot of ROP data after outlier removal. removal.\\nFeature Scaling: This involves changing the scale of \\nnumerical features in a dataset. To make the features similar and \\nprevent some from predominating others based only on their \\ninitial scale, the range or distribution of the features must be \\nchanged. This preprocessing technique is so important as it helps \\nthe machine learning models to better understand the features as \\nthey will usually be within the range of 0 to 1, which the models \\nusually prefer. For some particular models, it is a necessary \\nrequirement to perform feature scaling on the dataset before \\npassing it into them e.g., ANN and CNN, while some models \\nare not influenced when the dataset is scaled or not e.g., Random \\nForest and Extra Trees. There are many types of Feature scaling \\ntechniques e.g., Standard Scaler, MinMax Scaler and Robust \\nscaling. Each of these techniques has their rules of engagement, \\nso as to get better model performance. These rules depend on \\ndataset and model to be used. In this study, the standard scaler \\nwas utilized so as to scale features to have a mean of 0 and a \\nstandard deviation of 1. \\nTable 1 shows the features definition \\nwith the data types used. \\nTable 1: Features definition, unit, and data types.\\nFeature Definition Units Data type\\nDepth The actual depth at which the drilling \\nis taking place.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='dataset and model to be used. In this study, the standard scaler \\nwas utilized so as to scale features to have a mean of 0 and a \\nstandard deviation of 1. \\nTable 1 shows the features definition \\nwith the data types used. \\nTable 1: Features definition, unit, and data types.\\nFeature Definition Units Data type\\nDepth The actual depth at which the drilling \\nis taking place.\\nm Numerical\\nLag Depth Time delay or lag between the mea -\\nsured depth and the corresponding \\nROP value.\\nm Numerical\\nWHO Weight on String. klb Numerical\\nROP Rate of Penetration. m/h Numerical\\nRPM  \\nTURBIN\\nTurbine Speed. rev/\\nmin\\nNumerical\\nTorque Rotational force of drill string. klb.ft Numerical\\nSPP Standpipe Pressure. psi Numerical\\nFlow Inflow rate of drilling. fluid pumped into'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 6, 'page_label': '7'}, page_content='RPM  \\nTURBIN\\nTurbine Speed. rev/\\nmin\\nNumerical\\nTorque Rotational force of drill string. klb.ft Numerical\\nSPP Standpipe Pressure. psi Numerical\\nFlow Inflow rate of drilling. fluid pumped into \\nthe wellbore during drilling.\\ngpm Numerical\\nMw In total volume of drilling mud pumped \\ninto the wellbore during a specific pe-\\nriod of time.\\npcf Numerical\\nMw out total volume of drilling mud pumped \\nout of a wellbore during a specific pe-\\nriod of time.\\npcf Numerical\\nPIT#1 mud pit volume in the first mud pit or \\nmud tank.\\nBbl Numerical\\nPIT#2 mud pit volume in the second mud pit \\nor mud tank.\\nBbl Numerical'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n8\\nPIT#3 mud pit volume in the third mud pit \\nor mud tank.\\nBbl Numerical\\nPIT#4 mud pit volume in the fourth mud pit \\nor mud tank.\\nBbl Numerical\\nPIT#5 mud pit volume in the fifth mud pit or \\nmud tank.\\nBbl Numerical\\nPIT#6 mud pit volume in the Sixth mud pit \\nor mud tank.\\nBbl Numerical\\nTOT ACT Total Actual Time. Bbl Numerical\\nSteel V ol-\\nume\\nThe volume of steel that is used or \\nconsumed during the drilling process.\\nBbl Numerical\\nOver pull Additional force applied to the drilling \\nassembly in order to increase the drill-\\ning efficiency. \\nklb Numerical\\nFlow Pad-\\ndle\\nPercentage of drilling fluid that cir -\\nculates through the wellbore during \\ndrilling.\\n% Numerical\\nBit Posi -\\ntion\\nIt refers to the vertical depth at which \\nthe drilling bit is located within the \\nwellbore.\\nm Numerical\\nHook Po -\\nsition\\nVertical position of the drilling hook \\nor traveling block.\\nm Numerical\\nString  \\nWeight\\nTotal weight of the drill string, includ-\\ning the drill pipe, bottom hole assem -\\nbly (BHA), and any other components \\nattached to it.\\nklb Numerical\\nDrag Resistance encountered by the drill \\nstring and drill bit as they are ad-\\nvanced through the formation.\\nklb Numerical\\nTable 2 gives information on the statistic of ROP variable.\\nTable 2: Descriptive Statistics of ROP variable.\\nStatistic Mean Standard \\ndeviation\\nMini -\\nmum\\n25% 50% 75% Maxi -\\nmum\\nROP 3.964 4.317 0.000 0.000 2.880 7.410 18.525\\nTable 3 gives the Pearson correlation of the oil well features and \\ntheir values.\\nTable 3: Pearson correlation of features with rate of penetration.\\nFeatures Well data\\nDepth -0.37\\nLag depth 0.98\\nWHO 0.15\\nRPM TURBIN0.57\\nTorque 0.70\\nSPP 0.64\\nFlow in 0.57\\nMw in -0.08\\nMw out 0.20\\nPIT#1 0.24\\nPIT#2 -0.14\\nPIT#3 -0.10\\nPIT#4 -0.26\\nPIT#5 0.05\\nPIT#6 0.23\\nTOT ACT-0.25\\nSteel volume 0.20\\nFlow paddle 0.75\\nBit position 0.20\\nHook position 0.26\\nString eight -0.01\\nDrag -0.53\\nThe correlation heat map of the well data is depicted in \\nFigure 6.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 7, 'page_label': '8'}, page_content='Features Well data\\nDepth -0.37\\nLag depth 0.98\\nWHO 0.15\\nRPM TURBIN0.57\\nTorque 0.70\\nSPP 0.64\\nFlow in 0.57\\nMw in -0.08\\nMw out 0.20\\nPIT#1 0.24\\nPIT#2 -0.14\\nPIT#3 -0.10\\nPIT#4 -0.26\\nPIT#5 0.05\\nPIT#6 0.23\\nTOT ACT-0.25\\nSteel volume 0.20\\nFlow paddle 0.75\\nBit position 0.20\\nHook position 0.26\\nString eight -0.01\\nDrag -0.53\\nThe correlation heat map of the well data is depicted in \\nFigure 6.\\nFigure 6: Correlation heat map of the well data.\\n2.4 Feature Selection\\nThe defined input parameters from the dataset must pass \\nthrough the feature selection phase. The feature selection is \\nthe process of selecting a subset of relevant features (variable, \\npredictors) for usage in building machine learning algorithms. It \\ninvolves selecting the pool of features that has significant impact \\non making prediction with the machine learning algorithm. It is \\na crucial phase, in the bid that a good machine learning model \\nis developed. The feature selection algorithms are divided into \\nthree main categories: filter, wrapper, and embedded methods. \\nThe feature selection helps a user to better interpret the model \\ne.g., a model of 10 input parameters is much easier to interpret \\nthan that of 100 parameters. It also shortens training time for \\nthe machine learning algorithm and enhances generalization \\nby reducing overfitting. In this study, a filter method known \\nas mutual information was used to select optimal features for \\nmodel building. Mutual information is a statistical measure of \\nthe mutual dependence of 2 variables. In other words, mutual \\ninformation quantifies the amount of information gained about \\none random variable through observing another random variable. \\nThe mutual information algorithm is given by: \\n{ }∑∑ ××= )]() (/[) , (log) , () ; ( y px pyx py x pYX I  (8)\\nwhere I is the ranking score, X  and Ythe respective input and'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='9\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\noutput nodes, x and y are the dependent and target variables \\nrespectively.\\nThe algorithm selects the highest-ranking features that best \\ndescribes the target variable and separates them into percentiles \\ne.g., 10th, 20 th, 30 th etc., depending on the highest ranking. In \\nthis study, the features in the top 50 th (50 percentile), which \\ntranslated to 13 features out of the possible 27, were selected to \\nbe used to the build the machine learning models. The features \\nselected after future selection are depth, lag depth, WOB, SPP, \\nMW IN, PIT#2, PIT#3, PIT#4, PIT#6, TOT ACT, steel volume, \\nbit position and hunk position \\n2.5 Data Splitting\\nData splitting (otherwise known as cross validation) is a \\nprocess utilized in the building of artificial intelligence models. \\nHere, data is partitioned into two or more ways to enable the \\nmodel identify the patterns within the data set and predict its \\nperformance on unseen (real world) data. Two sets of the dataset \\nare created: a training set and a testing set. The training set is \\nused to train the artificial intelligence model on the data while \\nthe testing set is used to assess the model’s performance in real \\nworld scenarios. This is because there is a probability that the \\nbuilt model may not be robust enough to perform successfully on \\nunknown (real world) data. There are various methods used for \\ncross validation operation viz. holdout method, K-fold method, \\nStratified K-fold method, Leave One-Out method, amongst \\nothers. The K-fold cross validation technique was implemented \\nin this study using the Python Sklearn package.\\nA 60:40 split of the oil well data was made into train and \\ntest sets. There are 10368 rows and 13 columns in the training \\nset and 6912 rows and 13 columns in the test set. The training \\nresults were obtained by training the model on the train data \\nand using the resulting model to predict the training set. The'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='in this study using the Python Sklearn package.\\nA 60:40 split of the oil well data was made into train and \\ntest sets. There are 10368 rows and 13 columns in the training \\nset and 6912 rows and 13 columns in the test set. The training \\nresults were obtained by training the model on the train data \\nand using the resulting model to predict the training set. The \\ntest results were obtained by training the model on the train set \\nbefore predicting the test set.\\n3. Model Development and Training\\nSeven machine learning techniques were analyzed in this \\nwork, to be trained to make predictions of the rate of penetration \\nfor the oil well. The machine learning models that were employed \\nfor this analysis are outlined as follows and their written codes \\ncan be found in the Appendix.\\n3.1 Random Forest Regression\\nRandom forest can be applied to both classification and \\nregression problems. It is an ensemble learning technique that \\ncreates a large number of decision trees during training period \\nand utilizes averaging to improve the prediction accuracy \\nand control over-fitting. Random forests are widely used for \\napplications (such as credit scoring and spam filtering) because \\nthey can handle both categorical and continuous data. During \\ntraining, random forests create a lot of decision trees\\n36. Each \\ntree is constructed using a random subset of the features and \\na sample of the training data. The individual decision trees \\npredictions are combined by the random forest algorithm to \\nprovide a prediction. For a wide range of applications, random \\nforests are a potent and useful machine learning technique. They \\nare often good performers and are quite simple to teach and tune.\\n A schematic of the decision tree regression is depicted in \\nFigure. 7.\\nFigure 7: Decision tree regression schematic37.\\nA random forest model works by training multiple decision \\ntrees in parallel and uses a bagging technique to obtain a robust'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='forests are a potent and useful machine learning technique. They \\nare often good performers and are quite simple to teach and tune.\\n A schematic of the decision tree regression is depicted in \\nFigure. 7.\\nFigure 7: Decision tree regression schematic37.\\nA random forest model works by training multiple decision \\ntrees in parallel and uses a bagging technique to obtain a robust \\nmodel. Usually, machine learning models have hyperparameters, \\nthat is, parameters in the algorithm that are constant throughout \\ntraining that help the algorithm better understand the data \\npatterns. Hyperparameters in random forest algorithm include \\nmax_depth, max_features, min_samples_leaf, min_samples_\\nsplit, n_estimators. To obtain optimal performance of the \\nrandom forest algorithm, optimal values must be selected for'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='max_depth, max_features, min_samples_leaf, min_samples_\\nsplit, n_estimators. To obtain optimal performance of the \\nrandom forest algorithm, optimal values must be selected for \\nthese hyperparameters. To get the optimal values of the random \\nforest algorithm, a hyperparameter search algorithm (known as \\nthe randomized search algorithm) must be used. This algorithm \\nhelps to generate the optimal hyperparameter value for the \\nhyperparameter to be utilized in the model. After implementing \\nrandomized search algorithm on the well data, the optimal value \\nof the hyperparameters were max_depth = 31, max_features \\n= sqrt, min_samples_leaf = 3, min_samples_split = 13, n_\\nestimators = 666.\\n3.2 Linear Regression\\nLinear regression is a supervised method of machine learning \\nthat uses one or more input features to predict a continuous target \\nvariable. It is assumed that there is a linear relationship between \\nthe input variables and the goal variables. Linear regression \\nis intended to establish the optimal line according to the data, \\nminimizing the difference in predicted and real values. The \\nalgorithm operates by generating the coefficients of the line’s \\nlinear equation. Some hyperparameters in linear regression \\nare copy_X and fit_Intercept. After implementing randomized \\nsearch algorithm on the well data using linear regression as \\nthe base model, the optimal value of the hyperparameters were \\ncopy_X = True, and fit_Intercept = True. \\n3.3 KNearest Neighbor\\nKNearest Neighbor (KNN), as shown in Figure 8, is a \\nsupervised model-based machine learning technique that can \\nbe applied to both classification and regression models. KNN is \\nnot a parametric algorithm, meaning that it does not make any \\nassumptions about the distribution of data. The KNN method \\nis based on the hypothesis that similar occurrences will share \\nsimilar labels. The KNN technique identifies the K closest \\nneighbors to a given data point by reference to a distance metric,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 8, 'page_label': '9'}, page_content='be applied to both classification and regression models. KNN is \\nnot a parametric algorithm, meaning that it does not make any \\nassumptions about the distribution of data. The KNN method \\nis based on the hypothesis that similar occurrences will share \\nsimilar labels. The KNN technique identifies the K closest \\nneighbors to a given data point by reference to a distance metric, \\ntypically Euclidean, and assigns the label to the majority of these \\nK neighbors for a given data point. When the algorithm is doing \\na regression, it takes the weighted average of all the target values \\nfrom the K neighbor and uses it to predict the new value for the \\ngiven data point. The number of neighbors is a hyperparameter \\nthat can be changed. Some hyperparameters in KNN algorithms \\nare algorithm, leaf_size, p, weights, and n_neighbours. After'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n10\\nimplementing randomized search algorithm on the well data \\nusing KNearest neighbor as the base model, the optimal value of \\nthe hyperparameters were algorithm= auto, leaf_size = 10, p = 1, \\nweights = distance and n_neighbours = 3.\\nFigure 8: KNearest Neighbor38.\\nFigure 9: SVM schematic39.\\n3.4 Support Vector Machine Regression\\nSupport vector machine (SVM) regression is a supervised \\nlearning algorithm that is primarily used in classification tasks. \\nIt is derived from the concepts of support vector machines \\n(SVM), as shown in Figure 9. The goal of SVM regression is \\nto identify a function that best matches the relationship between \\nthe input and target variables. The SVM regression generates a \\nhigh-dimensional hyperplane with each data point as a feature \\nvector in the hyperplane space. The objective of the algorithm \\nis to find the hyperplane with the greatest margin, i.e., the \\ndistance from the hyperplane to the nearest data point in each \\nclass. In the regression case, SVM chooses the hyperplane that \\ncontains the most data points within the given range. The range \\nis the margin of tolerance, which allows some data points to fall \\noutside of the range. The support vectors are the data points that \\nfall within or cross the range. Some hyperparameters in support \\nvector regression algorithm are C, epsilon, and kernel. After \\nthe implementation of the randomized search algorithm on the \\nwell data using support vector regression algorithm as the base \\nmodel, the optimal values of the hyperparameters were C = 10, \\nepsilon = 1 and kernel = rbf. \\n3.5 Stacking Technique\\nStacking is a type of machine learning technique, whose \\nalgorithm is shown in Figure 10, that uses the predictive power of \\ndifferent machine learning algorithms to make better predictions \\non datasets. The stacking technique typically involves the use \\nof base models and a meta model. The base models are usually'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='epsilon = 1 and kernel = rbf. \\n3.5 Stacking Technique\\nStacking is a type of machine learning technique, whose \\nalgorithm is shown in Figure 10, that uses the predictive power of \\ndifferent machine learning algorithms to make better predictions \\non datasets. The stacking technique typically involves the use \\nof base models and a meta model. The base models are usually \\ncommon machine learning algorithms such as decision trees, \\nrandom forests, and support vector machines. These base models \\nare trained on a dataset and are used to make predictions; these \\npredictions are then combined in a meta model, which can be \\nlinear regression or a neural network to make final predictions. \\nIt is a powerful machine learning technique since it utilizes the \\ndiverse knowledge of the base models. The base models used for \\nthis study are random forests, or support vector machines, linear \\nregression, and nearest neighbors, while the meta model used is \\nthe linear regression model.\\nFigure 10: Stacking algorithm 40.\\n3.6 Voting Technique\\nV oting is a machine learning technique that involves the \\nintegration of predictions from multiple independent models to \\nform a final prediction, as shown in Figure 11. \\nFigure 11: V oting Algorithm (LevelUpCoding).\\nV oting technique is commonly referred to as ensemble \\nvoting, or majority voting, and is based on the principle that the \\nintegration of the opinions of multiple models can often lead \\nto greater prediction accuracy than the use of a single model. \\nUnder the V oting algorithm, each base model is trained on \\nthe same data set, but with different algorithms or settings. \\nDuring the prediction phase, each base model makes its own \\nprediction based on the data it has been trained on. Finally, the \\nfinal prediction is calculated by adding up all the predictions \\nusing a voting system. The base models used for this study are \\nrandom forests, or support vector machines, linear regression,'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='the same data set, but with different algorithms or settings. \\nDuring the prediction phase, each base model makes its own \\nprediction based on the data it has been trained on. Finally, the \\nfinal prediction is calculated by adding up all the predictions \\nusing a voting system. The base models used for this study are \\nrandom forests, or support vector machines, linear regression, \\nand nearest neighbors, while the meta model used is the linear \\nregression model.\\n3.7 Convolutional Neural Network\\nConvolution Neural Networks (CNNs) are a type of deep \\nlearning algorithm that is commonly employed in the analysis \\nand interpretation of visual data, including images and videos. \\nCNNs are widely used for image classification, object recognition \\nand image segmentation. However, not only can CNNs be used'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 9, 'page_label': '10'}, page_content='and interpretation of visual data, including images and videos. \\nCNNs are widely used for image classification, object recognition \\nand image segmentation. However, not only can CNNs be used \\nfor image classification, but they can also be used in regression-\\nbased projects, where it is purposed to predict continuous \\nvariables. A convolution neural network (CNN) usually consists \\nof four components: convolutional layers, pooling layers, fully \\nconnected layers, and output layers, as shown in Figure 12. \\nThese four components usually make for the architecture of \\nCNNs. The main difference between a CNN and a regression-\\nbased CNN is the output layer (output layer) and loss function \\n(loss function). The output layer in a CNN based on regression is \\ndistinct from that of a Softmax-based CNN. Instead of predicting \\nclass probabilities using a function of a Softmax, an output layer \\nis typically composed of an individual neuron with a function'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='11\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nof a linear activation. This allows the network to produce a \\ncontinuous value immediately as a regression prediction. For \\nregression tasks, a loss function is often used to measure the \\ndifference between predicted and actual target values. Examples \\nof loss functions that are commonly used include MSE (mean \\nsquared error) and MAE (mean absolute error). \\nFigure 12: Convolutional neural network39.\\n3.8 Model Evaluation\\nThere are metrics usually used to reflect how well the \\nmodel has learnt patterns in the data and the performance of the \\nmodel on the unseen (test) data set. There are metrics used for \\nevaluating the performance of \\nmachine learning models. These \\nmetrics show how far a model’s prediction is from the true \\nvalues. In this study, four error metrics are used to estimate a \\nmodel performance on the learning patterns in the dataset and \\nunseen data (test data). They are the mean absolute error (MAE), \\nroot mean squared error (RMSE), mean squared error (MSE) and \\ncoefficient of determination,\\n2R –score, given by Equations (9) \\nto (12) respectively. \\n∑\\n=\\n−=\\nn\\ni\\ni\\nn\\nyyMAE\\n1\\nˆ              (9)\\n( )∑\\n=\\n−=\\nn\\ni\\ni\\nn\\nyyRMSE\\n1\\n2\\nˆ        (10)\\n∑\\n=\\n−=\\nn\\ni i\\ni\\ny\\nyy\\nnMSE\\n1\\nˆ1               (11)\\n( )\\n( )∑\\n∑\\n=\\n=\\n−\\n−\\n= n\\ni\\ni\\nn\\ni\\nyy\\nyy\\nR\\n1\\n2\\n1\\n2\\n2\\nˆ\\n           (12)\\nwhere yˆ , iy  and y  are the respective predicted, actual and \\nmean values and n the number of observations.\\n4. Results and Discussion\\nThe well data after carrying out various statistical analyses, \\nthe features were reduced from the previous 27 columns to 13 \\ncolumns, , as displayed in Table 4, which is an excerpt of the well \\ndata used for both training and testing. It shows a sample of the \\ndata utilized after feature selection has been carried out, leaving \\n17280 rows and 13 columns. These data were then separated \\nusing cross validation to train and test data respectively. The \\ntrain data contained 10368 rows and 13 columns, while the test'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='columns, , as displayed in Table 4, which is an excerpt of the well \\ndata used for both training and testing. It shows a sample of the \\ndata utilized after feature selection has been carried out, leaving \\n17280 rows and 13 columns. These data were then separated \\nusing cross validation to train and test data respectively. The \\ntrain data contained 10368 rows and 13 columns, while the test \\ndata contained 6912 rows and 13 columns. The linear regression \\nmodel was applied to the training data and test data after the \\noptimal hyperparameters had been generated. The train and \\ntest data were standardized such that data has a mean of 0 and \\nstandard deviation of 1. The results obtained using the linear \\nregression model are presented in Table 5.\\nThe random forest regression, KNearest neighbor, and \\nsupport vector regression (SVR) model were applied to the \\ntraining data and test data after the optimal hyperparameters had \\nbeen generated using the randomized search cv algorithm. The \\ntrain and test data were standardized such that data has a mean \\nof 0 and standard deviation of 1. The random forest, KNearest \\nneighbor, and support vector regression (SVR) models’ results \\nare presented in Tables 6–8 respectively.\\nEqually, the stacking and voting techniques were applied to \\nthe training data and test data after the optimal hyperparameters \\nhad been generated using the randomized search cv algorithm \\nfor the base model used in the technique. The train and test data \\nwere standardized such that data has a mean of 0 and standard \\ndeviation of 1. The results obtained using the stacking and voting \\ntechniques are presented in Tables 9 and 10 respectively.\\nThe convolutional neural network (CNN) model was applied \\nto the training data and test data using an epoch of 120 and a batch \\nsize of 32 together with an output layer of 1. The architecture of \\nthe CNN model created is as follows: two 1–D (one dimensional \\nconvolutional layers), filters (32 and 64), kernel size of two, one'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='techniques are presented in Tables 9 and 10 respectively.\\nThe convolutional neural network (CNN) model was applied \\nto the training data and test data using an epoch of 120 and a batch \\nsize of 32 together with an output layer of 1. The architecture of \\nthe CNN model created is as follows: two 1–D (one dimensional \\nconvolutional layers), filters (32 and 64), kernel size of two, one \\nGlobal MaxPooling Layer, 5 hidden layers and 1 output layer. \\nThe train and test data were standardized such that data has a \\nmean of 0 and standard deviation of 1. The results obtained \\nusing the CNN model are presented in Table 11.\\nTable 4: Sample taken from well data used to build ML models.\\nTable 5: Linear regression model results.\\nError metric Training data Test data\\nRMSE 2.611 2.565'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 10, 'page_label': '11'}, page_content='Table 4: Sample taken from well data used to build ML models.\\nTable 5: Linear regression model results.\\nError metric Training data Test data\\nRMSE 2.611 2.565\\nMSE 6.819 6.582\\nMAE 1.773 1.744\\n2R  Score 0.639 0.639\\nTable 6: Random Forest model results.\\nError Metric Training Data Test Data\\nRMSE 0.469 0.676\\nMSE 0.220 0.458\\nMAE 0.207 0.300\\nScore \\n2R\\n0.988 0.975\\nTable 7: KNearest neighbor model results.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n12\\nError Metric Training Data Test Data\\nRMSE 0.523 0.724\\nMSE 0.309 0.524\\nMAE 0.201 0.239\\nScore\\n 2R\\n0.984 0.971\\nTable 8: SVM model results.\\nError Metric Training Data Test Data\\nRMSE 1.724 1.669\\nMSE 2.972 2.784\\nMAE 0.841 0.832\\nScore 0.843 0.847\\nTable 9: Stacking technique results.\\nError Metric Training Data Test Data\\nRMSE 0.306 0.548\\nMSE 0.033 0.423\\nMAE 0.094 0.300\\nScore \\n2R\\n0.98 0.976\\nTable 10: V oting Technique results.\\nError Metric Training Data Test Data\\nRMSE 0.803 0.826\\nMSE 1.167 1.331\\nMAE 0.646 0.681\\nScore \\n2R\\n0.938 0.926\\nTable 11: CNN results.\\nError Metric Training Data Test Data\\nRMSE 0.797 0.751\\nMSE 1.167 1.331\\nMAE 0.636 0.564\\nScore \\n2R\\n0.924 0.928\\n From the results displayed in Tables 5–11, the stacking \\ntechnique performed better than all the models and techniques \\nemployed in this study for the training data. Hence, the decreasing \\norder of performance of the models for the training data is as \\nfollows: stacking technique > random forest model > KNearest \\nneighbor model > CNN model > V oting technique > SVR model \\n> linear regression model. In terms of the RMSE, the stacking \\ntechnique was 35% better than the random forest model, 41% \\nbetter than the KNearest neighbor model, 62% better than the \\nCNN model and V oting technique, 82% better than the SVR \\nmodel and 88% better than the linear regression model. In terms \\nof the MAE, the stacking technique was 55% better than the \\nRandom Forest model, 53% better than the KNearest Neighbour \\nmodel, 85% better than the CNN model and V oting technique, \\n89% better than the SVR model and 95% better than the linear \\nregression model.\\nFor the testing data, generalizing across the four metrics, \\nthe stacking technique yet again out-performed other models. It \\nwas only in terms of the MAE that the KNearest neighbor model \\noutperformed the stacking technique by 20%, but in terms of the \\nRMSE, MSE, \\n2R  Score, the stacking technique outperformed'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='89% better than the SVR model and 95% better than the linear \\nregression model.\\nFor the testing data, generalizing across the four metrics, \\nthe stacking technique yet again out-performed other models. It \\nwas only in terms of the MAE that the KNearest neighbor model \\noutperformed the stacking technique by 20%, but in terms of the \\nRMSE, MSE, \\n2R  Score, the stacking technique outperformed \\nthe KNearest Neighbour model. SVR model and linear \\nregression model performed better on the test data compared to \\ntheir performances on the train data, indicating generalization of \\nthe models and lack of overfitting on the training data.\\nIn terms of the test (unseen) data, the stacking technique \\nperformed better than all the traditional ML models employed \\nin this study. The next to it on the ranking of the model that \\nbest performed on the test data was the Random Forest model, \\nfollowed by the KNearest Neighbour model, then the CNN \\nmodel, then the V oting technique, then the SVR model and lastly \\nthe linear regression model. \\nIn terms of the RMSE, the stacking technique was 19% better \\nthan the Random Forest model, 24% better than the KNearest \\nNeighbour model, 27% better than the CNN model, 34% better \\nthan the V oting technique, 67% better than the SVR model and \\n79% better than the linear regression model.\\nIn terms of the MAE, the stacking technique and the Random \\nForest model had the same performance score of 0.30. The \\nstacking technique was still 47% better than the CNN model, \\n56% better than the V oting technique, 64% better than the SVR \\nmodel and 83% better than the linear regression model.\\nOur findings in this investigation that the complex ML models \\nof Stacking, V oting and CNN have the capacity to perform better \\nthan the traditional ML model was buttressed in the work of \\nBurgos et al, which was equally corroborated in the study of \\nZhang et. al.\\n19, where the CNN model developed outperformed'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='model and 83% better than the linear regression model.\\nOur findings in this investigation that the complex ML models \\nof Stacking, V oting and CNN have the capacity to perform better \\nthan the traditional ML model was buttressed in the work of \\nBurgos et al, which was equally corroborated in the study of \\nZhang et. al.\\n19, where the CNN model developed outperformed \\nall the traditional ML models in terms of accuracy and reliability. \\nIt can equally be deduced from this study that irrespective of the \\narchitecture and predictive capacity of the ML model, traditional \\nML models, with proper feature engineering and hyperparameter \\ntuning, can perform better than more complex machine learning \\nmodels.\\n5. Conclusions\\nA comparative analysis of machine learning algorithms in \\npredicting rate of penetration during drilling was carried out in'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 11, 'page_label': '12'}, page_content='models.\\n5. Conclusions\\nA comparative analysis of machine learning algorithms in \\npredicting rate of penetration during drilling was carried out in \\nthis study. Data was obtained from the Daily Drilling Report \\n(DDR) for an oil well. The well contains data of 17280 rows \\nand 27 columns. The data preprocessing techniques of outlier \\nhandling, variable transformation and feature scaling were \\nemployed. Each of the seven machine learning techniques \\nemployed to predict the rate of penetration during drilling was \\nable to extract meaningful information and patterns from the oil \\nwell data. However, some models outperformed other models by \\na distance, which reflects the predictive power of the algorithms. \\nThe capacity of the stacking algorithm to combine the predictive \\npower of each base model gave it an edge over the rest of the \\nmodels. The voting technique performed well, but not measured \\nup to the performance of the stacking technique. Hence, the \\nstacking technique is a more powerful ensembling technique \\nthan the voting technique. Amongst the base models, the random \\nforest and KNearest Neighbors models are robust since they \\nperformed well on both the train and test data, while the SVM \\nand linear regression models gave the highest errors on both \\nthe train and test data but they also showed their generalization \\ncapability and lower tendency to overfit. The CNN model has \\nthe capacity to perform well on regression-based task like rate \\nof penetration predictions since it performed well on the test and \\ntrain data.\\nStatements and Declarations'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='13\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nConflict of interest The authors declare that there is no conflict \\nof interest regarding the publication of this article.\\nFunding The authors received no specific funding for this \\nwork. Hence, the corresponding author confirms that there are \\nno financial and personal relationships with other people or \\norganizations that could inappropriately influence this study.\\n6. References\\n1. Azar HF, Saksala T, Jalali SME. Artificial neural networks models \\nfor rate of penetration prediction in rock drilling. J Structural \\nMechanics 2017;50(3):252-255. \\n2. Rupert JP, Padro CW, Blattel SR. The effects of weight material \\ntype and mud formulation on penetration rate using invert oil \\nsystems. Paper presented at the Society of Petroleum Engineers \\n(SPE) Annual Technical Conference and Exhibition 1981. \\n3. Bourgoyne Jr AT, Young Jr FS. A multiple regression approach \\nto optimal drilling and abnormal pressure detection. SPE J \\n1974;14(04):371-384.\\n4. Bingham MG. A new approach to interpreting rock drillability. \\nTechnical Manual Reprint Oil & Gas Journal 1965: 1-93.\\n5. Elkatatny S. Real time prediction of rheological parameters of \\nKCl water-based drilling fluid using artificial neural networks. \\nArabian Journal for Science and Engineering 2017;42:1655-\\n1665.\\n6. Mahmoud AA, Elkatatny S, Chen W, Abdulraheem A. Estimation \\nof oil recovery factor for water drive sandy reservoirs through \\napplications of artificial intelligence. Energies 2019;12(9):3671.\\n7. Connor Shorten “Machine Learning vs. Deep Learning” Towards  \\nData Science. 2018.\\n8. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature \\n2015;521(7553):436–444.\\n9. Otchere DA, Ganat TOA, Gholami R, Ridha S. Application \\nof supervised machine learning paradigms in the prediction \\nof petroleum reservoir properties: Comparative analysis of \\nANN and SVM models. Journal of Petroleum Science and \\nEngineering 2021;200:108182.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Data Science. 2018.\\n8. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature \\n2015;521(7553):436–444.\\n9. Otchere DA, Ganat TOA, Gholami R, Ridha S. Application \\nof supervised machine learning paradigms in the prediction \\nof petroleum reservoir properties: Comparative analysis of \\nANN and SVM models. Journal of Petroleum Science and \\nEngineering 2021;200:108182. \\n10. Bilgesu HI, Tetrick LT, Altmis U, Mohaghegh S, Ameri S. A new \\napproach for the prediction of rate of penetration (ROP) values. \\nPaper presented at the Society of Petroleum Engineers (SPE) \\nEastern Regional Meeting 1997; SPE–39231–MS.\\n11. Arabjamaloei R, Shadizadeh S. Modeling and optimizing rate \\nof penetration using intelligent systems in an Iranian southern \\noil field (Ahwaz oil field). Petroleum Science and Technology \\n2011;29(16):1637–1648.\\n12.  Bataee M, Mohseni S. Application of artificial intelligent systems \\nin ROP optimization: a case study in Shadegan oil field. Paper \\npresented at the Society of Petroleum Engineers (SPE) \\nMiddle East Unconventional Gas Conference and Exhibition \\n2011;SPE-140029-MS.\\n13. Warren TM. Penetration-rate performance of roller-cone bits. \\nSPE Drill Eng 1987;2(01):9–18.\\n14. AL-Mahasneh MA. Optimization Drilling Parameters \\nPerformance during Drilling in Gas Wells. International Journal \\nof Oil, Gas and Coal Engineering 2017;5:19-26. \\n15. Amar K, Ibrahim, A. Rate of penetration prediction and \\noptimization using advances in artificial neural networks, a  \\ncomparative study. In Proceedings of the 4th International Joint \\nConference on Computational Intelligence 2012;1:647-652.\\n16. Shi X, Liu G, Gong X, Zhang J, Wang J, Zhang H. An efficient \\napproach for real-time prediction of rate of penetration in offshore \\ndrilling. Mathematical Problems in Engineering 2016;(Article ID \\n3575380):1–13.\\n17. Ahmed A, Elkatatny S, Abdulraheem A, Mohammed M, Ali A , \\nMohamed I. Prediction of rate of penetration of deep and tight'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Conference on Computational Intelligence 2012;1:647-652.\\n16. Shi X, Liu G, Gong X, Zhang J, Wang J, Zhang H. An efficient \\napproach for real-time prediction of rate of penetration in offshore \\ndrilling. Mathematical Problems in Engineering 2016;(Article ID \\n3575380):1–13.\\n17. Ahmed A, Elkatatny S, Abdulraheem A, Mohammed M, Ali A , \\nMohamed I. Prediction of rate of penetration of deep and tight \\nformation using support vector machine. In Proceedings of the \\nSPE Kingdom of Saudi Arabia Annual Technical Symposium \\nand Exhibition, Dammam, Saudi Arabia. 2018; SPE–192316–\\nMS.\\n18. Maurer WC. The, “perfect-cleaning” theory of rotary drilling. J \\nPet Technol 1962;14(11):1270-1274.\\n19. Zhang Y, Zhang X, Chen Y. Deep neural networks for predicting \\nrate of penetration in drilling. Journal of Petroleum Science and \\nEngineering 2018;165:734-743.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Pet Technol 1962;14(11):1270-1274.\\n19. Zhang Y, Zhang X, Chen Y. Deep neural networks for predicting \\nrate of penetration in drilling. Journal of Petroleum Science and \\nEngineering 2018;165:734-743.\\n20.  Zhao Y, Noorbakhsh A, Koopialipoor M, Azizi A, Tahir MM. \\nA new methodology for optimization and prediction of rate \\nof penetration during drilling operations. Engineering with \\nComputers 2020;36:587-595.\\n21. Abdulmalek A, Abdulwahab A, Salaheldin E, Abdulazeez A. New \\nartificial neural networks model for predicting rate of penetration \\nin deep shale formation. Sustainability 2019;11(22): 6527. \\n22. Hareland G, Hoberock LL. Use of drilling parameters to predict \\nin-situ stress bounds. Paperpresented at the SPE/IADC Drilling \\nConference. Netherlands 1993:SPE-25727-MS. \\n23. Ashrafi SB, Anemangely M, Sabah M, Ameri MJ. Application of \\nhybrid artificial neural networks for predicting rate of penetration \\n(ROP): a case study from Marun oil field. Journal of Petroleum \\nScience and Engineering 2019;175:604-623.\\n24. Iqbal F. Drilling optimization technique using real time \\nparameters. SPE Russian Oil & Gas Technical Conference and \\nExhibition, Moscow, Russia, 2008. \\n25. Burgos CE, Zhang T, Li J, Zhang C, Chen S. ROP prediction \\nusing convolutional neural networks for Paleozoic shale drilling. \\nJournal of Petroleum Science and Engineering 2019;17:633-\\n641.\\n26. Monazami M, Hashemi A, Shahbazian M. Drilling rate of \\npenetration prediction using artificial neural network: A case \\nstudy of one of Iranian Southern oil fields. Journal of Oil and \\nGas Business 2012.\\n27. Abbas AK, Rushdi S, Alsaba M, Al Dushaishi MF. Drilling rate of \\npenetration prediction of high-angled wells using artificial neural \\nnetworks. J. Energy Resour. Technol 2019;141(11):112904.\\n28. Miyora TO. 2014. Modeling and optimization of geothermal \\ndrilling parameters: A case study of well MW-17 in Menengai \\nKenya, MS Thesis. University of Iceland 2014.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 12, 'page_label': '13'}, page_content='Gas Business 2012.\\n27. Abbas AK, Rushdi S, Alsaba M, Al Dushaishi MF. Drilling rate of \\npenetration prediction of high-angled wells using artificial neural \\nnetworks. J. Energy Resour. Technol 2019;141(11):112904.\\n28. Miyora TO. 2014. Modeling and optimization of geothermal \\ndrilling parameters: A case study of well MW-17 in Menengai \\nKenya, MS Thesis. University of Iceland 2014.\\n29. Al-AbdulJabbar A, Elkatatny S, Mahmoud AA, et al. Prediction \\nof the rate of penetration while drilling horizontal carbonate \\nreservoirs using the self-adaptive artificial neural networks \\ntechnique. Sustainability 2020;12(4):1376.\\n30. Wang K, Zhang Y, Zhang X, Wang Y. A hybrid ensemble \\nlearning approach for rate of penetration prediction in oil and \\ngas drilling. Journal of Petroleum Science and Engineering \\n2020;194:107424.\\n31.  Liu N, Gao H, Zhen Z, Hu Y, Duan L. A stacked generalization  \\nensemble model for optimization and prediction of the gas well  \\nrate of penetration: a case study in Xinjiang. Journal of Petroleum \\nExploration and Production Technology 2021;6:1595-1608.\\n32. Moraveji MK, Naderi M. Drilling rate of penetration prediction \\nand optimization using response surface methodology and bat \\nalgorithm. Journal of National Gas Science and Engineering \\n2016;31:829–841. \\n33. Motahhari HR, Hareland G, Nygaard R, Bond B. Method of \\noptimizing motor and bit performance for maximum ROP. J Can \\nPet Technol 2009;48(06):44-49. \\n34. Hareland G, Rampersad PR. Drag - Bit Model Including Wear. \\nAmerica/Caribbean Petroleum Engineering Conference 1994: \\nSPE-26957-MS.\\n35. Bourgoyne Jr AT, Millheim KK, Chenevert ME, Young Jr FS.'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 13, 'page_label': '14'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n14\\nApplied drilling engineering. SPE Textbook Series 1991;2:ISBN: \\n978-1-55563-001-0.\\n36. Quinlan JR. Induction of decision trees. Machine Learning \\n1986;1(1):81-106. \\n37. SametGirgin, Decision Tree Regression in 6 Steps with Python, \\nPursuitData (Medium). 2019.\\n38. Javat (2022).  \\n39. Pandey YN, Rastogi A, Kainkaryam S, Bhattacharya S, Saputelli \\nL. Overview of Machine Learning and Deep Learning Concepts. \\nMachine Learning in the Oil and Gas Industry 2020:75-152.\\n40. GeeksForGeeks (2022)\\n7 Appendix: Codes for the different algorithms employed in this work.\\nRandom Forest Algorithm\\nLinear Regression Algorithm\\nK Nearest Neighbour Algorithm'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 14, 'page_label': '15'}, page_content='15\\nOlafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\\nSVR Algorithm\\nStacking Algorithm\\nVoting Algorithm'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 9.26', 'creator': '', 'creationdate': \"D:20231110215223Z00'00'\", 'moddate': \"D:20231110215223Z00'00'\", 'title': '', 'author': '', 'subject': '', 'keywords': '', 'source': 'Comparative_Analysis_of_Machine_Learning.pdf', 'total_pages': 16, 'page': 15, 'page_label': '16'}, page_content='J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\\n16\\nCNN Algorithm Code')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\" Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
    "text :{text}\n",
    "\n",
    " \"\"\"\n",
    " \n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(template=template,input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\nProvide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\\n{text} \\n')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_template = \"\"\"\n",
    "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
    "{text} \n",
    "\"\"\"\n",
    "\n",
    "final_prompt_template=PromptTemplate(input_variables=['text'],template=final_template)\n",
    "final_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template=' Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\\ntext :{text}\\n\\n ')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "chain = load_summarize_chain(llm=llm,map_prompt=prompt,chain_type='map_reduce',verbose=True,combine_prompt=final_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :Comparative Analysis of Machine Learning Algorithms in Predicting Rate of \n",
      "Penetration during Drilling\n",
      "Olaosebikan Abidoye Olafadehan*, Ikenna David Ahaotu\n",
      "Department of Chemical and Petroleum Engineering, University of Lagos, Akoka-Y aba, Lagos 101017, Nigeria\n",
      "Citation: Olafadehan OA, Ahaotu  ID, Comparative Analysis of Machine Learning Algorithms in Predicting Rate of Penetration \n",
      "during Drilling. J Petro Chem Eng 2023;1(1): 32-47.\n",
      "Received: 14 October, 2023; Accepted: 31 October, 2023; Published: 07 November, 2023\n",
      "*Corresponding author: Olafadehan OA, Department of Chemical and Petroleum Engineering, University of Lagos, Akoka-\n",
      "Y aba, Lagos 101017 Nigeria, Phone: +234802-912-9559, Email: oolafadehan@unilag.edu.ng\n",
      "Copyright: © 2023 Olafadehan OA., et al., This is an open-access article published in J Petro Chem Eng (JPCE) and distributed \n",
      "under the terms of the Creative Commons Attribution License, which permits unrestricted use, dist ribution, and reproduction \n",
      "in any medium, provided the original author and source are credited.\n",
      "1\n",
      " A B S T R A C T \n",
      "Drilling for potential oil and gas reserves is one of the foremost practices in the petroleum industry. The dr illing process, \n",
      "however, is quite expensive and can take quite some time to accomplish.  Hence, there has been a rise in the n eed to reduce \n",
      "cost and time by optimizing the rate of penetration during drilling, which has led to the development of mathemat ical models \n",
      "to describe and evaluate this process.  However, the accuracy of these models has varied owing to variat ion of the drilling \n",
      "parameters accounted for in each model. This event has led to the usage of alternative approaches such as Data driven models.  In \n",
      "this study, the predictive capacities of the rate of penetration (ROP) during drilling using machine learning (ML) algorithms of \n",
      "support vector machine regression (SVR), Random Forest regression (RF), Linear regression (LR), KNearest neighbors (KNN), \n",
      "Stacking technique, Voting technique and Convolution neural network (CNN), were compared.  Data from an oil well in Nigeria \n",
      "was used in this investigation. The data for the well was split into train–test sets in the ratio of 60:40.  The train data was used to \n",
      "train and select the best model before making predictions on the test sets.  The Stacking technique was found t o have the best \n",
      "performance across both training and test data sets with respective accuracies of 99.8% and 97.5% in terms of the  –score. The \n",
      "Voting technique also performed well, with respective accuracies of 93.6% and 92.6% in terms of the  –score across both sets of \n",
      "data. The CNN model equally performed well on the training and test data sets, with respective accuracies of 92.4% a nd 92.8% \n",
      "in terms of the  –Score.  Generally, the machine learning models were able to detect patterns and gain valuable insights into the \n",
      "data. They can be employed for real time prediction of the rate of penetration during oil well drilling.\n",
      "Keywords: Rate of penetration; Drilling; Artificial intelligence; Machine learning algorithms; train–test data.\n",
      "Abbreviations\n",
      "AI  Artificial Intelligence\n",
      "ANN            Artificial Neural Network\n",
      "CNN            Convolutional Neural Network\n",
      "DDR             Daily Drilling Report\n",
      "KNN              KNearest Neighbors\n",
      "MAE             Mean Absolute Error\n",
      "ML                  Machine Learning\n",
      "R2                    Coefficient of determination\n",
      "RMSE             Root mean squared Error.\n",
      "ROP                 Rate of penetration. \n",
      "RPM            Rotary speed,\n",
      "SVR                Support Vector Regressor\n",
      "WOB              Weight on bit, kblf\n",
      "Research Article\n",
      "Vol: 1 & Iss: 1\n",
      "https://urfpublishers.com/journal/petrochemical-engineering\n",
      "Journal of Petroleum & Chemical Engineering\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "2\n",
      "1. Introduction\n",
      "Drilling is a key aspect of the petroleum industry. It is the \n",
      "process of boring a hole deep into the subsurface section of the \n",
      "earth in order to reach formations with hydrocarbon reserves, \n",
      "for the aim of hydrocarbon recovery. The importance of this \n",
      "process cannot be understated and as a result, a lot of different \n",
      "drilling technologies were implemented to maximize drilling \n",
      "operations. The popular drilling method used today known \n",
      "as the rotary drilling, which is applied in drilling the majority \n",
      "of onshore and offshore wells and makes use of an applied \n",
      "axial force on the rotating drill bit to achieve penetration. It is \n",
      "impossible to overstate the significance of this procedure, which \n",
      "is why numerous drilling methods have been used to maximize \n",
      "drilling operations. The bulk of onshore and offshore wells are \n",
      "drilled using the widely used technique known as the rotary \n",
      "drilling, which applies an axial force to the revolving drill bit \n",
      "to accomplish penetration. In a rotary drilling process, key \n",
      "parameters need to be considered to ensure optimal operations, \n",
      "and a key parameter among these is the rate of penetration, ROP. \n",
      "It is the depth of penetration accomplished per unit time, and is \n",
      "usually measured as a factor of how many feet the bit can drill in \n",
      "an hour (i.e., ft/h). However, evaluation of ROP is difficult due \n",
      "to the complex relationship between other drilling parameters \n",
      "affecting the ROP. The rate of penetration (ROP) prediction is \n",
      "a key task in drilling economical assessments\n",
      "1. Not always is \n",
      "the lowest cost per foot provided by the fastest drilling pace. A \n",
      "rise in the project’s overall cost may be caused by other factors. \n",
      "The characteristics of drilling fluid (such as mud viscosity, mud \n",
      "density, filtration loss), mechanical characteristics (such as bit \n",
      "type and weight), and formation properties (such as porosity, rock \n",
      "abrasivity, formation elasticity, formation stress, permeability) \n",
      "are a few examples of the properties that affect penetration rate\n",
      "2. \n",
      "Hence, it is important to maximize the rate of penetration in order \n",
      "to mitigate some of the general cost associated with drilling for \n",
      "extended periods. Therefore, it is necessary to understand the \n",
      "relationship between the ROP and other operational parameters.\n",
      "Mathematical models have been used to model the \n",
      "relationship between some operational parameters and ROP \n",
      "e.g., Bourgoyne and Young\n",
      "3 model and the Bingham 4. The \n",
      "accuracy of these models has varied due to variation in the \n",
      "drilling parameters considered in each model. This has led to \n",
      "the usage of alternative approaches such as a data driven model \n",
      "e.g., artificial intelligence (AI). Artificial intelligence methods \n",
      "have developed rapidly over the past decades and has led to it \n",
      "been implemented in various sectors, including the oil and gas \n",
      "industry. Colossal amount of data is been generated on the oil \n",
      "field during operating hours. These data include drilling data, \n",
      "production data, seismic data and mud log data, amongst others. \n",
      "These data sets can be trained using artificial intelligence \n",
      "methods to make future predictions and generate hidden insights \n",
      "into the data. The AI methods have been used extensively in \n",
      "applications to the petroleum industry where they can provide \n",
      "solutions to drilling problems such as prediction of drill bit wear \n",
      "from drilling parameters, real-time predictions of alterations in \n",
      "drilling fluid rheology\n",
      "5, and the estimation of oil recovery factor \n",
      "for water drive sandy reservoirs6.\n",
      "1.1 Artificial Intelligence\n",
      "Machine Learning (ML) and Deep Learning (DL) are \n",
      "branches of artificial intelligence that deals with computerized \n",
      "systems and algorithms learning from previous data generated\n",
      "7. \n",
      "By utilizing various algorithmic strategies, they enable the \n",
      "systems to perform computational tasks without requiring \n",
      "explicit programming and learn from the data. Finding patterns\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :7. \n",
      "By utilizing various algorithmic strategies, they enable the \n",
      "systems to perform computational tasks without requiring \n",
      "explicit programming and learn from the data. Finding patterns \n",
      "in numerical data by applying computer algorithms to convert \n",
      "data into numerical form is known as machine learning. \n",
      "Amongst other formats, the data may be in the form of pictures, \n",
      "music, numbers, or alphabetical data. The algorithms used to \n",
      "find the patterns within these data are called machine learning \n",
      "models. These models, which include linear regression, logistic \n",
      "regression, decision Trees, random forest, K-Means, K-Nearest \n",
      "Neighbors, are used for prediction, data sub-grouping and \n",
      "sound-detection, amongst others. They have been applied to \n",
      "aid in the prediction of ROP values with better accuracy and \n",
      "generalization. ML operations are divided into supervised and \n",
      "unsupervised learning. Supervised learning is a paradigm in \n",
      "machine learning here input objects and a desired output value \n",
      "train a model. The training data is processed, and builds a \n",
      "function that maps new data on expected output values (e.g., \n",
      "regression and classification). In unsupervised learning, the data \n",
      "has no target label, the machine learning model aims at finding \n",
      "hidden patterns in the data using algorithms to make critical \n",
      "judgments in the future (e.g., clustering and recommendation).\n",
      "Deep learning is a branch of the machine learning and \n",
      "artificial intelligence that mimics the operation of how the human \n",
      "brain receives, process and transmit information, as depicted in \n",
      "Figure 1.\n",
      "Figure 1: Human neuron model.\n",
      "Deep learning (DL) is essentially a neural network with one \n",
      "or more layers. The components of the human neural network \n",
      "are modelled similar to the neural network operation\n",
      "8. The \n",
      "dendrites act as input nodes, cell body represents activation \n",
      "function, synapse is the weightage of each input, and the axon \n",
      "terminal is the output node as shown in Figure 2.\n",
      "Figure 2: A typical feed forward neural network architecture9.\n",
      "Neural networks (or deep learning) are massively parallel\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :3\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "distributed processor that store and make use of experiential \n",
      "knowledge. It is classified into 3 parts: artificial neural network \n",
      "(ANN), convolutional neural network (CNN), and recurrent \n",
      "neural network (RNN), which are used to carry out different \n",
      "operations. The ANN is mostly used to carry out regression \n",
      "and classification problems. The CNN is mostly used to carry \n",
      "out image processing and prediction while the RNN is mostly \n",
      "used for forecasting operations. A convolutional neural network \n",
      "and a few machine learning strategies are used in this work. \n",
      "Convolutional layers, feature extractors (filters), pooling layers, \n",
      "hidden layers, and one or more output layers are the components \n",
      "of a convolutional neural network. Weights are used to connect \n",
      "the layers in the hidden layer of the CNN structure. These weights \n",
      "facilitate information flow between layers and aid in neural \n",
      "network training. An activation function is present in every \n",
      "hidden layer, which helps to save computational time and cost \n",
      "by converting the data into a more computer-interactive format. \n",
      "To extract important features from the data, convolutional layers \n",
      "assist in performing convolutional operations on the data.\n",
      "Before the data is sent to the filter, which extracts the features \n",
      "and patterns in the dataset, the convolutional layer typically \n",
      "receives the input in the form of length, breadth, height, and \n",
      "color channels. CNNs have two feature extraction layers: one \n",
      "that makes use of pooling layers and the other that makes use of \n",
      "filters. To extract even more important insights from the dataset, \n",
      "a pooling layer made up of a pooling approach is employed to \n",
      "perform pooling on the features that the filter helped extract. To \n",
      "conduct out-pooling, different sorts of pooling techniques are \n",
      "employed, such as MaxPooling, Average Pooling, and Global \n",
      "Pooling.\n",
      "Bilgesu et al\n",
      "10. used an artificial neural network to develop an \n",
      "ROP model, which was dependent on several operating \n",
      "parameters. A data of 500 points was used, with nine features, \n",
      "which were tooth wear, rotary speed, torque, weight on bit, \n",
      "pump flow rate, rotating time, bearing wear, formation \n",
      "drillability, and formation abrasiveness. A train-test ratio of 9:1, \n",
      "which implies 90% of the data was used for training and 10% for \n",
      "validating the model. A coefficient of determination (\n",
      "2R ) \n",
      "between 0.902 and 0.982 was achieved after cross-validation \n",
      "across the data. In the work of Arabjamaloei and Shadizadeh\n",
      "11, \n",
      "an artificial neural network with a single hidden layer of 10 \n",
      "neurons was developed and combined with genetic algorithm \n",
      "(GA) to create a model to predict ROP values. There were seven \n",
      "features and 300 points (rows) in the data. The bit type, formation \n",
      "properties, bit operating condition (rotary speed and bit weight), \n",
      "bit tooth wear, bit hydraulics, hydrostatic head, and equivalent \n",
      "circulating density were the input features. A total of 224 points \n",
      "were used for model training, 56 points for validation, and 20 \n",
      "points for testing. The generic algorithm was employed to find \n",
      "where the maximum rate of penetration occurred. With a low \n",
      "mean-square error for both training and test set, it was concluded \n",
      "that the neural network is valid for other data sets that fall within \n",
      "the range of data set used for training the model\n",
      "12.performed a \n",
      "comparative evaluation of models for estimating the rate of \n",
      "penetration (ROP) by utilizing field data from a well located in \n",
      "Iran. The model used for this study were the Bingham\n",
      "4, Warren13 \n",
      "and, Bourgoyne and Young 3 models. They carried out ROP \n",
      "predictions on wells that were drilled with roller cone and PDC \n",
      "bits, and comparison was carried out on three separate drilling \n",
      "sections. However, there was a short coming of this study, in that \n",
      "threshold \n",
      "oBW was neglected due to lack of drill-off test been \n",
      "carried out. The findings of this study demonstrated that among\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :sections. However, there was a short coming of this study, in that \n",
      "threshold \n",
      "oBW was neglected due to lack of drill-off test been \n",
      "carried out. The findings of this study demonstrated that among \n",
      "the models examined, the Bourgoyne and Young model exhibited \n",
      "the highest level of predictive performance. Mahasneh\n",
      "14 \n",
      "developed a mathematical model to predict the rate of penetration \n",
      "(ROP) in gas wells, considering the factors of weight on bit \n",
      "(WOB), bit rotation speed (RPM), flow rate (FR), formation \n",
      "strength, depth, and formation compaction. He then used his \n",
      "model to optimize the drilling parameters for a gas well in \n",
      "Jordan, increasing the ROP by 15% and reducing the cost of \n",
      "drilling by 10%. Mahasneh\n",
      "14’s study demonstrated the \n",
      "importance of drilling optimization in improving the efficiency \n",
      "and cost-effectiveness of drilling operations. Amar and Ibrahim\n",
      "15 \n",
      "worked on the comparative analysis of physics-based equations \n",
      "with artificial neural networks (ANN). They developed two \n",
      "neural network models to evaluate the ROP values. The input \n",
      "parameters into the neural networks were formation depth, ECD, \n",
      "weight on bit, DSR, pore pressure gradient, drill bit tooth wear, \n",
      "and Reynolds number function. The physics-based equations \n",
      "used for the comparative analysis were the Bingham\n",
      "4 model and \n",
      "Bourgoyne and Young3 model. A comparison of the predictive \n",
      "accuracy of the developed ANN-based models with the available \n",
      "empirical equations showed that both ANN-based models were \n",
      "highly accurate for estimating the ROP as compared with the \n",
      "empirical equations. Shi et al.\n",
      "16predicted the rate of penetration \n",
      "(ROP) using the Extreme Learning Machine (ELM) and Upper-\n",
      "layer solution-ware (USA) techniques. To construct the \n",
      "predictive models, various input parameters such as formation \n",
      "properties, rig hydraulics, bit specifications, weight on bit, rotary \n",
      "speed, and mud properties were utilized. These input features \n",
      "were selected based on reservoir data from Bohai Bay, China. \n",
      "The performance of the developed models using ELM and USA \n",
      "techniques was compared with an artificial neural network \n",
      "model. The accuracy of these models was evaluated using \n",
      "metrics such as regression coefficient (\n",
      "2R ), mean absolute error \n",
      "(MAE), and root mean square error ( RMSE). The findings \n",
      "indicated that the ROP model developed with the USA technique \n",
      "exhibited the highest predictive performance compared to the \n",
      "other models. Additionally, it was observed that the development \n",
      "of the ROP model using the extreme learning technique required \n",
      "the most time investment. Ahmed et al.\n",
      "17 investigated the \n",
      "application of a support vector machine model to estimate the \n",
      "rate of penetration in a formation containing shale materials. The \n",
      "input features used in the model were hinged on drilling \n",
      "parameters and mud properties such as weight on bit, rotary \n",
      "speed, pump flow rate, standpipe pressure, drilling torque, mud \n",
      "density, plastic viscosity, funnel viscosity, yield point and solid \n",
      "content (%). The support vector machine model and the \n",
      "Bourgoyne and Youngs model were trained on more than 400 \n",
      "real data in shale formation using these 10 features as inputs. \n",
      "The two models were both compared on their predictive \n",
      "performance on the test data. The Bourgoyne and Young (1974) \n",
      "model produced a coefficient of determination (\n",
      "2R ) of 0.0692 \n",
      "and an absolute percentage error of 23.41%. By applying the \n",
      "support vector machine (SVM) model, a coefficient of \n",
      "determination (\n",
      "2R ) of 0.995 and an absolute percentage error of \n",
      "2.82% were obtained. It was concluded that SVM can be used to \n",
      "predict ROP with higher accuracy and also generate ROP values \n",
      "faster than the Bourgoyne and Young\n",
      "3 model. Elkatany 5 \n",
      "developed an artificial neural network (ANN) model to predict \n",
      "the rate of penetration (ROP) using data collected from three \n",
      "vertical wells in an offshore oilfield. The ANN-ROP model was \n",
      "obtained based on drilling parameters and drilling fluid\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :the rate of penetration (ROP) using data collected from three \n",
      "vertical wells in an offshore oilfield. The ANN-ROP model was \n",
      "obtained based on drilling parameters and drilling fluid \n",
      "properties. Two wells were utilized for training the model, and \n",
      "the third well was used to evaluate the accuracy of the model.\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "4\n",
      "The performance of the ANN-ROP model was compared to \n",
      "other ROP models of Bingham (1965), Bourgoyne and Young\n",
      "3, \n",
      "and Maurer18. Elkatany5 concluded that the proposed ANN-ROP \n",
      "model exhibited superior performance over others considered in \n",
      "his work. The training data consisted of 3333 data points and \n",
      "yielded a coefficient of determination (\n",
      "2R ) of 0.99, with an \n",
      "average absolute percentage error ( AAPE) of 5%. The test set, \n",
      "consisting of 2700 unseen data points from the third well, \n",
      "resulted in the ANN-ROP model predicting the rate of penetration \n",
      "with \n",
      "99. 02 =R and AAPE = 4%. Zhang et al. 19 proposed a deep \n",
      "convolutional neural network (CNN) model for predicting the \n",
      "rate of penetration (ROP) during drilling operations. The authors \n",
      "argued that existing models for predicting ROP are often \n",
      "inaccurate and unreliable, and that deep learning methods could \n",
      "provide a more accurate and practical solution. They collected \n",
      "data from drilling operations in two different fields and used it to \n",
      "train and test the proposed deep CNN model in their work. The \n",
      "model consists of six convolutional layers and is trained using a \n",
      "mean absolute percentage error (MAPE) loss function. The \n",
      "authors compared the performance of their deep CNN model to \n",
      "other machine learning models and found that it outperformed \n",
      "these models in terms of accuracy and reliability. They also \n",
      "conducted sensitivity analyses to determine the most important \n",
      "features for predicting ROP. They found that the weight on bit, \n",
      "the rotary speed, and the mud flow rate were the most important \n",
      "features for predicting ROP. Zhao et al.\n",
      "20 focused on developing \n",
      "multiple artificial neural network (ANN) models for predicting \n",
      "the rate of penetration (ROP) using data collected from a gas \n",
      "well located in the southern region of Iran. A dataset comprising \n",
      "3180 data points was obtained from various drilling sections, \n",
      "involving one run of a roller-cone bit and three runs of PDC bits. \n",
      "To construct the ANN-ROP models, several input variables were \n",
      "considered, including depth, rotary speed of the bit, weight on \n",
      "bit (WOB), shut-in pipe pressure, fluid rate, mud weight, the \n",
      "ratio of yield point to plastic viscosity, and the ratio of 10-minute \n",
      "gel strength to 10-second gel strength. Three different training \n",
      "functions, namely Levenberg-Marquardt (LM), Scaled \n",
      "Conjugate Gradient (SCG), and One-Step Secant (OSS), were \n",
      "employed in combination with the neural networks to estimate \n",
      "the penetration rates. It was concluded that the ANN-ROP model \n",
      "utilizing the Levenberg-Marquardt (LM) function demonstrated \n",
      "the best prediction performance, achieving a regression \n",
      "coefficient (\n",
      "2R ) of 0.91 in training and 0.89 in testing. \n",
      "Furthermore, they also applied the Artificial Bee Colony (ABC) \n",
      "algorithm to optimize the ROP. The optimization process \n",
      "resulted in an approximate improvement of 20–30% in the rate \n",
      "of penetration. Abdulmalek et al.\n",
      "21 carried out a comparative \n",
      "analysis between artificial intelligence techniques and some \n",
      "traditional models for ROP prediction in shaley formations. An \n",
      "artificial neural network was developed for the ROP prediction \n",
      "in the shale formation. The parameters considered for the \n",
      "prediction of the rate of penetration (ROP) included torque, \n",
      "standpipe pressure, pump rate, mud weight, funnel and plastic \n",
      "viscosities, solid content, and yield point. The traditional ROP \n",
      "models such as those proposed by Bingham\n",
      "4, Warren 13, \n",
      "Bourgoyne and Young3, Maurer18 and Hareland and Hoberock22, \n",
      "were selected for comparison. Both the artificial neural network–\n",
      "ROP (ANN-ROP) model and the traditional models underwent \n",
      "training and testing using a dataset consisting of 347 data points \n",
      "from a deep shale formation in an onshore oilfield. Additionally, \n",
      "200 new data points from an upper shale formation were utilized \n",
      "to validate the models. The results indicated that the ANN-ROP\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :from a deep shale formation in an onshore oilfield. Additionally, \n",
      "200 new data points from an upper shale formation were utilized \n",
      "to validate the models. The results indicated that the ANN-ROP \n",
      "model outperformed the other models in comprehending the \n",
      "intricate relationships within the data and making accurate \n",
      "predictions. The ANN-ROP model achieved a rate of penetration \n",
      "prediction with an average absolute percentage error (AAPE) of \n",
      "5.776% and a regression coefficient (\n",
      "2R ) of 0.996. Ashrafi et \n",
      "al.23 explored the prediction of rate of penetration (ROP) using \n",
      "various optimization algorithms and neural network architectures. \n",
      "The optimization algorithms employed included Genetic \n",
      "Algorithm (GA), Particle Swarm Optimization (PSO), \n",
      "Biogeography-based Optimizer (BBO), and Imperialist \n",
      "Competitive Algorithm (ICA). These algorithms were combined \n",
      "with different neural network architectures to develop hybrid \n",
      "ROP models. To evaluate the performance of the hybrid models, \n",
      "the results were compared with two other models: Non-linear \n",
      "Multiple Regression (NLMR) and Linear Multiple Regression \n",
      "(LMR) techniques. For the hybrid models, two popular neural \n",
      "network architectures, namely Multi-Layer Perception (MLP) \n",
      "and Radial-Based Function (RBF), were utilized. These \n",
      "architectures consisted of two hidden layers with 4 and 6 \n",
      "neurons, respectively. The activation function used in the hidden \n",
      "layers and output layer was tan-sigmoid. The input features were \n",
      "weight on bit, rotational speed of the drill bit, pump inlet flow \n",
      "rate, pore pressure pump pressure, gamma ray, density log, and \n",
      "shear wave velocity. The dataset used for the study consisted of \n",
      "1000 data points, collected from the Marun oilfield in Iran. It \n",
      "was concluded in their study that the hybrid models utilizing \n",
      "PSO-MLP and PSO-RBF neural networks exhibited the best \n",
      "predictive accuracy for ROP. The root mean square error (RMSE) \n",
      "values for these models were 1.12 and 1.4, respectively, \n",
      "indicating their superior performance compared to the other \n",
      "developed models. Iqbal\n",
      "24 developed a mathematical model to \n",
      "predict the rate of penetration (ROP) in drilling operations, \n",
      "considering the factors of weight on bit (WOB), bit rotation \n",
      "speed (RPM), flow rate (FR), formation strength, depth, and \n",
      "formation compaction. He then used his model to optimize the \n",
      "drilling parameters for a real-time drilling dataset from a Middle \n",
      "Eastern oil field, increasing the ROP by 10% and reducing the \n",
      "cost of drilling by 5%. Iqbal’s study demonstrates the importance \n",
      "of using real-time drilling parameters to optimize drilling \n",
      "operations and provides a valuable contribution to the field of \n",
      "drilling engineering. Burgos et. al.\n",
      "25 developed a convolutional \n",
      "neural network (CNN) model to predict the rate of penetration \n",
      "(ROP) during rotary drilling operations. The model takes in 10 \n",
      "drilling parameters as inputs, such as weight on bit, rotary speed, \n",
      "flow rate, and hook load. The inputs are normalized between 0 \n",
      "and 1. The CNN architecture consists of 3 convolutional layers \n",
      "followed by 2 fully connected layers. The output layer has a \n",
      "single node with a linear activation to predict the ROP value. \n",
      "The model was trained on data from over 600 wells. It achieved \n",
      "a mean absolute percentage error (MAPE) of 9.3% on the test \n",
      "set, outperforming traditional machine learning models like \n",
      "linear regression, random forests, and support vector regression. \n",
      "An ablation study showed that the CNN’s ability to learn \n",
      "complex non-linear relationships between the drilling parameters \n",
      "allowed it to accurately predict ROP, whereas simply averaging \n",
      "the inputs did not work as well. The model was able to generalize \n",
      "the data from 50 additional wells, with the MAPE only increasing \n",
      "slightly to 10.2%. This shows the model has good generalization \n",
      "performance. In conclusion, the CNN approach effectively \n",
      "modelled the complexity between drilling parameters and ROP,\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :slightly to 10.2%. This shows the model has good generalization \n",
      "performance. In conclusion, the CNN approach effectively \n",
      "modelled the complexity between drilling parameters and ROP, \n",
      "outperformed traditional models, and generalized well to new \n",
      "data. This could enable more efficient drilling operations through \n",
      "accurate ROP predictions. Monazami et al.\n",
      "26 used an artificial \n",
      "neural network (ANN) to predict the rate of penetration (ROP) \n",
      "in drilling operations. The ANN model took cognizance of\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :5\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "formation strength, depth, formation compaction, pressure \n",
      "differential, bit diameter, weight on bit (WOB), bit rotation \n",
      "(RPM), and bit hydraulics. The authors evaluated the performance \n",
      "of their ANN model on a test dataset of ROP data. They found \n",
      "that the model was able to predict ROP with high accuracy. The \n",
      "average error between the predicted and actual ROP values was \n",
      "less than 5%. The model was able to predict ROP with high \n",
      "accuracy, suggesting that ANN is a promising tool for optimizing \n",
      "drilling parameters and improving the efficiency and cost-\n",
      "effectiveness of drilling operations. Abbas et al.\n",
      "27 employed an \n",
      "artificial neural network (ANN) approach to develop a \n",
      "computational-based method for predicting the rate of \n",
      "penetration (ROP). Through a thorough analysis of feature \n",
      "selection, it was determined that out of the 25 input variables \n",
      "examined, 19 variables had the greatest influence on the ROP. A \n",
      "dataset consisting of 13,125 data points from 14 deviated wells \n",
      "in a formation located in southern Iraq was collected for the \n",
      "study. The data specifically pertained to the 8 ½” production \n",
      "casing section, which was drilled using a drag bit and a \n",
      "conventional bottom hole assembly (BHA) with a water-based \n",
      "mud circulating system. It was concluded that the ROP model \n",
      "based on the artificial neural network, utilizing three hidden \n",
      "layers and employing the tan–sigmoid activation function, \n",
      "exhibited the highest efficiency in predicting ROP. The model \n",
      "achieved a regression coefficient of 0.92 during training and \n",
      "0.97 during testing, with mean absolute percentage errors \n",
      "(MAPE) of 9.1% and 8.8% in training and testing, respectively. \n",
      "Furthermore, the model demonstrated good performance on \n",
      "unseen data and did not exhibit overfitting issues. Miyora\n",
      "28 \n",
      "studied the factors that affect the rate of penetration (ROP) in \n",
      "geothermal drilling and developed a mathematical model to \n",
      "predict ROP based on these factors. The model includes \n",
      "formation strength, depth, formation compaction, pressure \n",
      "differential, bit diameter, weight on bit (WOB), bit rotation \n",
      "(RPM), and bit hydraulics. Miyora () found that all these factors \n",
      "have a significant impact on ROP and used his model to optimize \n",
      "the drilling parameters for Well MW-17 in Menengai, Kenya, \n",
      "increasing the ROP by up to 20%. Al-AbdulJabbar et al.\n",
      "29 utilized \n",
      "an artificial neural network (ANN) in combination with self-\n",
      "adaptive differential evolution (SADE) to predict the rate of \n",
      "penetration (ROP) specifically in horizontal carbonate reservoirs. \n",
      "The model incorporated six input variables, including rotary \n",
      "speed, torque, weight on bit, as well as formation petrophysical \n",
      "properties such as gamma ray, resistivity, and bulk density data. \n",
      "The developed model demonstrated strong performance, \n",
      "achieving a regression coefficient (\n",
      "2R ) of 0.96 and a mean \n",
      "absolute percentage error (MAPE) of 5.12%. To further evaluate \n",
      "the accuracy of the model, an unseen well was used as test data. \n",
      "The resulting regression coefficient (\n",
      "2R ) and MAPE values \n",
      "were 0.95 and 5.8%, respectively. Furthermore, their study \n",
      "aimed to enhance the interpretability of the ROP model by \n",
      "extracting the weights and biases in a matrix form, effectively \n",
      "transforming it from a black box model to a white box model. \n",
      "Wang et al.\n",
      "30 proposed a hybrid ensemble learning approach for \n",
      "predicting the rate of penetration (ROP) during oil and gas \n",
      "drilling operations. They argued that existing models for \n",
      "predicting ROP are often inaccurate and unreliable, and that \n",
      "ensemble learning methods can provide a more accurate and \n",
      "practical solution. They collected data from drilling operations \n",
      "in the Gulf of Mexico and used it to train and test their hybrid \n",
      "ensemble learning model. The model consisted of several \n",
      "machine learning algorithms, including support vector regression \n",
      "(SVR), random forest regression (RFR), and gradient boosting\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :ensemble learning model. The model consisted of several \n",
      "machine learning algorithms, including support vector regression \n",
      "(SVR), random forest regression (RFR), and gradient boosting \n",
      "regression (GBR), which were combined using a weighted \n",
      "average ensemble method. The authors compared the \n",
      "performance of their hybrid ensemble learning model to other \n",
      "machine learning models and found that it outperformed these \n",
      "models in terms of accuracy and reliability. The authors also \n",
      "conducted sensitivity analyses to determine the most important \n",
      "features for predicting ROP. They found that the weight on bit, \n",
      "the rotary speed, and the mud flow rate were the most important \n",
      "features for predicting ROP. Liu et al.\n",
      "31 proposed a stacked \n",
      "generalization ensemble model for predicting the rate of \n",
      "penetration (ROP) in gas well drilling. The model is trained on a \n",
      "dataset of historical ROP data and drilling parameters from a \n",
      "shale gas survey well in Xinjiang, China. The model combined \n",
      "the predictions of six machine learning models: support vector \n",
      "regression (SVR), extremely randomized trees (XRT), random \n",
      "forest (RF), gradient boosting machine (GBM), light gradient \n",
      "boosting machine (LightGBM), and extreme gradient boosting \n",
      "(XGB). They first used Pearson correlation analysis to identify \n",
      "the most important features from the dataset. Then, they used a \n",
      "Savitzky-Golay smoothing filter to reduce noise in the dataset. \n",
      "Finally, they trained the stacked generalization ensemble model \n",
      "using the leave-one-out cross-validation method. The results \n",
      "showed that the stacked generalization ensemble model can \n",
      "significantly improve the accuracy of ROP prediction. The root \n",
      "mean square error (RMSE) of the model on the testing dataset is \n",
      "0.4853 m/h, which is lower than the RMSE of any of the \n",
      "individual models. The model also has a high \n",
      "2R value of \n",
      "0.9568. They also used the model to optimize the ROP \n",
      "parameters. They use particle swarm optimization (PSO) to \n",
      "search for the optimal combination of ROP parameters. The \n",
      "results show that the optimized ROP parameters can significantly \n",
      "improve the ROP. It was thus concluded that the stacked \n",
      "generalization ensemble model is a promising approach for \n",
      "predicting ROP in gas well drilling. The model is accurate and \n",
      "can be used to optimize the ROP parameters. Moraveji and \n",
      "Naderi32investigated the simultaneous effect of six variables on \n",
      "penetration rate using real field drilling data via response surface \n",
      "methodology (RSM). The important variables included well \n",
      "depth (D), weight on bit (WOB), bit rotation speed ( N), bit jet \n",
      "impact force (IF), yield point, \n",
      "pY , to plastic viscosity ratio, PVR\n",
      ", ( PVRYp ), 10 min to 10 s gel strength ratio (10MGS/10SGS). \n",
      "Equally, bat algorithm (BA) was used to identify optimal range \n",
      "of factors in order to maximize drilling rate of penetration. Their \n",
      "results indicated that the derived statistical model provides an \n",
      "efficient tool for estimation of ROP and determining optimum \n",
      "drilling conditions.\n",
      "The aim of this study is to analyze the performance of \n",
      "machine learning and deep learning techniques in predicting the \n",
      "rate of penetration during drilling, which is crucial in optimizing \n",
      "drilling operations. The results of this study can contribute \n",
      "to drilling planning and optimization of future wells. Exact \n",
      "prediction of the rate of penetration during drilling will save the \n",
      "oil and gas industry a large amount of expenses during drilling \n",
      "operation and reduce the amount of non-productive time (NPT) \n",
      "encountered during drilling operation.\n",
      "1.2 Approaches to Rate of Penetration Modelling\n",
      "Over the past few years, a large amount of research has gone \n",
      "into ways in which ROP can be modelled with its dependent \n",
      "drilling parameters (controllable and uncontrollable). A key \n",
      "drive that leads to further research regarding this field is the\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "6\n",
      "non-comprehensiveness of previous models developed. This \n",
      "is because not all of the known ROP-affecting factors have \n",
      "been accounted for in a single model, which has led to poor \n",
      "accuracy and generalizability of the estimated models\n",
      "33. The \n",
      "seemingly large number of factors affecting the ROP and \n",
      "essential requirement for a model with high accuracy and \n",
      "reliable generalization has led to development of various ROP \n",
      "estimation models. An approach to carry out this modelling is \n",
      "hinged on two patterns, which are physics-based approach, and \n",
      "data-driven approach. The physics-based approach involves \n",
      "the use of mathematical modelling techniques to evaluate \n",
      "relationships between dependent parameter (ROP) and the \n",
      "independent parameters, so as to estimate accurate ROP values. \n",
      "These mathematical relationships are developed based on the \n",
      "physics of the borehole. There are various models used for ROP \n",
      "estimation that are created using the physics-based approach \n",
      "e.g., Cunningham model, Bingham\n",
      "4 model, Maurer 19 model, \n",
      "Motahhari et al. model33 and Hareland and Rampersad model 34. \n",
      "The Cunningham model is given by:\n",
      "          (1)\n",
      "where R  is the rate of penetration (ft/h), K  the constant of \n",
      "proportionality, 0W  the threshold weight on bit (lb f) and N  \n",
      "rotary speed (rpm).\n",
      "Bingham4 model: \n",
      "  (2)\n",
      "where  is the weight-on bit (klb), BD  is the bit diameter \n",
      "(in), a and b are the dimensionless constants for each rock \n",
      "formation.\n",
      "Maurer\n",
      "18 model: \n",
      "   (3)\n",
      "where  is the rate of penetration (ft/h), W  the weight (Ibf), s  \n",
      "the confined rock strength (psi) and D the depth (ft).\n",
      "Motahhari et al. model33: \n",
      "  (4)\n",
      "where fw  is the dimensionless wear function, G is a model \n",
      "coefficient related to bit-rock interactions and bit geometry, \n",
      "α  and γ  are ROP model exponents. The bit coefficient, G, \n",
      "is determined by the bit design, cutter size, cutter rock friction \n",
      "coefficient and the bit geometry. In this model, a decrease in \n",
      "the value of the wear function, while keeping other model \n",
      "parameters constant leads to a decrease in ROP. In the case of \n",
      "the bit size or compressive strength, when its value is decreased \n",
      "an inverse occurs. The relationship between \n",
      "N ,  and R  is \n",
      "non-linear. Hence, the exponents can yield an optimum value for \n",
      " and N due to the exponential nature of the relationship.\n",
      "Hareland and Rampersad Model34: \n",
      "    (5)\n",
      "where cN  is the number of cutters and vA  the area of rock \n",
      "compressed ahead of a cutter (in2 ).\n",
      "Other models used for ROP estimation are as follows:\n",
      "Bourgoyne and Young\n",
      "3 model: \n",
      "     (6)\n",
      "where  is the weight-on bit (klb), BD  is the bit diamete r \n",
      "(in), a and bare the dimensionless constants for each rock \n",
      "formation.\n",
      " Bourgoyne et al. 35 aimed at seeking to optimize the \n",
      "controllable parameters during drilling operation. They proposed \n",
      "the development of an ROP model based on the application \n",
      "of multiple linear regression technique. The controllable \n",
      "parameters used in developing this model were eight: strength \n",
      "of formation, normal compaction function, weight on bit, \n",
      "bit teeth wear, rotary speed function, bit hydraulic function, \n",
      "differential pressure function, and under compaction function. \n",
      "These parameters were treated as independent parameters on the \n",
      "ROP (the dependent parameter). The developed model was then \n",
      "applied to estimate ROP for wells drilled vertically using roller \n",
      "cone bits, and it was concluded that the application of the ROP \n",
      "model could help reduce drilling operational cost by 10%. On \n",
      "inception, the model was basically created for modelling ROP \n",
      "for roller cone bits, but overtime has also shown effectiveness \n",
      "in modelling ROP for PDC bits. The Bourgoyne et al.\n",
      "35 model \n",
      "is given by:\n",
      "∏\n",
      "=\n",
      "=\n",
      "8\n",
      "1i\n",
      "iFR            (7)\n",
      "where )( 1\n",
      "1\n",
      "aeF =  is the formation strength function for \n",
      "Bourgyone and Young model, ( )[ ] DaeF −= 10000\n",
      "2\n",
      "2 the normal \n",
      "compaction function for Bourgyone and Young model, \n",
      " the under compaction function\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :1\n",
      "aeF =  is the formation strength function for \n",
      "Bourgyone and Young model, ( )[ ] DaeF −= 10000\n",
      "2\n",
      "2 the normal \n",
      "compaction function for Bourgyone and Young model, \n",
      " the under compaction function \n",
      "for Bourgyone and Young model, ( )[ ]{ } cpg D aF ρ−= 44 exp  the \n",
      "pressure differential function for Bourgyone and Young model, \n",
      "( ) ( )\n",
      "( ) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "−=\n",
      "t\n",
      "t\n",
      "d w\n",
      "d wd wInaF 4exp 55  the weight on bit function \n",
      "for Bourgyone and Young model, \n",
      "the r otary speed function for Bourgyone and Young model, \n",
      "( )[ ]{ } haF −= 77 exp  the bit tooth wear function for Bourgyone \n",
      "and Young model and \n",
      "  the bit hydraulic \n",
      "function for Bourgyone and Young model.\n",
      " The physics-based approach has limitations due to the failure \n",
      "to consider all the parameters affecting the drilling operation and \n",
      "in the choice of an empirical constant for the ROP estimation \n",
      "with respect to the well/borehole in operation. This gave rise \n",
      "to the use of data-driven approaches, which make use of data \n",
      "generated during drilling (Logging While Drilling (LWD)) \n",
      "and artificial intelligence techniques for ROP estimation\n",
      "17. The \n",
      "application of AI models for ROP estimation was suggested by \n",
      "Bilgesu et al.\n",
      "10, so as to get over the weakness of the physics-\n",
      "based approach and improve the accuracy of ROP predictability. \n",
      "2. Methodology\n",
      "2.1 Methods\n",
      "Figure 3 shows the proposed methodology, adopted in this \n",
      "study.\n",
      "2.2 Data Collection\n",
      "The data utilized for this study was obtained from the Daily \n",
      "Drilling Report (DDR) for an oil well in Nigeria. It contains \n",
      "parameters that ROP depends on, which will help make a robust \n",
      "model. Such parameters are weight on bit, pump flow rate, mud \n",
      "weight, mud type, drill bit diameter and wellbore trajectory, \n",
      "amongst others. After data collection, the uncertainties within \n",
      "the dataset and the suitable parameters are defined. This leads \n",
      "to filtration of the dataset. The well contains data of 27 columns \n",
      "(the number of variables), 17280 rows, 0% missing cells, and \n",
      "0% duplicate rows.\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :7\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "2.3 Data Processing\n",
      "The data preprocessing phase is also known as Feature \n",
      "Engineering Phase. The data set used for the study is subjected to \n",
      "various statistical manipulations and transformations in order to \n",
      "extract relationships and insights between parameters in the data \n",
      "and, process the data into forms that are more understandable \n",
      "by the algorithms, hence, producing better model performances. \n",
      "Such techniques include exploratory data analysis, missing \n",
      "data imputation, outlier handling, feature scaling, variable \n",
      "transformation, and discretization, amongst others. These \n",
      "processes help the model match key relationships between the \n",
      "input parameters and the target variable. In this study, the data \n",
      "preprocessing techniques used were outlier handling, variable \n",
      "transformation and feature scaling.\n",
      "Outlier handling: This refers to the process involved in dealing \n",
      "with outliers found in a dataset. Outliers are simply data point \n",
      "that vary significantly to majority of the dataset. Outliers must \n",
      "be dealt with since they can significantly affect the outcomes \n",
      "and precision of statistical models. Outlier treatment can be done \n",
      "in a number of ways, such as by removing outliers, capping, \n",
      "or imputing more representative values. The method utilized in \n",
      "this study was the capping technique, which involved imputing \n",
      "the interquartile range of the variable with the outlier where the \n",
      "outliers are in the variable. Figures 4 and \n",
      "5 show the box plot of \n",
      "ROP data before and after outlier.\n",
      "Figure 4: Box plot of ROP data before outlier.\n",
      "Variable Transformation: This technique was employed in \n",
      "this study to treat the variables that were skewed either to the \n",
      "left or to the right. It involves changing a variable’s scale or \n",
      "distribution to satisfy requirements or enhance the performance \n",
      "of statistical models. This preprocessing technique was \n",
      "performed on variables that were skewed either to the left or \n",
      "right, so as to equalize variances and establish linearization \n",
      "among the variables, which makes it easier to interpret and \n",
      "model. The variable transformation technique use in this study \n",
      "were LogTransformer and BoxCoxTransformer.\n",
      "Figure 5: Box plot of ROP data after outlier removal. removal.\n",
      "Feature Scaling: This involves changing the scale of \n",
      "numerical features in a dataset. To make the features similar and \n",
      "prevent some from predominating others based only on their \n",
      "initial scale, the range or distribution of the features must be \n",
      "changed. This preprocessing technique is so important as it helps \n",
      "the machine learning models to better understand the features as \n",
      "they will usually be within the range of 0 to 1, which the models \n",
      "usually prefer. For some particular models, it is a necessary \n",
      "requirement to perform feature scaling on the dataset before \n",
      "passing it into them e.g., ANN and CNN, while some models \n",
      "are not influenced when the dataset is scaled or not e.g., Random \n",
      "Forest and Extra Trees. There are many types of Feature scaling \n",
      "techniques e.g., Standard Scaler, MinMax Scaler and Robust \n",
      "scaling. Each of these techniques has their rules of engagement, \n",
      "so as to get better model performance. These rules depend on \n",
      "dataset and model to be used. In this study, the standard scaler \n",
      "was utilized so as to scale features to have a mean of 0 and a \n",
      "standard deviation of 1. \n",
      "Table 1 shows the features definition \n",
      "with the data types used. \n",
      "Table 1: Features definition, unit, and data types.\n",
      "Feature Definition Units Data type\n",
      "Depth The actual depth at which the drilling \n",
      "is taking place.\n",
      "m Numerical\n",
      "Lag Depth Time delay or lag between the mea -\n",
      "sured depth and the corresponding \n",
      "ROP value.\n",
      "m Numerical\n",
      "WHO Weight on String. klb Numerical\n",
      "ROP Rate of Penetration. m/h Numerical\n",
      "RPM  \n",
      "TURBIN\n",
      "Turbine Speed. rev/\n",
      "min\n",
      "Numerical\n",
      "Torque Rotational force of drill string. klb.ft Numerical\n",
      "SPP Standpipe Pressure. psi Numerical\n",
      "Flow Inflow rate of drilling. fluid pumped into\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :RPM  \n",
      "TURBIN\n",
      "Turbine Speed. rev/\n",
      "min\n",
      "Numerical\n",
      "Torque Rotational force of drill string. klb.ft Numerical\n",
      "SPP Standpipe Pressure. psi Numerical\n",
      "Flow Inflow rate of drilling. fluid pumped into \n",
      "the wellbore during drilling.\n",
      "gpm Numerical\n",
      "Mw In total volume of drilling mud pumped \n",
      "into the wellbore during a specific pe-\n",
      "riod of time.\n",
      "pcf Numerical\n",
      "Mw out total volume of drilling mud pumped \n",
      "out of a wellbore during a specific pe-\n",
      "riod of time.\n",
      "pcf Numerical\n",
      "PIT#1 mud pit volume in the first mud pit or \n",
      "mud tank.\n",
      "Bbl Numerical\n",
      "PIT#2 mud pit volume in the second mud pit \n",
      "or mud tank.\n",
      "Bbl Numerical\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "8\n",
      "PIT#3 mud pit volume in the third mud pit \n",
      "or mud tank.\n",
      "Bbl Numerical\n",
      "PIT#4 mud pit volume in the fourth mud pit \n",
      "or mud tank.\n",
      "Bbl Numerical\n",
      "PIT#5 mud pit volume in the fifth mud pit or \n",
      "mud tank.\n",
      "Bbl Numerical\n",
      "PIT#6 mud pit volume in the Sixth mud pit \n",
      "or mud tank.\n",
      "Bbl Numerical\n",
      "TOT ACT Total Actual Time. Bbl Numerical\n",
      "Steel V ol-\n",
      "ume\n",
      "The volume of steel that is used or \n",
      "consumed during the drilling process.\n",
      "Bbl Numerical\n",
      "Over pull Additional force applied to the drilling \n",
      "assembly in order to increase the drill-\n",
      "ing efficiency. \n",
      "klb Numerical\n",
      "Flow Pad-\n",
      "dle\n",
      "Percentage of drilling fluid that cir -\n",
      "culates through the wellbore during \n",
      "drilling.\n",
      "% Numerical\n",
      "Bit Posi -\n",
      "tion\n",
      "It refers to the vertical depth at which \n",
      "the drilling bit is located within the \n",
      "wellbore.\n",
      "m Numerical\n",
      "Hook Po -\n",
      "sition\n",
      "Vertical position of the drilling hook \n",
      "or traveling block.\n",
      "m Numerical\n",
      "String  \n",
      "Weight\n",
      "Total weight of the drill string, includ-\n",
      "ing the drill pipe, bottom hole assem -\n",
      "bly (BHA), and any other components \n",
      "attached to it.\n",
      "klb Numerical\n",
      "Drag Resistance encountered by the drill \n",
      "string and drill bit as they are ad-\n",
      "vanced through the formation.\n",
      "klb Numerical\n",
      "Table 2 gives information on the statistic of ROP variable.\n",
      "Table 2: Descriptive Statistics of ROP variable.\n",
      "Statistic Mean Standard \n",
      "deviation\n",
      "Mini -\n",
      "mum\n",
      "25% 50% 75% Maxi -\n",
      "mum\n",
      "ROP 3.964 4.317 0.000 0.000 2.880 7.410 18.525\n",
      "Table 3 gives the Pearson correlation of the oil well features and \n",
      "their values.\n",
      "Table 3: Pearson correlation of features with rate of penetration.\n",
      "Features Well data\n",
      "Depth -0.37\n",
      "Lag depth 0.98\n",
      "WHO 0.15\n",
      "RPM TURBIN0.57\n",
      "Torque 0.70\n",
      "SPP 0.64\n",
      "Flow in 0.57\n",
      "Mw in -0.08\n",
      "Mw out 0.20\n",
      "PIT#1 0.24\n",
      "PIT#2 -0.14\n",
      "PIT#3 -0.10\n",
      "PIT#4 -0.26\n",
      "PIT#5 0.05\n",
      "PIT#6 0.23\n",
      "TOT ACT-0.25\n",
      "Steel volume 0.20\n",
      "Flow paddle 0.75\n",
      "Bit position 0.20\n",
      "Hook position 0.26\n",
      "String eight -0.01\n",
      "Drag -0.53\n",
      "The correlation heat map of the well data is depicted in \n",
      "Figure 6.\n",
      "Figure 6: Correlation heat map of the well data.\n",
      "2.4 Feature Selection\n",
      "The defined input parameters from the dataset must pass \n",
      "through the feature selection phase. The feature selection is \n",
      "the process of selecting a subset of relevant features (variable, \n",
      "predictors) for usage in building machine learning algorithms. It \n",
      "involves selecting the pool of features that has significant impact \n",
      "on making prediction with the machine learning algorithm. It is \n",
      "a crucial phase, in the bid that a good machine learning model \n",
      "is developed. The feature selection algorithms are divided into \n",
      "three main categories: filter, wrapper, and embedded methods. \n",
      "The feature selection helps a user to better interpret the model \n",
      "e.g., a model of 10 input parameters is much easier to interpret \n",
      "than that of 100 parameters. It also shortens training time for \n",
      "the machine learning algorithm and enhances generalization \n",
      "by reducing overfitting. In this study, a filter method known \n",
      "as mutual information was used to select optimal features for \n",
      "model building. Mutual information is a statistical measure of \n",
      "the mutual dependence of 2 variables. In other words, mutual \n",
      "information quantifies the amount of information gained about \n",
      "one random variable through observing another random variable. \n",
      "The mutual information algorithm is given by: \n",
      "{ }∑∑ ××= )]() (/[) , (log) , () ; ( y px pyx py x pYX I  (8)\n",
      "where I is the ranking score, X  and Ythe respective input and\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :9\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "output nodes, x and y are the dependent and target variables \n",
      "respectively.\n",
      "The algorithm selects the highest-ranking features that best \n",
      "describes the target variable and separates them into percentiles \n",
      "e.g., 10th, 20 th, 30 th etc., depending on the highest ranking. In \n",
      "this study, the features in the top 50 th (50 percentile), which \n",
      "translated to 13 features out of the possible 27, were selected to \n",
      "be used to the build the machine learning models. The features \n",
      "selected after future selection are depth, lag depth, WOB, SPP, \n",
      "MW IN, PIT#2, PIT#3, PIT#4, PIT#6, TOT ACT, steel volume, \n",
      "bit position and hunk position \n",
      "2.5 Data Splitting\n",
      "Data splitting (otherwise known as cross validation) is a \n",
      "process utilized in the building of artificial intelligence models. \n",
      "Here, data is partitioned into two or more ways to enable the \n",
      "model identify the patterns within the data set and predict its \n",
      "performance on unseen (real world) data. Two sets of the dataset \n",
      "are created: a training set and a testing set. The training set is \n",
      "used to train the artificial intelligence model on the data while \n",
      "the testing set is used to assess the model’s performance in real \n",
      "world scenarios. This is because there is a probability that the \n",
      "built model may not be robust enough to perform successfully on \n",
      "unknown (real world) data. There are various methods used for \n",
      "cross validation operation viz. holdout method, K-fold method, \n",
      "Stratified K-fold method, Leave One-Out method, amongst \n",
      "others. The K-fold cross validation technique was implemented \n",
      "in this study using the Python Sklearn package.\n",
      "A 60:40 split of the oil well data was made into train and \n",
      "test sets. There are 10368 rows and 13 columns in the training \n",
      "set and 6912 rows and 13 columns in the test set. The training \n",
      "results were obtained by training the model on the train data \n",
      "and using the resulting model to predict the training set. The \n",
      "test results were obtained by training the model on the train set \n",
      "before predicting the test set.\n",
      "3. Model Development and Training\n",
      "Seven machine learning techniques were analyzed in this \n",
      "work, to be trained to make predictions of the rate of penetration \n",
      "for the oil well. The machine learning models that were employed \n",
      "for this analysis are outlined as follows and their written codes \n",
      "can be found in the Appendix.\n",
      "3.1 Random Forest Regression\n",
      "Random forest can be applied to both classification and \n",
      "regression problems. It is an ensemble learning technique that \n",
      "creates a large number of decision trees during training period \n",
      "and utilizes averaging to improve the prediction accuracy \n",
      "and control over-fitting. Random forests are widely used for \n",
      "applications (such as credit scoring and spam filtering) because \n",
      "they can handle both categorical and continuous data. During \n",
      "training, random forests create a lot of decision trees\n",
      "36. Each \n",
      "tree is constructed using a random subset of the features and \n",
      "a sample of the training data. The individual decision trees \n",
      "predictions are combined by the random forest algorithm to \n",
      "provide a prediction. For a wide range of applications, random \n",
      "forests are a potent and useful machine learning technique. They \n",
      "are often good performers and are quite simple to teach and tune.\n",
      " A schematic of the decision tree regression is depicted in \n",
      "Figure. 7.\n",
      "Figure 7: Decision tree regression schematic37.\n",
      "A random forest model works by training multiple decision \n",
      "trees in parallel and uses a bagging technique to obtain a robust \n",
      "model. Usually, machine learning models have hyperparameters, \n",
      "that is, parameters in the algorithm that are constant throughout \n",
      "training that help the algorithm better understand the data \n",
      "patterns. Hyperparameters in random forest algorithm include \n",
      "max_depth, max_features, min_samples_leaf, min_samples_\n",
      "split, n_estimators. To obtain optimal performance of the \n",
      "random forest algorithm, optimal values must be selected for\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :max_depth, max_features, min_samples_leaf, min_samples_\n",
      "split, n_estimators. To obtain optimal performance of the \n",
      "random forest algorithm, optimal values must be selected for \n",
      "these hyperparameters. To get the optimal values of the random \n",
      "forest algorithm, a hyperparameter search algorithm (known as \n",
      "the randomized search algorithm) must be used. This algorithm \n",
      "helps to generate the optimal hyperparameter value for the \n",
      "hyperparameter to be utilized in the model. After implementing \n",
      "randomized search algorithm on the well data, the optimal value \n",
      "of the hyperparameters were max_depth = 31, max_features \n",
      "= sqrt, min_samples_leaf = 3, min_samples_split = 13, n_\n",
      "estimators = 666.\n",
      "3.2 Linear Regression\n",
      "Linear regression is a supervised method of machine learning \n",
      "that uses one or more input features to predict a continuous target \n",
      "variable. It is assumed that there is a linear relationship between \n",
      "the input variables and the goal variables. Linear regression \n",
      "is intended to establish the optimal line according to the data, \n",
      "minimizing the difference in predicted and real values. The \n",
      "algorithm operates by generating the coefficients of the line’s \n",
      "linear equation. Some hyperparameters in linear regression \n",
      "are copy_X and fit_Intercept. After implementing randomized \n",
      "search algorithm on the well data using linear regression as \n",
      "the base model, the optimal value of the hyperparameters were \n",
      "copy_X = True, and fit_Intercept = True. \n",
      "3.3 KNearest Neighbor\n",
      "KNearest Neighbor (KNN), as shown in Figure 8, is a \n",
      "supervised model-based machine learning technique that can \n",
      "be applied to both classification and regression models. KNN is \n",
      "not a parametric algorithm, meaning that it does not make any \n",
      "assumptions about the distribution of data. The KNN method \n",
      "is based on the hypothesis that similar occurrences will share \n",
      "similar labels. The KNN technique identifies the K closest \n",
      "neighbors to a given data point by reference to a distance metric, \n",
      "typically Euclidean, and assigns the label to the majority of these \n",
      "K neighbors for a given data point. When the algorithm is doing \n",
      "a regression, it takes the weighted average of all the target values \n",
      "from the K neighbor and uses it to predict the new value for the \n",
      "given data point. The number of neighbors is a hyperparameter \n",
      "that can be changed. Some hyperparameters in KNN algorithms \n",
      "are algorithm, leaf_size, p, weights, and n_neighbours. After\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "10\n",
      "implementing randomized search algorithm on the well data \n",
      "using KNearest neighbor as the base model, the optimal value of \n",
      "the hyperparameters were algorithm= auto, leaf_size = 10, p = 1, \n",
      "weights = distance and n_neighbours = 3.\n",
      "Figure 8: KNearest Neighbor38.\n",
      "Figure 9: SVM schematic39.\n",
      "3.4 Support Vector Machine Regression\n",
      "Support vector machine (SVM) regression is a supervised \n",
      "learning algorithm that is primarily used in classification tasks. \n",
      "It is derived from the concepts of support vector machines \n",
      "(SVM), as shown in Figure 9. The goal of SVM regression is \n",
      "to identify a function that best matches the relationship between \n",
      "the input and target variables. The SVM regression generates a \n",
      "high-dimensional hyperplane with each data point as a feature \n",
      "vector in the hyperplane space. The objective of the algorithm \n",
      "is to find the hyperplane with the greatest margin, i.e., the \n",
      "distance from the hyperplane to the nearest data point in each \n",
      "class. In the regression case, SVM chooses the hyperplane that \n",
      "contains the most data points within the given range. The range \n",
      "is the margin of tolerance, which allows some data points to fall \n",
      "outside of the range. The support vectors are the data points that \n",
      "fall within or cross the range. Some hyperparameters in support \n",
      "vector regression algorithm are C, epsilon, and kernel. After \n",
      "the implementation of the randomized search algorithm on the \n",
      "well data using support vector regression algorithm as the base \n",
      "model, the optimal values of the hyperparameters were C = 10, \n",
      "epsilon = 1 and kernel = rbf. \n",
      "3.5 Stacking Technique\n",
      "Stacking is a type of machine learning technique, whose \n",
      "algorithm is shown in Figure 10, that uses the predictive power of \n",
      "different machine learning algorithms to make better predictions \n",
      "on datasets. The stacking technique typically involves the use \n",
      "of base models and a meta model. The base models are usually \n",
      "common machine learning algorithms such as decision trees, \n",
      "random forests, and support vector machines. These base models \n",
      "are trained on a dataset and are used to make predictions; these \n",
      "predictions are then combined in a meta model, which can be \n",
      "linear regression or a neural network to make final predictions. \n",
      "It is a powerful machine learning technique since it utilizes the \n",
      "diverse knowledge of the base models. The base models used for \n",
      "this study are random forests, or support vector machines, linear \n",
      "regression, and nearest neighbors, while the meta model used is \n",
      "the linear regression model.\n",
      "Figure 10: Stacking algorithm 40.\n",
      "3.6 Voting Technique\n",
      "V oting is a machine learning technique that involves the \n",
      "integration of predictions from multiple independent models to \n",
      "form a final prediction, as shown in Figure 11. \n",
      "Figure 11: V oting Algorithm (LevelUpCoding).\n",
      "V oting technique is commonly referred to as ensemble \n",
      "voting, or majority voting, and is based on the principle that the \n",
      "integration of the opinions of multiple models can often lead \n",
      "to greater prediction accuracy than the use of a single model. \n",
      "Under the V oting algorithm, each base model is trained on \n",
      "the same data set, but with different algorithms or settings. \n",
      "During the prediction phase, each base model makes its own \n",
      "prediction based on the data it has been trained on. Finally, the \n",
      "final prediction is calculated by adding up all the predictions \n",
      "using a voting system. The base models used for this study are \n",
      "random forests, or support vector machines, linear regression, \n",
      "and nearest neighbors, while the meta model used is the linear \n",
      "regression model.\n",
      "3.7 Convolutional Neural Network\n",
      "Convolution Neural Networks (CNNs) are a type of deep \n",
      "learning algorithm that is commonly employed in the analysis \n",
      "and interpretation of visual data, including images and videos. \n",
      "CNNs are widely used for image classification, object recognition \n",
      "and image segmentation. However, not only can CNNs be used\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :and interpretation of visual data, including images and videos. \n",
      "CNNs are widely used for image classification, object recognition \n",
      "and image segmentation. However, not only can CNNs be used \n",
      "for image classification, but they can also be used in regression-\n",
      "based projects, where it is purposed to predict continuous \n",
      "variables. A convolution neural network (CNN) usually consists \n",
      "of four components: convolutional layers, pooling layers, fully \n",
      "connected layers, and output layers, as shown in Figure 12. \n",
      "These four components usually make for the architecture of \n",
      "CNNs. The main difference between a CNN and a regression-\n",
      "based CNN is the output layer (output layer) and loss function \n",
      "(loss function). The output layer in a CNN based on regression is \n",
      "distinct from that of a Softmax-based CNN. Instead of predicting \n",
      "class probabilities using a function of a Softmax, an output layer \n",
      "is typically composed of an individual neuron with a function\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :11\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "of a linear activation. This allows the network to produce a \n",
      "continuous value immediately as a regression prediction. For \n",
      "regression tasks, a loss function is often used to measure the \n",
      "difference between predicted and actual target values. Examples \n",
      "of loss functions that are commonly used include MSE (mean \n",
      "squared error) and MAE (mean absolute error). \n",
      "Figure 12: Convolutional neural network39.\n",
      "3.8 Model Evaluation\n",
      "There are metrics usually used to reflect how well the \n",
      "model has learnt patterns in the data and the performance of the \n",
      "model on the unseen (test) data set. There are metrics used for \n",
      "evaluating the performance of \n",
      "machine learning models. These \n",
      "metrics show how far a model’s prediction is from the true \n",
      "values. In this study, four error metrics are used to estimate a \n",
      "model performance on the learning patterns in the dataset and \n",
      "unseen data (test data). They are the mean absolute error (MAE), \n",
      "root mean squared error (RMSE), mean squared error (MSE) and \n",
      "coefficient of determination,\n",
      "2R –score, given by Equations (9) \n",
      "to (12) respectively. \n",
      "∑\n",
      "=\n",
      "−=\n",
      "n\n",
      "i\n",
      "i\n",
      "n\n",
      "yyMAE\n",
      "1\n",
      "ˆ              (9)\n",
      "( )∑\n",
      "=\n",
      "−=\n",
      "n\n",
      "i\n",
      "i\n",
      "n\n",
      "yyRMSE\n",
      "1\n",
      "2\n",
      "ˆ        (10)\n",
      "∑\n",
      "=\n",
      "−=\n",
      "n\n",
      "i i\n",
      "i\n",
      "y\n",
      "yy\n",
      "nMSE\n",
      "1\n",
      "ˆ1               (11)\n",
      "( )\n",
      "( )∑\n",
      "∑\n",
      "=\n",
      "=\n",
      "−\n",
      "−\n",
      "= n\n",
      "i\n",
      "i\n",
      "n\n",
      "i\n",
      "yy\n",
      "yy\n",
      "R\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "ˆ\n",
      "           (12)\n",
      "where yˆ , iy  and y  are the respective predicted, actual and \n",
      "mean values and n the number of observations.\n",
      "4. Results and Discussion\n",
      "The well data after carrying out various statistical analyses, \n",
      "the features were reduced from the previous 27 columns to 13 \n",
      "columns, , as displayed in Table 4, which is an excerpt of the well \n",
      "data used for both training and testing. It shows a sample of the \n",
      "data utilized after feature selection has been carried out, leaving \n",
      "17280 rows and 13 columns. These data were then separated \n",
      "using cross validation to train and test data respectively. The \n",
      "train data contained 10368 rows and 13 columns, while the test \n",
      "data contained 6912 rows and 13 columns. The linear regression \n",
      "model was applied to the training data and test data after the \n",
      "optimal hyperparameters had been generated. The train and \n",
      "test data were standardized such that data has a mean of 0 and \n",
      "standard deviation of 1. The results obtained using the linear \n",
      "regression model are presented in Table 5.\n",
      "The random forest regression, KNearest neighbor, and \n",
      "support vector regression (SVR) model were applied to the \n",
      "training data and test data after the optimal hyperparameters had \n",
      "been generated using the randomized search cv algorithm. The \n",
      "train and test data were standardized such that data has a mean \n",
      "of 0 and standard deviation of 1. The random forest, KNearest \n",
      "neighbor, and support vector regression (SVR) models’ results \n",
      "are presented in Tables 6–8 respectively.\n",
      "Equally, the stacking and voting techniques were applied to \n",
      "the training data and test data after the optimal hyperparameters \n",
      "had been generated using the randomized search cv algorithm \n",
      "for the base model used in the technique. The train and test data \n",
      "were standardized such that data has a mean of 0 and standard \n",
      "deviation of 1. The results obtained using the stacking and voting \n",
      "techniques are presented in Tables 9 and 10 respectively.\n",
      "The convolutional neural network (CNN) model was applied \n",
      "to the training data and test data using an epoch of 120 and a batch \n",
      "size of 32 together with an output layer of 1. The architecture of \n",
      "the CNN model created is as follows: two 1–D (one dimensional \n",
      "convolutional layers), filters (32 and 64), kernel size of two, one \n",
      "Global MaxPooling Layer, 5 hidden layers and 1 output layer. \n",
      "The train and test data were standardized such that data has a \n",
      "mean of 0 and standard deviation of 1. The results obtained \n",
      "using the CNN model are presented in Table 11.\n",
      "Table 4: Sample taken from well data used to build ML models.\n",
      "Table 5: Linear regression model results.\n",
      "Error metric Training data Test data\n",
      "RMSE 2.611 2.565\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :Table 4: Sample taken from well data used to build ML models.\n",
      "Table 5: Linear regression model results.\n",
      "Error metric Training data Test data\n",
      "RMSE 2.611 2.565\n",
      "MSE 6.819 6.582\n",
      "MAE 1.773 1.744\n",
      "2R  Score 0.639 0.639\n",
      "Table 6: Random Forest model results.\n",
      "Error Metric Training Data Test Data\n",
      "RMSE 0.469 0.676\n",
      "MSE 0.220 0.458\n",
      "MAE 0.207 0.300\n",
      "Score \n",
      "2R\n",
      "0.988 0.975\n",
      "Table 7: KNearest neighbor model results.\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "12\n",
      "Error Metric Training Data Test Data\n",
      "RMSE 0.523 0.724\n",
      "MSE 0.309 0.524\n",
      "MAE 0.201 0.239\n",
      "Score\n",
      " 2R\n",
      "0.984 0.971\n",
      "Table 8: SVM model results.\n",
      "Error Metric Training Data Test Data\n",
      "RMSE 1.724 1.669\n",
      "MSE 2.972 2.784\n",
      "MAE 0.841 0.832\n",
      "Score 0.843 0.847\n",
      "Table 9: Stacking technique results.\n",
      "Error Metric Training Data Test Data\n",
      "RMSE 0.306 0.548\n",
      "MSE 0.033 0.423\n",
      "MAE 0.094 0.300\n",
      "Score \n",
      "2R\n",
      "0.98 0.976\n",
      "Table 10: V oting Technique results.\n",
      "Error Metric Training Data Test Data\n",
      "RMSE 0.803 0.826\n",
      "MSE 1.167 1.331\n",
      "MAE 0.646 0.681\n",
      "Score \n",
      "2R\n",
      "0.938 0.926\n",
      "Table 11: CNN results.\n",
      "Error Metric Training Data Test Data\n",
      "RMSE 0.797 0.751\n",
      "MSE 1.167 1.331\n",
      "MAE 0.636 0.564\n",
      "Score \n",
      "2R\n",
      "0.924 0.928\n",
      " From the results displayed in Tables 5–11, the stacking \n",
      "technique performed better than all the models and techniques \n",
      "employed in this study for the training data. Hence, the decreasing \n",
      "order of performance of the models for the training data is as \n",
      "follows: stacking technique > random forest model > KNearest \n",
      "neighbor model > CNN model > V oting technique > SVR model \n",
      "> linear regression model. In terms of the RMSE, the stacking \n",
      "technique was 35% better than the random forest model, 41% \n",
      "better than the KNearest neighbor model, 62% better than the \n",
      "CNN model and V oting technique, 82% better than the SVR \n",
      "model and 88% better than the linear regression model. In terms \n",
      "of the MAE, the stacking technique was 55% better than the \n",
      "Random Forest model, 53% better than the KNearest Neighbour \n",
      "model, 85% better than the CNN model and V oting technique, \n",
      "89% better than the SVR model and 95% better than the linear \n",
      "regression model.\n",
      "For the testing data, generalizing across the four metrics, \n",
      "the stacking technique yet again out-performed other models. It \n",
      "was only in terms of the MAE that the KNearest neighbor model \n",
      "outperformed the stacking technique by 20%, but in terms of the \n",
      "RMSE, MSE, \n",
      "2R  Score, the stacking technique outperformed \n",
      "the KNearest Neighbour model. SVR model and linear \n",
      "regression model performed better on the test data compared to \n",
      "their performances on the train data, indicating generalization of \n",
      "the models and lack of overfitting on the training data.\n",
      "In terms of the test (unseen) data, the stacking technique \n",
      "performed better than all the traditional ML models employed \n",
      "in this study. The next to it on the ranking of the model that \n",
      "best performed on the test data was the Random Forest model, \n",
      "followed by the KNearest Neighbour model, then the CNN \n",
      "model, then the V oting technique, then the SVR model and lastly \n",
      "the linear regression model. \n",
      "In terms of the RMSE, the stacking technique was 19% better \n",
      "than the Random Forest model, 24% better than the KNearest \n",
      "Neighbour model, 27% better than the CNN model, 34% better \n",
      "than the V oting technique, 67% better than the SVR model and \n",
      "79% better than the linear regression model.\n",
      "In terms of the MAE, the stacking technique and the Random \n",
      "Forest model had the same performance score of 0.30. The \n",
      "stacking technique was still 47% better than the CNN model, \n",
      "56% better than the V oting technique, 64% better than the SVR \n",
      "model and 83% better than the linear regression model.\n",
      "Our findings in this investigation that the complex ML models \n",
      "of Stacking, V oting and CNN have the capacity to perform better \n",
      "than the traditional ML model was buttressed in the work of \n",
      "Burgos et al, which was equally corroborated in the study of \n",
      "Zhang et. al.\n",
      "19, where the CNN model developed outperformed \n",
      "all the traditional ML models in terms of accuracy and reliability. \n",
      "It can equally be deduced from this study that irrespective of the \n",
      "architecture and predictive capacity of the ML model, traditional \n",
      "ML models, with proper feature engineering and hyperparameter \n",
      "tuning, can perform better than more complex machine learning \n",
      "models.\n",
      "5. Conclusions\n",
      "A comparative analysis of machine learning algorithms in \n",
      "predicting rate of penetration during drilling was carried out in\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :models.\n",
      "5. Conclusions\n",
      "A comparative analysis of machine learning algorithms in \n",
      "predicting rate of penetration during drilling was carried out in \n",
      "this study. Data was obtained from the Daily Drilling Report \n",
      "(DDR) for an oil well. The well contains data of 17280 rows \n",
      "and 27 columns. The data preprocessing techniques of outlier \n",
      "handling, variable transformation and feature scaling were \n",
      "employed. Each of the seven machine learning techniques \n",
      "employed to predict the rate of penetration during drilling was \n",
      "able to extract meaningful information and patterns from the oil \n",
      "well data. However, some models outperformed other models by \n",
      "a distance, which reflects the predictive power of the algorithms. \n",
      "The capacity of the stacking algorithm to combine the predictive \n",
      "power of each base model gave it an edge over the rest of the \n",
      "models. The voting technique performed well, but not measured \n",
      "up to the performance of the stacking technique. Hence, the \n",
      "stacking technique is a more powerful ensembling technique \n",
      "than the voting technique. Amongst the base models, the random \n",
      "forest and KNearest Neighbors models are robust since they \n",
      "performed well on both the train and test data, while the SVM \n",
      "and linear regression models gave the highest errors on both \n",
      "the train and test data but they also showed their generalization \n",
      "capability and lower tendency to overfit. The CNN model has \n",
      "the capacity to perform well on regression-based task like rate \n",
      "of penetration predictions since it performed well on the test and \n",
      "train data.\n",
      "Statements and Declarations\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :13\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "Conflict of interest The authors declare that there is no conflict \n",
      "of interest regarding the publication of this article.\n",
      "Funding The authors received no specific funding for this \n",
      "work. Hence, the corresponding author confirms that there are \n",
      "no financial and personal relationships with other people or \n",
      "organizations that could inappropriately influence this study.\n",
      "6. References\n",
      "1. Azar HF, Saksala T, Jalali SME. Artificial neural networks models \n",
      "for rate of penetration prediction in rock drilling. J Structural \n",
      "Mechanics 2017;50(3):252-255. \n",
      "2. Rupert JP, Padro CW, Blattel SR. The effects of weight material \n",
      "type and mud formulation on penetration rate using invert oil \n",
      "systems. Paper presented at the Society of Petroleum Engineers \n",
      "(SPE) Annual Technical Conference and Exhibition 1981. \n",
      "3. Bourgoyne Jr AT, Young Jr FS. A multiple regression approach \n",
      "to optimal drilling and abnormal pressure detection. SPE J \n",
      "1974;14(04):371-384.\n",
      "4. Bingham MG. A new approach to interpreting rock drillability. \n",
      "Technical Manual Reprint Oil & Gas Journal 1965: 1-93.\n",
      "5. Elkatatny S. Real time prediction of rheological parameters of \n",
      "KCl water-based drilling fluid using artificial neural networks. \n",
      "Arabian Journal for Science and Engineering 2017;42:1655-\n",
      "1665.\n",
      "6. Mahmoud AA, Elkatatny S, Chen W, Abdulraheem A. Estimation \n",
      "of oil recovery factor for water drive sandy reservoirs through \n",
      "applications of artificial intelligence. Energies 2019;12(9):3671.\n",
      "7. Connor Shorten “Machine Learning vs. Deep Learning” Towards  \n",
      "Data Science. 2018.\n",
      "8. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature \n",
      "2015;521(7553):436–444.\n",
      "9. Otchere DA, Ganat TOA, Gholami R, Ridha S. Application \n",
      "of supervised machine learning paradigms in the prediction \n",
      "of petroleum reservoir properties: Comparative analysis of \n",
      "ANN and SVM models. Journal of Petroleum Science and \n",
      "Engineering 2021;200:108182. \n",
      "10. Bilgesu HI, Tetrick LT, Altmis U, Mohaghegh S, Ameri S. A new \n",
      "approach for the prediction of rate of penetration (ROP) values. \n",
      "Paper presented at the Society of Petroleum Engineers (SPE) \n",
      "Eastern Regional Meeting 1997; SPE–39231–MS.\n",
      "11. Arabjamaloei R, Shadizadeh S. Modeling and optimizing rate \n",
      "of penetration using intelligent systems in an Iranian southern \n",
      "oil field (Ahwaz oil field). Petroleum Science and Technology \n",
      "2011;29(16):1637–1648.\n",
      "12.  Bataee M, Mohseni S. Application of artificial intelligent systems \n",
      "in ROP optimization: a case study in Shadegan oil field. Paper \n",
      "presented at the Society of Petroleum Engineers (SPE) \n",
      "Middle East Unconventional Gas Conference and Exhibition \n",
      "2011;SPE-140029-MS.\n",
      "13. Warren TM. Penetration-rate performance of roller-cone bits. \n",
      "SPE Drill Eng 1987;2(01):9–18.\n",
      "14. AL-Mahasneh MA. Optimization Drilling Parameters \n",
      "Performance during Drilling in Gas Wells. International Journal \n",
      "of Oil, Gas and Coal Engineering 2017;5:19-26. \n",
      "15. Amar K, Ibrahim, A. Rate of penetration prediction and \n",
      "optimization using advances in artificial neural networks, a  \n",
      "comparative study. In Proceedings of the 4th International Joint \n",
      "Conference on Computational Intelligence 2012;1:647-652.\n",
      "16. Shi X, Liu G, Gong X, Zhang J, Wang J, Zhang H. An efficient \n",
      "approach for real-time prediction of rate of penetration in offshore \n",
      "drilling. Mathematical Problems in Engineering 2016;(Article ID \n",
      "3575380):1–13.\n",
      "17. Ahmed A, Elkatatny S, Abdulraheem A, Mohammed M, Ali A , \n",
      "Mohamed I. Prediction of rate of penetration of deep and tight \n",
      "formation using support vector machine. In Proceedings of the \n",
      "SPE Kingdom of Saudi Arabia Annual Technical Symposium \n",
      "and Exhibition, Dammam, Saudi Arabia. 2018; SPE–192316–\n",
      "MS.\n",
      "18. Maurer WC. The, “perfect-cleaning” theory of rotary drilling. J \n",
      "Pet Technol 1962;14(11):1270-1274.\n",
      "19. Zhang Y, Zhang X, Chen Y. Deep neural networks for predicting \n",
      "rate of penetration in drilling. Journal of Petroleum Science and \n",
      "Engineering 2018;165:734-743.\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :Pet Technol 1962;14(11):1270-1274.\n",
      "19. Zhang Y, Zhang X, Chen Y. Deep neural networks for predicting \n",
      "rate of penetration in drilling. Journal of Petroleum Science and \n",
      "Engineering 2018;165:734-743.\n",
      "20.  Zhao Y, Noorbakhsh A, Koopialipoor M, Azizi A, Tahir MM. \n",
      "A new methodology for optimization and prediction of rate \n",
      "of penetration during drilling operations. Engineering with \n",
      "Computers 2020;36:587-595.\n",
      "21. Abdulmalek A, Abdulwahab A, Salaheldin E, Abdulazeez A. New \n",
      "artificial neural networks model for predicting rate of penetration \n",
      "in deep shale formation. Sustainability 2019;11(22): 6527. \n",
      "22. Hareland G, Hoberock LL. Use of drilling parameters to predict \n",
      "in-situ stress bounds. Paperpresented at the SPE/IADC Drilling \n",
      "Conference. Netherlands 1993:SPE-25727-MS. \n",
      "23. Ashrafi SB, Anemangely M, Sabah M, Ameri MJ. Application of \n",
      "hybrid artificial neural networks for predicting rate of penetration \n",
      "(ROP): a case study from Marun oil field. Journal of Petroleum \n",
      "Science and Engineering 2019;175:604-623.\n",
      "24. Iqbal F. Drilling optimization technique using real time \n",
      "parameters. SPE Russian Oil & Gas Technical Conference and \n",
      "Exhibition, Moscow, Russia, 2008. \n",
      "25. Burgos CE, Zhang T, Li J, Zhang C, Chen S. ROP prediction \n",
      "using convolutional neural networks for Paleozoic shale drilling. \n",
      "Journal of Petroleum Science and Engineering 2019;17:633-\n",
      "641.\n",
      "26. Monazami M, Hashemi A, Shahbazian M. Drilling rate of \n",
      "penetration prediction using artificial neural network: A case \n",
      "study of one of Iranian Southern oil fields. Journal of Oil and \n",
      "Gas Business 2012.\n",
      "27. Abbas AK, Rushdi S, Alsaba M, Al Dushaishi MF. Drilling rate of \n",
      "penetration prediction of high-angled wells using artificial neural \n",
      "networks. J. Energy Resour. Technol 2019;141(11):112904.\n",
      "28. Miyora TO. 2014. Modeling and optimization of geothermal \n",
      "drilling parameters: A case study of well MW-17 in Menengai \n",
      "Kenya, MS Thesis. University of Iceland 2014.\n",
      "29. Al-AbdulJabbar A, Elkatatny S, Mahmoud AA, et al. Prediction \n",
      "of the rate of penetration while drilling horizontal carbonate \n",
      "reservoirs using the self-adaptive artificial neural networks \n",
      "technique. Sustainability 2020;12(4):1376.\n",
      "30. Wang K, Zhang Y, Zhang X, Wang Y. A hybrid ensemble \n",
      "learning approach for rate of penetration prediction in oil and \n",
      "gas drilling. Journal of Petroleum Science and Engineering \n",
      "2020;194:107424.\n",
      "31.  Liu N, Gao H, Zhen Z, Hu Y, Duan L. A stacked generalization  \n",
      "ensemble model for optimization and prediction of the gas well  \n",
      "rate of penetration: a case study in Xinjiang. Journal of Petroleum \n",
      "Exploration and Production Technology 2021;6:1595-1608.\n",
      "32. Moraveji MK, Naderi M. Drilling rate of penetration prediction \n",
      "and optimization using response surface methodology and bat \n",
      "algorithm. Journal of National Gas Science and Engineering \n",
      "2016;31:829–841. \n",
      "33. Motahhari HR, Hareland G, Nygaard R, Bond B. Method of \n",
      "optimizing motor and bit performance for maximum ROP. J Can \n",
      "Pet Technol 2009;48(06):44-49. \n",
      "34. Hareland G, Rampersad PR. Drag - Bit Model Including Wear. \n",
      "America/Caribbean Petroleum Engineering Conference 1994: \n",
      "SPE-26957-MS.\n",
      "35. Bourgoyne Jr AT, Millheim KK, Chenevert ME, Young Jr FS.\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "14\n",
      "Applied drilling engineering. SPE Textbook Series 1991;2:ISBN: \n",
      "978-1-55563-001-0.\n",
      "36. Quinlan JR. Induction of decision trees. Machine Learning \n",
      "1986;1(1):81-106. \n",
      "37. SametGirgin, Decision Tree Regression in 6 Steps with Python, \n",
      "PursuitData (Medium). 2019.\n",
      "38. Javat (2022).  \n",
      "39. Pandey YN, Rastogi A, Kainkaryam S, Bhattacharya S, Saputelli \n",
      "L. Overview of Machine Learning and Deep Learning Concepts. \n",
      "Machine Learning in the Oil and Gas Industry 2020:75-152.\n",
      "40. GeeksForGeeks (2022)\n",
      "7 Appendix: Codes for the different algorithms employed in this work.\n",
      "Random Forest Algorithm\n",
      "Linear Regression Algorithm\n",
      "K Nearest Neighbour Algorithm\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :15\n",
      "Olafadehan OA., et al., J Petro Chem Eng  | V ol: 1 & Iss: 1\n",
      "SVR Algorithm\n",
      "Stacking Algorithm\n",
      "Voting Algorithm\n",
      "\n",
      " \u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m Write a concise and detailed summary of the following texts. Make sure to capture the technical terms in it. its very important,\n",
      "text :J Petro Chem Eng | V ol: 1 & Iss:1Olafadehan OA., et al.,\n",
      "16\n",
      "CNN Algorithm Code\n",
      "\n",
      " \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NEW USER\\anaconda3\\envs\\genv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\NEW USER\\anaconda3\\envs\\genv\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\NEW USER\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (12783 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "This study presents a comparative analysis of machine learning (ML) algorithms in predicting the rate of penetration (ROP) during drilling in the petroleum industry. The authors evaluated the performance of seven ML algorithms: Support Vector Machine Regression (SVR), Random Forest Regression (RF), Linear Regression (LR), K-Nearest Neighbors (KNN), Stacking technique, Voting technique, and Convolutional Neural Network (CNN). The data used for this investigation was obtained from an oil well in Nigeria and was split into training and testing sets in a 60:40 ratio. The results showed that the Stacking technique had the best performance, with an accuracy of 99.8% and 97.5% on the training and testing data sets, respectively, in terms of the R-squared (R2) score. The Voting technique and CNN model also performed well, with accuracies of 93.6% and 92.4%, and 92.6% and 92.8%, respectively, on the training and testing data sets.\n",
      "\n",
      "The study highlights the potential of ML algorithms in predicting ROP during drilling, which can help optimize the drilling process and reduce costs. The authors used various technical terms, including Artificial Intelligence (AI), Machine Learning (ML), Artificial Neural Network (ANN), Convolutional Neural Network (CNN), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Coefficient of Determination (R2). The study demonstrates the effectiveness of ML algorithms in gaining valuable insights into drilling data and making real-time predictions of ROP.\n",
      "\n",
      "Key technical terms used in the study include:\n",
      "\n",
      "* Machine Learning (ML) algorithms\n",
      "* Support Vector Machine Regression (SVR)\n",
      "* Random Forest Regression (RF)\n",
      "* Linear Regression (LR)\n",
      "* K-Nearest Neighbors (KNN)\n",
      "* Stacking technique\n",
      "* Voting technique\n",
      "* Convolutional Neural Network (CNN)\n",
      "* Artificial Intelligence (AI)\n",
      "* Artificial Neural Network (ANN)\n",
      "* Mean Absolute Error (MAE)\n",
      "* Root Mean Squared Error (RMSE)\n",
      "* Coefficient of Determination (R2)\n",
      "* Rate of Penetration (ROP)\n",
      "* Rotary speed (RPM)\n",
      "* Weight on bit (WOB)\n",
      "* Daily Drilling Report (DDR)\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The petroleum industry relies heavily on drilling, a process of boring holes into the earth's subsurface to reach hydrocarbon reserves. The most common drilling method used today is rotary drilling, which applies an axial force to a rotating drill bit to achieve penetration. A key parameter in rotary drilling is the Rate of Penetration (ROP), which is the depth of penetration accomplished per unit time, typically measured in feet per hour (ft/h). However, evaluating ROP is challenging due to its complex relationship with other drilling parameters, such as mud viscosity, mud density, filtration loss, bit type and weight, porosity, rock abrasivity, formation elasticity, formation stress, and permeability.\n",
      "\n",
      "To maximize ROP and mitigate drilling costs, it is essential to understand the relationship between ROP and other operational parameters. Mathematical models, such as the Bourgoyne and Young model and the Bingham model, have been used to model this relationship, but their accuracy varies due to differences in drilling parameters considered. Alternative approaches, such as data-driven models using Artificial Intelligence (AI), have been employed to improve ROP prediction.\n",
      "\n",
      "AI methods, including Machine Learning (ML) and Deep Learning (DL), can be trained on large datasets generated during oil field operations, including drilling data, production data, seismic data, and mud log data. These models can learn from the data and make future predictions, providing insights into drilling problems, such as predicting drill bit wear, real-time predictions of alterations in drilling fluid rheology, and estimating oil recovery factor for water drive sandy reservoirs. By utilizing various algorithmic strategies, ML and DL enable systems to perform computational tasks without explicit programming and learn from the data, allowing for pattern recognition and prediction of complex relationships between drilling parameters and ROP.\n",
      "\n",
      "Technical terms captured:\n",
      "\n",
      "* Rotary drilling\n",
      "* Rate of Penetration (ROP)\n",
      "* Axial force\n",
      "* Mud viscosity\n",
      "* Mud density\n",
      "* Filtration loss\n",
      "* Bit type and weight\n",
      "* Porosity\n",
      "* Rock abrasivity\n",
      "* Formation elasticity\n",
      "* Formation stress\n",
      "* Permeability\n",
      "* Bourgoyne and Young model\n",
      "* Bingham model\n",
      "* Artificial Intelligence (AI)\n",
      "* Machine Learning (ML)\n",
      "* Deep Learning (DL)\n",
      "* Drilling fluid rheology\n",
      "* Oil recovery factor\n",
      "* Water drive sandy reservoirs\n",
      "* Algorithmic strategies\n",
      "* Pattern recognition\n",
      "* Computational tasks\n",
      "* Explicit programming\n",
      "* Data-driven models\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "Machine learning (ML) enables systems to perform computational tasks without explicit programming by utilizing various algorithmic strategies to learn from data. ML involves finding patterns in numerical data by applying computer algorithms to convert data into numerical form, which can be in the form of pictures, music, numbers, or alphabetical data. Machine learning models, such as linear regression, logistic regression, decision trees, random forest, K-Means, and K-Nearest Neighbors, are used for prediction, data sub-grouping, and sound detection. These models are categorized into supervised learning, where input objects and desired output values train a model, and unsupervised learning, where the data has no target label and the model aims to find hidden patterns.\n",
      "\n",
      "A branch of ML is deep learning (DL), which mimics the operation of the human brain by receiving, processing, and transmitting information. DL is essentially a neural network with one or more layers, consisting of components such as dendrites (input nodes), cell body (activation function), synapse (weightage of each input), and axon terminal (output node). Neural networks, also known as deep learning, are massively parallel and can be represented by a typical feed-forward neural network architecture.\n",
      "\n",
      "Key technical terms:\n",
      "\n",
      "* Machine learning (ML)\n",
      "* Algorithmic strategies\n",
      "* Linear regression\n",
      "* Logistic regression\n",
      "* Decision trees\n",
      "* Random forest\n",
      "* K-Means\n",
      "* K-Nearest Neighbors\n",
      "* Supervised learning\n",
      "* Unsupervised learning\n",
      "* Deep learning (DL)\n",
      "* Neural networks\n",
      "* Dendrites (input nodes)\n",
      "* Cell body (activation function)\n",
      "* Synapse (weightage of each input)\n",
      "* Axon terminal (output node)\n",
      "* Feed-forward neural network architecture\n",
      "* Massively parallel neural networks\n",
      "\n",
      "These technical terms are crucial in understanding the concepts of machine learning, deep learning, and neural networks, which are essential in the field of artificial intelligence.\n",
      "\n",
      "The text discusses the application of machine learning techniques, specifically artificial neural networks (ANN), convolutional neural networks (CNN), and recurrent neural networks (RNN), in the field of petroleum engineering. The authors highlight the use of CNNs in image processing and prediction, as well as the components of a CNN, including convolutional layers, feature extractors (filters), pooling layers, hidden layers, and output layers. The text also explains the role of weights in connecting layers and facilitating information flow, and the use of activation functions to convert data into a more computer-interactive format.\n",
      "\n",
      "The authors reference several studies that have used machine learning models to predict the rate of penetration (ROP) in drilling operations. For example, Bilgesu et al. used an ANN to develop an ROP model based on several operating parameters, including tooth wear, rotary speed, torque, and weight on bit. The model was trained on a dataset of 500 points with nine features and achieved a coefficient of determination (R²) between 0.902 and 0.982.\n",
      "\n",
      "Another study by Arabjamaloei and Shadizadeh used a combination of an ANN and a genetic algorithm (GA) to predict ROP values. The model was trained on a dataset of 300 points with seven features, including bit type, formation properties, and bit operating conditions. The study found that the neural network was valid for predicting ROP values for other datasets within the range of the training data.\n",
      "\n",
      "The text also references a comparative evaluation of models for estimating ROP, including the Bingham, Warren, and Bourgoyne and Young models. The study found that the models performed well in predicting ROP values for wells drilled with roller cone and PDC bits, but noted that the threshold overbalance weight (oBW) was neglected due to a lack of drill-off test data.\n",
      "\n",
      "Key technical terms used in the text include:\n",
      "\n",
      "* Artificial neural network (ANN)\n",
      "* Convolutional neural network (CNN)\n",
      "* Recurrent neural network (RNN)\n",
      "* Convolutional layers\n",
      "* Feature extractors (filters)\n",
      "* Pooling layers\n",
      "* Hidden layers\n",
      "* Output layers\n",
      "* Weights\n",
      "* Activation functions\n",
      "* Rate of penetration (ROP)\n",
      "* Genetic algorithm (GA)\n",
      "* Coefficient of determination (R²)\n",
      "* Mean-square error\n",
      "* Bingham model\n",
      "* Warren model\n",
      "* Bourgoyne and Young model\n",
      "* Threshold overbalance weight (oBW)\n",
      "* Drill-off test data.\n",
      "\n",
      "Here is a concise and detailed summary of the provided text, capturing the technical terms:\n",
      "\n",
      "The study of drilling operations has led to the development of various models to predict the rate of penetration (ROP) in gas and oil wells. A previous study neglected the threshold overbalance (oBW) due to the lack of a drill-off test, but still found that the Bourgoyne and Young model exhibited the highest predictive performance among the models examined. \n",
      "\n",
      "Mahasneh's mathematical model considered factors such as weight on bit (WOB), bit rotation speed (RPM), flow rate (FR), formation strength, depth, and formation compaction to predict ROP in gas wells. The model was used to optimize drilling parameters, resulting in a 15% increase in ROP and a 10% reduction in drilling costs.\n",
      "\n",
      "Other studies have compared the predictive accuracy of physics-based equations, such as the Bingham model and the Bourgoyne and Young model, with artificial neural networks (ANN) and other machine learning techniques. Amar and Ibrahim's study used ANN models with input parameters such as formation depth, equivalent circulating density (ECD), WOB, drill string rotation (DSR), pore pressure gradient, drill bit tooth wear, and Reynolds number function. The results showed that the ANN models were highly accurate for estimating ROP compared to empirical equations.\n",
      "\n",
      "Shi et al. used the Extreme Learning Machine (ELM) and Upper-layer solution-ware (USA) techniques to predict ROP, utilizing input parameters such as formation properties, rig hydraulics, bit specifications, WOB, rotary speed, and mud properties. The performance of these models was compared to an ANN model, with the USA technique exhibiting the highest predictive performance.\n",
      "\n",
      "Ahmed et al. applied a support vector machine (SVM) model to estimate ROP in shale formations, using input features such as WOB, rotary speed, pump flow rate, standpipe pressure, drilling torque, mud density, plastic viscosity, funnel viscosity, yield point, and solid content. The SVM model outperformed the Bourgoyne and Young model, with a higher coefficient of determination (R²) and lower absolute percentage error.\n",
      "\n",
      "Finally, Elkatany developed an ANN model to predict ROP using data from three vertical wells in an offshore oilfield, considering drilling parameters and drilling fluid properties. The study demonstrated the importance of drilling optimization and the use of machine learning techniques to improve the efficiency and cost-effectiveness of drilling operations.\n",
      "\n",
      "Technical terms used in the summary include:\n",
      "\n",
      "* Rate of penetration (ROP)\n",
      "* Weight on bit (WOB)\n",
      "* Bit rotation speed (RPM)\n",
      "* Flow rate (FR)\n",
      "* Formation strength\n",
      "* Depth\n",
      "* Formation compaction\n",
      "* Equivalent circulating density (ECD)\n",
      "* Drill string rotation (DSR)\n",
      "* Pore pressure gradient\n",
      "* Drill bit tooth wear\n",
      "* Reynolds number function\n",
      "* Artificial neural networks (ANN)\n",
      "* Support vector machine (SVM)\n",
      "* Extreme Learning Machine (ELM)\n",
      "* Upper-layer solution-ware (USA)\n",
      "* Coefficient of determination (R²)\n",
      "* Mean absolute error (MAE)\n",
      "* Root mean square error (RMSE)\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The study aimed to predict the Rate of Penetration (ROP) in an offshore oilfield using an Artificial Neural Network (ANN) model. The ANN-ROP model was developed based on drilling parameters and drilling fluid properties data collected from three vertical wells. The model was trained using data from two wells and then validated using data from the third well to evaluate its accuracy. \n",
      "\n",
      "Technical terms captured: \n",
      "- Rate of Penetration (ROP)\n",
      "- Artificial Neural Network (ANN)\n",
      "- Drilling parameters\n",
      "- Drilling fluid properties \n",
      "- Offshore oilfield \n",
      "- Vertical wells \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "The provided text discusses the application of artificial intelligence (AI) techniques, specifically artificial neural networks (ANNs) and deep convolutional neural networks (CNNs), to predict the rate of penetration (ROP) during drilling operations. The performance of these models is compared to traditional ROP models, such as those proposed by Bingham, Bourgoyne and Young, and Maurer.\n",
      "\n",
      "The technical terms used in the text include:\n",
      "\n",
      "1. **ANN-ROP model**: An artificial neural network model used to predict the rate of penetration.\n",
      "2. **CNN model**: A deep convolutional neural network model used to predict the ROP.\n",
      "3. **Coefficient of determination (R²)**: A statistical measure used to evaluate the performance of the models, with values ranging from 0 to 1, where 1 indicates perfect prediction.\n",
      "4. **Average absolute percentage error (AAPE)**: A measure of the average difference between predicted and actual values, expressed as a percentage.\n",
      "5. **Mean absolute percentage error (MAPE)**: A loss function used to train the CNN model.\n",
      "6. **Levenberg-Marquardt (LM) function**: A training function used in combination with the neural networks to estimate the penetration rates.\n",
      "7. **Scaled Conjugate Gradient (SCG) and One-Step Secant (OSS)**: Other training functions used in the ANN-ROP models.\n",
      "8. **Artificial Bee Colony (ABC) algorithm**: An optimization algorithm used to optimize the ROP.\n",
      "\n",
      "The results of the studies discussed in the text indicate that the AI-based models, particularly the ANN-ROP and CNN models, outperform traditional ROP models in terms of accuracy and reliability. The most important features for predicting ROP are found to be the weight on bit, rotary speed, and mud flow rate. The optimization of ROP using the ABC algorithm results in an approximate improvement of 20-30% in the rate of penetration.\n",
      "\n",
      "The key findings of the studies are:\n",
      "\n",
      "* The ANN-ROP model exhibits superior performance over traditional ROP models, with a coefficient of determination (R²) of 0.99 and an average absolute percentage error (AAPE) of 5%.\n",
      "* The CNN model outperforms other machine learning models, with a mean absolute percentage error (MAPE) of 4%.\n",
      "* The ANN-ROP model using the Levenberg-Marquardt (LM) function demonstrates the best prediction performance, achieving a regression coefficient (R²) of 0.91 in training and 0.89 in testing.\n",
      "* The optimization of ROP using the ABC algorithm results in an approximate improvement of 20-30% in the rate of penetration.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The text discusses various studies that utilize machine learning models and optimization algorithms to predict the Rate of Penetration (ROP) in drilling operations. The studies employ techniques such as Artificial Neural Networks (ANN), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Biogeography-based Optimizer (BBO), and Imperialist Competitive Algorithm (ICA) to develop hybrid ROP models. The models are validated using datasets from onshore oilfields, including the Marun oilfield in Iran, and are compared to traditional models such as Non-linear Multiple Regression (NLMR) and Linear Multiple Regression (LMR) techniques.\n",
      "\n",
      "The technical terms used in the studies include:\n",
      "\n",
      "* ANN-ROP model: an Artificial Neural Network model for predicting ROP\n",
      "* AAPE: Average Absolute Percentage Error, used to evaluate the model's performance\n",
      "* R-squared (R²): a regression coefficient used to evaluate the model's performance\n",
      "* GA, PSO, BBO, and ICA: optimization algorithms used to develop hybrid ROP models\n",
      "* MLP and RBF: Multi-Layer Perception and Radial-Based Function neural network architectures, respectively\n",
      "* Tan-sigmoid: an activation function used in the hidden layers and output layer of the neural networks\n",
      "* RMSE: Root Mean Square Error, used to evaluate the model's performance\n",
      "* MAPE: Mean Absolute Percentage Error, used to evaluate the model's performance\n",
      "* CNN: Convolutional Neural Network, used to predict ROP during rotary drilling operations\n",
      "\n",
      "The studies demonstrate the effectiveness of machine learning models and optimization algorithms in predicting ROP and optimizing drilling parameters. The results show that the hybrid models, such as PSO-MLP and PSO-RBF, exhibit superior predictive accuracy compared to traditional models. The CNN model, in particular, is able to learn complex non-linear relationships between drilling parameters and ROP, achieving a MAPE of 9.3% on the test set.\n",
      "\n",
      "The input features used in the studies include:\n",
      "\n",
      "* Weight on bit (WOB)\n",
      "* Rotational speed of the drill bit (RPM)\n",
      "* Pump inlet flow rate\n",
      "* Pore pressure pump pressure\n",
      "* Gamma ray\n",
      "* Density log\n",
      "* Shear wave velocity\n",
      "* Hook load\n",
      "* Flow rate\n",
      "\n",
      "The studies highlight the importance of using real-time drilling parameters to optimize drilling operations and demonstrate the potential of machine learning models and optimization algorithms in improving drilling efficiency and reducing costs.\n",
      "\n",
      "Here is a concise and detailed summary of the provided text, capturing the technical terms:\n",
      "\n",
      "The model demonstrated good generalization performance, with an accuracy of approximately 10.2%. This suggests that the Convolutional Neural Network (CNN) approach effectively modeled the complex relationship between drilling parameters and Rate of Penetration (ROP), outperforming traditional models. The CNN model also showed good generalizability to new data, enabling potential applications in optimizing drilling operations through accurate ROP predictions. Additionally, a separate study by Monazami et al. utilized an Artificial Neural Network (ANN) to predict ROP, indicating the effectiveness of machine learning techniques, such as CNN and ANN, in modeling drilling operations and improving efficiency. \n",
      "\n",
      "Technical terms captured:\n",
      "- Convolutional Neural Network (CNN)\n",
      "- Rate of Penetration (ROP)\n",
      "- Artificial Neural Network (ANN)\n",
      "- Generalization performance \n",
      "- Drilling parameters \n",
      "- Drilling operations\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The text discusses various studies that utilize artificial intelligence and machine learning techniques to predict the Rate of Penetration (ROP) in drilling operations. The studies employed different approaches, including Artificial Neural Networks (ANN), self-adaptive differential evolution (SADE), and hybrid ensemble learning.\n",
      "\n",
      "The input variables used to predict ROP include formation strength, depth, formation compaction, pressure differential, bit diameter, weight on bit (WOB), bit rotation (RPM), and bit hydraulics. Other variables such as rotary speed, torque, gamma ray, resistivity, and bulk density data were also used.\n",
      "\n",
      "The studies achieved high accuracy in predicting ROP, with average errors ranging from 5% to 9.1%. The models were trained and tested using datasets from various drilling operations, including deviated wells in southern Iraq and the Gulf of Mexico.\n",
      "\n",
      "The technical terms used in the studies include:\n",
      "\n",
      "* Artificial Neural Network (ANN)\n",
      "* Self-adaptive differential evolution (SADE)\n",
      "* Hybrid ensemble learning\n",
      "* Support Vector Regression (SVR)\n",
      "* Random Forest Regression (RFR)\n",
      "* Gradient Boosting\n",
      "* Tan-sigmoid activation function\n",
      "* Regression coefficient (R²)\n",
      "* Mean Absolute Percentage Error (MAPE)\n",
      "* Weight on Bit (WOB)\n",
      "* Bit rotation (RPM)\n",
      "* Bit hydraulics\n",
      "* Formation petrophysical properties (gamma ray, resistivity, and bulk density)\n",
      "\n",
      "The studies concluded that the use of artificial intelligence and machine learning techniques can improve the accuracy and efficiency of drilling operations, and can be used to optimize drilling parameters and reduce costs. The models developed can be used to predict ROP in various drilling environments, including geothermal drilling and horizontal carbonate reservoirs.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The text discusses various approaches to modeling the Rate of Penetration (ROP) in drilling operations, which is crucial for optimizing drilling processes. Several machine learning and ensemble learning models have been proposed to predict ROP, including:\n",
      "\n",
      "1. **Weighted Average Ensemble Method**: A model that combines the predictions of Support Vector Regression (SVR), Random Forest Regression (RFR), and Gradient Boosting Regression (GBR) using a weighted average ensemble method.\n",
      "2. **Stacked Generalization Ensemble Model**: A model that combines the predictions of six machine learning models: SVR, Extremely Randomized Trees (XRT), Random Forest (RF), Gradient Boosting Machine (GBM), Light Gradient Boosting Machine (LightGBM), and Extreme Gradient Boosting (XGB).\n",
      "3. **Response Surface Methodology (RSM)**: A statistical method used to investigate the simultaneous effect of six variables on penetration rate using real field drilling data.\n",
      "4. **Bat Algorithm (BA)**: A optimization algorithm used to identify the optimal range of factors to maximize drilling rate of penetration.\n",
      "\n",
      "The models were trained on datasets of historical ROP data and drilling parameters, and their performance was evaluated using metrics such as Root Mean Square Error (RMSE) and R-squared (R²) value. The results showed that the ensemble learning models can significantly improve the accuracy of ROP prediction, with the stacked generalization ensemble model achieving an RMSE of 0.4853 m/h and an R² value of 0.9568.\n",
      "\n",
      "The study also highlighted the importance of feature selection and optimization of ROP parameters, with techniques such as **Pearson Correlation Analysis**, **Savitzky-Golay Smoothing Filter**, and **Particle Swarm Optimization (PSO)** being used to identify the most important features and optimize the ROP parameters.\n",
      "\n",
      "Overall, the study aims to analyze the performance of machine learning and deep learning techniques in predicting ROP, which can contribute to drilling planning and optimization of future wells, reducing non-productive time (NPT) and expenses in the oil and gas industry.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The text discusses the limitations of previous models for estimating Rate of Penetration (ROP) in drilling operations, citing the non-comprehensiveness of these models due to the large number of factors affecting ROP. To address this, various ROP estimation models have been developed using two approaches: physics-based and data-driven. \n",
      "\n",
      "The physics-based approach involves mathematical modeling techniques to evaluate relationships between dependent (ROP) and independent parameters. Several models are mentioned, including:\n",
      "\n",
      "1. **Cunningham model**: R = K × (W - W₀) × N, where R is the rate of penetration, K is the constant of proportionality, W₀ is the threshold weight on bit, and N is the rotary speed.\n",
      "2. **Bingham model**: R = a × (W - b) × (BD)^c, where W is the weight-on-bit, BD is the bit diameter, and a, b, and c are dimensionless constants.\n",
      "3. **Maurer model**: R = (W × s) / (D × ρ), where W is the weight, s is the confined rock strength, D is the depth, and ρ is the rock density.\n",
      "4. **Motahhari et al. model**: R = fw × G × (α × N) × (γ × W), where fw is the dimensionless wear function, G is a model coefficient, α and γ are ROP model exponents, and N is the rotary speed.\n",
      "5. **Hareland and Rampersad model**: R = cN × vA, where cN is the number of cutters and vA is the area of rock compressed ahead of a cutter.\n",
      "\n",
      "Other models mentioned include the **Bourgoyne and Young model**, which uses multiple linear regression to optimize controllable parameters during drilling operations. The model is given by: R = ∏[i=1 to 8] (ai × Fi), where ai are constants and Fi are functions of independent parameters such as formation strength, weight on bit, and bit teeth wear.\n",
      "\n",
      "These models aim to provide accurate estimates of ROP, which is essential for optimizing drilling operations and reducing costs. The development of these models highlights the importance of considering multiple factors that affect ROP, including rock properties, drilling parameters, and bit design. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The text discusses the Bourgyone and Young model, a physics-based approach for estimating Rate of Penetration (ROP) in drilling operations. The model includes several functions, such as:\n",
      "\n",
      "1. **Formation strength function (aeF)**: a function that estimates the strength of the rock formation.\n",
      "2. **Normal compaction function (DaeF)**: a function that estimates the normal compaction of the rock formation.\n",
      "3. **Under compaction function (cpg)**: a function that estimates the under compaction of the rock formation.\n",
      "4. **Pressure differential function (ρ)**: a function that estimates the pressure differential in the wellbore.\n",
      "5. **Weight on bit function (w)**: a function that estimates the weight on the drill bit.\n",
      "6. **Rotary speed function (t)**: a function that estimates the rotary speed of the drill bit.\n",
      "7. **Bit tooth wear function (haF)**: a function that estimates the wear on the drill bit teeth.\n",
      "8. **Bit hydraulic function**: a function that estimates the hydraulic performance of the drill bit.\n",
      "\n",
      "However, the physics-based approach has limitations due to the failure to consider all parameters affecting drilling operations and the choice of empirical constants. To overcome these limitations, data-driven approaches using **Logging While Drilling (LWD)** data and artificial intelligence (AI) techniques have been proposed.\n",
      "\n",
      "The text also discusses the application of AI models for ROP estimation, as suggested by Bilgesu et al. The proposed methodology involves collecting data from the **Daily Drilling Report (DDR)**, which includes parameters such as weight on bit, pump flow rate, mud weight, mud type, drill bit diameter, and wellbore trajectory. The data is then filtered to remove uncertainties and define suitable parameters, resulting in a dataset with 27 variables, 17280 rows, 0% missing cells, and 0% duplicate rows.\n",
      "\n",
      "Key technical terms in this text include:\n",
      "\n",
      "* **Bourgyone and Young model**: a physics-based approach for estimating ROP\n",
      "* **Logging While Drilling (LWD)**: a technique for collecting data during drilling operations\n",
      "* **Artificial intelligence (AI)**: a technique used for ROP estimation\n",
      "* **Rate of Penetration (ROP)**: a measure of drilling speed\n",
      "* **Daily Drilling Report (DDR)**: a report that contains data on drilling operations\n",
      "* **Data-driven approach**: an approach that uses data to estimate ROP\n",
      "* **Physics-based approach**: an approach that uses physical models to estimate ROP.\n",
      "\n",
      "Here is a concise and detailed summary of the text:\n",
      "\n",
      "The study employs data preprocessing techniques, also known as feature engineering, to extract relationships and insights between parameters in the dataset. The techniques used include:\n",
      "\n",
      "1. **Outlier handling**: Dealing with data points that vary significantly from the majority of the dataset. The capping technique was used, which involves imputing the interquartile range of the variable with the outlier.\n",
      "2. **Variable transformation**: Changing a variable's scale or distribution to satisfy requirements or enhance the performance of statistical models. LogTransformer and BoxCoxTransformer were used to treat skewed variables.\n",
      "3. **Feature scaling**: Changing the scale of numerical features to prevent some from predominating others. The standard scaler was used to scale features to have a mean of 0 and a standard deviation of 1.\n",
      "\n",
      "These techniques were applied to a dataset with features including:\n",
      "\n",
      "* **Depth**: The actual depth at which drilling is taking place (numerical, meters)\n",
      "* **Lag Depth**: Time delay or lag between the measured depth and the corresponding ROP value (numerical, meters)\n",
      "* **WHO**: Weight on String (numerical, kilopounds)\n",
      "* **ROP**: Rate of Penetration (numerical, meters per hour)\n",
      "* **RPM**: Turbine Speed (numerical, revolutions per minute)\n",
      "* **Torque**: Rotational force of drill string (numerical, kilopounds-feet)\n",
      "* **SPP**: Standpipe Pressure (numerical, pounds per square inch)\n",
      "* **Flow**: Inflow rate of drilling fluid pumped into the well (numerical)\n",
      "\n",
      "The preprocessing techniques were used to match key relationships between the input parameters and the target variable, and to produce better model performances. The study used various statistical manipulations and transformations, including exploratory data analysis, missing data imputation, and discretization, to process the data into forms that are more understandable by machine learning algorithms.\n",
      "\n",
      "The provided text outlines various technical parameters related to drilling operations, specifically focusing on turbine speed, torque, pressure, and fluid flow. The key terms and their corresponding units are:\n",
      "\n",
      "1. **RPM (TURBIN)**: Refers to the rotational speed of the turbine, measured in revolutions per minute (rev/min).\n",
      "2. **Torque**: The rotational force of the drill string, measured in kilo-pound feet (klb.ft).\n",
      "3. **SPP (Standpipe Pressure)**: The pressure measured at the standpipe, expressed in pounds per square inch (psi).\n",
      "4. **Flow**: The inflow rate of drilling fluid pumped into the wellbore during drilling, measured in gallons per minute (gpm).\n",
      "5. **Mw (In)**: The total volume of drilling mud pumped into the wellbore during a specific period, measured in pounds per cubic foot (pcf).\n",
      "6. **Mw (Out)**: The total volume of drilling mud pumped out of the wellbore during a specific period, also measured in pounds per cubic foot (pcf).\n",
      "7. **PIT#1 and PIT#2**: The volume of mud in the first and second mud pits or mud tanks, respectively, measured in barrels (Bbl).\n",
      "\n",
      "These technical terms are crucial in monitoring and controlling drilling operations, ensuring efficient and safe drilling practices.\n",
      "\n",
      "The provided text appears to be a research article in the field of Petroleum Chemistry Engineering, specifically focusing on drilling operations and the application of machine learning algorithms to predict the Rate of Penetration (ROP). Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "**Data Description**\n",
      "\n",
      "The article describes a dataset containing various features related to drilling operations, including:\n",
      "\n",
      "1. Mud pit volumes (PIT#1 to PIT#6) in barrels (Bbl)\n",
      "2. Total Actual Time (TOT ACT) in Bbl\n",
      "3. Steel volume consumed during drilling in Bbl\n",
      "4. Overpull (additional force applied to the drilling assembly) in kilopounds (klb)\n",
      "5. Flow paddle (percentage of drilling fluid circulating through the wellbore) in percentage (%)\n",
      "6. Bit position (vertical depth of the drilling bit) in meters (m)\n",
      "7. Hook position (vertical position of the drilling hook) in meters (m)\n",
      "8. String weight (total weight of the drill string) in kilopounds (klb)\n",
      "9. Drag (resistance encountered by the drill string and bit) in kilopounds (klb)\n",
      "\n",
      "**Statistical Analysis**\n",
      "\n",
      "The article presents descriptive statistics (mean, standard deviation, minimum, 25%, 50%, 75%, and maximum) for the ROP variable, which is the target variable for prediction. The statistics are presented in Table 2.\n",
      "\n",
      "**Correlation Analysis**\n",
      "\n",
      "The article presents a Pearson correlation analysis between the ROP variable and various features, including depth, lag depth, WHO, RPM TURBINO, torque, SPP, flow in, Mw in, Mw out, PIT#1 to PIT#6, TOT ACT, steel volume, flow paddle, bit position, hook position, string weight, and drag. The correlation coefficients are presented in Table 3.\n",
      "\n",
      "**Feature Selection**\n",
      "\n",
      "The article discusses the importance of feature selection in machine learning model development. Feature selection is the process of selecting a subset of relevant features that have a significant impact on prediction. The article mentions three main categories of feature selection algorithms: filter, wrapper, and embedded methods. In this study, a filter method known as mutual information is used to select optimal features for model building. Mutual information is a statistical measure of the mutual dependence between two variables, and it is calculated using the formula:\n",
      "\n",
      "I(X;Y) = ∑∑(p(x,y) \\* log(p(x,y) / (p(x) \\* p(y))))\n",
      "\n",
      "where I is the ranking score, X and Y are the input and output variables, and p(x,y) is the joint probability distribution of X and Y.\n",
      "\n",
      "Overall, the article aims to develop a machine learning model to predict the ROP variable using a subset of relevant features selected through the mutual information algorithm.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "**Introduction to Machine Learning Model Development**\n",
      "\n",
      "The study focuses on developing machine learning models to predict the rate of penetration for oil wells. The algorithm used selects the top 50th percentile of features, resulting in 13 features out of 27, including depth, lag depth, WOB, SPP, MW IN, PIT#2, PIT#3, PIT#4, PIT#6, TOT ACT, steel volume, bit position, and hunk position.\n",
      "\n",
      "**Data Splitting and Cross-Validation**\n",
      "\n",
      "The data is split into training and testing sets using a 60:40 ratio, resulting in 10,368 rows and 13 columns in the training set and 6,912 rows and 13 columns in the test set. The K-fold cross-validation technique is implemented using the Python Sklearn package to assess the model's performance on unseen data.\n",
      "\n",
      "**Model Development and Training**\n",
      "\n",
      "Seven machine learning techniques are analyzed, including Random Forest Regression. Random Forest is an ensemble learning technique that creates multiple decision trees during training and uses averaging to improve prediction accuracy and control over-fitting. The algorithm combines individual decision tree predictions to provide a final prediction.\n",
      "\n",
      "**Random Forest Regression**\n",
      "\n",
      "Random Forest works by training multiple decision trees in parallel using a bagging technique to obtain a robust model. The algorithm has hyperparameters, such as max_depth, max_features, min_samples_leaf, min_samples_split, and n_estimators, which must be optimized to achieve optimal performance. The study aims to select optimal values for these hyperparameters to obtain the best results.\n",
      "\n",
      "**Technical Terms**\n",
      "\n",
      "* **Dependent and target variables**: output nodes x and y\n",
      "* **Feature selection**: selecting the top 50th percentile of features\n",
      "* **Data splitting**: partitioning data into training and testing sets\n",
      "* **Cross-validation**: assessing model performance on unseen data using techniques such as K-fold\n",
      "* **Random Forest Regression**: an ensemble learning technique using multiple decision trees\n",
      "* **Hyperparameters**: parameters in the algorithm that are constant throughout training, such as max_depth and n_estimators\n",
      "* **Bagging technique**: combining multiple decision trees to obtain a robust model\n",
      "* **Decision tree regression**: a schematic representation of the decision-making process in a decision tree.\n",
      "\n",
      "The text discusses the optimization of hyperparameters for three machine learning algorithms: Random Forest, Linear Regression, and K-Nearest Neighbor (KNN). \n",
      "\n",
      "1. **Random Forest**: To achieve optimal performance, hyperparameters such as `max_depth`, `max_features`, `min_samples_leaf`, `min_samples_split`, and `n_estimators` need to be tuned. Using a **randomized search algorithm**, the optimal values for these hyperparameters were found to be `max_depth = 31`, `max_features = sqrt`, `min_samples_leaf = 3`, `min_samples_split = 13`, and `n_estimators = 666`.\n",
      "\n",
      "2. **Linear Regression**: This supervised learning method assumes a linear relationship between input variables and the target variable. It aims to establish the optimal line that minimizes the difference between predicted and actual values. Key hyperparameters include `copy_X` and `fit_Intercept`. After applying the **randomized search algorithm**, the optimal values were determined as `copy_X = True` and `fit_Intercept = True`.\n",
      "\n",
      "3. **K-Nearest Neighbor (KNN)**: KNN is a non-parametric algorithm that can be used for both classification and regression. It operates on the principle that similar instances will have similar labels. The algorithm identifies the `K` closest neighbors based on a distance metric (often **Euclidean**) and assigns the label based on the majority of these neighbors. For regression, it predicts the target value as the weighted average of the `K` nearest neighbors. Key hyperparameters in KNN include `algorithm`, `leaf_size`, `p`, `weights`, and `n_neighbours`.\n",
      "\n",
      "In all cases, the **randomized search algorithm** was utilized to find the optimal hyperparameter values for each model, which is crucial for achieving the best performance in machine learning tasks. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The study explores various machine learning algorithms and techniques for implementing well data analysis. The algorithms used include:\n",
      "\n",
      "1. **K-Nearest Neighbor (KNN)**: A supervised learning algorithm that uses the optimal hyperparameters of `algorithm=auto`, `leaf_size=10`, `p=1`, `weights=distance`, and `n_neighbours=3`.\n",
      "2. **Support Vector Machine (SVM) Regression**: A supervised learning algorithm that generates a high-dimensional hyperplane to identify the relationship between input and target variables. The optimal hyperparameters used are `C=10`, `epsilon=1`, and `kernel=rbf`.\n",
      "3. **Stacking Technique**: A machine learning technique that combines the predictive power of different algorithms, including **Decision Trees**, **Random Forests**, **Support Vector Machines**, and **Linear Regression**, to make better predictions.\n",
      "4. **Voting Technique**: An ensemble voting technique that integrates predictions from multiple independent models, including **Random Forests**, **Support Vector Machines**, **Linear Regression**, and **Nearest Neighbors**, to form a final prediction.\n",
      "5. **Convolutional Neural Network (CNN)**: A deep learning algorithm commonly used for image classification, object recognition, and image segmentation.\n",
      "\n",
      "The study also mentions the use of **Randomized Search Algorithm** to optimize the hyperparameters of the base models, including **KNN** and **SVM Regression**. The **Meta Model** used in the study is **Linear Regression**.\n",
      "\n",
      "Key technical terms used in the study include:\n",
      "\n",
      "* **Hyperparameters**: Parameters that are set before training a model, such as `C`, `epsilon`, and `kernel` in SVM Regression.\n",
      "* **Base Models**: Machine learning algorithms used as the foundation for stacking and voting techniques, such as **Decision Trees**, **Random Forests**, and **Support Vector Machines**.\n",
      "* **Meta Model**: A model that combines the predictions of multiple base models, such as **Linear Regression**.\n",
      "* **Ensemble Voting**: A technique that integrates predictions from multiple independent models to form a final prediction.\n",
      "* **Deep Learning**: A type of machine learning that uses neural networks with multiple layers, such as **Convolutional Neural Networks (CNNs)**.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The text discusses the application and architecture of Convolutional Neural Networks (CNNs) in the interpretation of visual data, including images and videos. CNNs are commonly used for image classification, object recognition, and image segmentation, but can also be utilized for regression-based projects to predict continuous variables. A typical CNN architecture consists of four components: \n",
      "\n",
      "1. **Convolutional layers**: \n",
      "2. **Pooling layers**: \n",
      "3. **Fully connected layers**: \n",
      "4. **Output layers**.\n",
      "\n",
      "The key difference between a standard CNN and a regression-based CNN lies in the **output layer** and **loss function**. In a regression-based CNN, the output layer is composed of a single neuron with a distinct function, unlike the **Softmax-based** output layer used in standard CNNs for predicting class probabilities. This distinction allows regression-based CNNs to predict continuous variables instead of class labels.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The study focuses on developing machine learning models for regression tasks, specifically using a linear activation function to produce continuous values. The performance of the models is evaluated using various metrics, including Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Coefficient of Determination (R-squared). These metrics are calculated using equations (9) to (12), where ŷ, y, and ȳ represent predicted, actual, and mean values, respectively.\n",
      "\n",
      "The study uses a dataset with 27 columns, which is reduced to 13 columns after feature selection, resulting in 17,280 rows. The data is then split into training and testing sets using cross-validation, with 10,368 rows and 6,912 rows, respectively. The models used include Linear Regression, Random Forest Regression, K-Nearest Neighbor, Support Vector Regression (SVR), Stacking, Voting, and Convolutional Neural Network (CNN).\n",
      "\n",
      "The CNN model architecture consists of two 1-D convolutional layers with 32 and 64 filters, kernel size of two, one Global MaxPooling Layer, five hidden layers, and one output layer. The training and testing data are standardized to have a mean of 0 and standard deviation of 1. The results of the models are presented in tables 5-11, with error metrics calculated for each model.\n",
      "\n",
      "The technical terms used in the study include:\n",
      "\n",
      "* Linear activation function\n",
      "* Regression tasks\n",
      "* Loss function\n",
      "* MSE (Mean Squared Error)\n",
      "* MAE (Mean Absolute Error)\n",
      "* RMSE (Root Mean Squared Error)\n",
      "* R-squared (Coefficient of Determination)\n",
      "* Cross-validation\n",
      "* Hyperparameters\n",
      "* Randomized search cv algorithm\n",
      "* Stacking and Voting techniques\n",
      "* Convolutional Neural Network (CNN)\n",
      "* 1-D convolutional layers\n",
      "* Filters\n",
      "* Kernel size\n",
      "* Global MaxPooling Layer\n",
      "* Hidden layers\n",
      "* Output layer\n",
      "* Standardization (mean = 0, standard deviation = 1)\n",
      "\n",
      "Overall, the study aims to evaluate the performance of different machine learning models on a dataset, using various metrics and techniques to optimize the results.\n",
      "\n",
      "The provided text discusses the results of three machine learning (ML) models: Linear Regression, Random Forest, and K-Nearest Neighbor. The models were trained and tested using well data samples (Table 4). The performance of each model is evaluated using various error metrics, including:\n",
      "\n",
      "1. **Root Mean Squared Error (RMSE)**: measures the difference between predicted and actual values.\n",
      "2. **Mean Squared Error (MSE)**: measures the average squared difference between predicted and actual values.\n",
      "3. **Mean Absolute Error (MAE)**: measures the average absolute difference between predicted and actual values.\n",
      "4. **R-Squared (R² or 2R) Score**: measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\n",
      "\n",
      "The results are presented in three tables:\n",
      "\n",
      "* **Table 5: Linear Regression model results**: shows an RMSE of 2.611 (training) and 2.565 (test), MSE of 6.819 (training) and 6.582 (test), MAE of 1.773 (training) and 1.744 (test), and an R² score of 0.639 for both training and test data.\n",
      "* **Table 6: Random Forest model results**: shows an RMSE of 0.469 (training) and 0.676 (test), MSE of 0.220 (training) and 0.458 (test), MAE of 0.207 (training) and 0.300 (test), and an R² score of 0.988 (training) and 0.975 (test).\n",
      "* **Table 7: K-Nearest Neighbor model results**: is incomplete, but it is expected to show similar error metrics and evaluation scores.\n",
      "\n",
      "Overall, the Random Forest model appears to outperform the Linear Regression model, with lower error metrics and higher R² scores, indicating better predictive performance.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "The study compares the performance of various machine learning (ML) models, including Support Vector Machine (SVM), Stacking technique, Voting technique, Convolutional Neural Network (CNN), Random Forest, K-Nearest Neighbor (KNN), and Linear Regression, in predicting the rate of penetration during drilling. The models were evaluated using error metrics such as Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and R-Squared (2R) score.\n",
      "\n",
      "The results show that the Stacking technique outperformed all other models for both training and testing data. For training data, the Stacking technique had an RMSE of 0.306 and an MAE of 0.094, which was 35% and 55% better than the Random Forest model, respectively. For testing data, the Stacking technique had an RMSE of 0.548 and an MAE of 0.300, which was 19% and 47% better than the Random Forest model, respectively.\n",
      "\n",
      "The study also found that the CNN model, which is a complex ML model, performed better than traditional ML models such as Linear Regression and Support Vector Regression (SVR). However, the Stacking technique, which is an ensemble method, outperformed all other models, including CNN.\n",
      "\n",
      "The results suggest that complex ML models, such as Stacking and CNN, can perform better than traditional ML models, but traditional models can still perform well with proper feature engineering and hyperparameter tuning. The study concludes that the choice of ML model depends on the specific problem and dataset, and that a comparative analysis of different models is necessary to determine the best approach.\n",
      "\n",
      "Key technical terms used in the summary include:\n",
      "\n",
      "* Machine Learning (ML)\n",
      "* Support Vector Machine (SVM)\n",
      "* Stacking technique\n",
      "* Voting technique\n",
      "* Convolutional Neural Network (CNN)\n",
      "* Random Forest\n",
      "* K-Nearest Neighbor (KNN)\n",
      "* Linear Regression\n",
      "* Root Mean Square Error (RMSE)\n",
      "* Mean Square Error (MSE)\n",
      "* Mean Absolute Error (MAE)\n",
      "* R-Squared (2R) score\n",
      "* Ensemble method\n",
      "* Feature engineering\n",
      "* Hyperparameter tuning.\n",
      "\n",
      "Here is a concise and detailed summary of the text, capturing the technical terms:\n",
      "\n",
      "This study conducted a comparative analysis of seven machine learning algorithms to predict the rate of penetration during drilling using data from the Daily Drilling Report (DDR) of an oil well, comprising 17,280 rows and 27 columns. The data was preprocessed using techniques such as outlier handling, variable transformation, and feature scaling. The study employed various machine learning models, including Random Forest, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Linear Regression, Convolutional Neural Network (CNN), stacking, and voting techniques. The results showed that the stacking algorithm, which combined the predictive power of each base model, outperformed the other models, while the voting technique performed well but not as well as the stacking technique. Among the base models, Random Forest and KNN were robust, performing well on both train and test data, whereas SVM and Linear Regression models showed high errors but demonstrated generalization capability and low tendency to overfit. The CNN model also performed well on regression-based tasks, such as rate of penetration predictions, on both train and test data. Overall, the study highlights the effectiveness of ensemble techniques, such as stacking, in improving predictive power and the robustness of certain base models, such as Random Forest and KNN, in predicting rate of penetration during drilling.\n",
      "\n",
      "The provided text appears to be a list of references for a research article related to petroleum engineering, specifically focusing on the prediction of rate of penetration (ROP) in drilling operations. The references include a range of technical papers and articles from various journals and conferences, including the Journal of Petroleum Science and Engineering, Society of Petroleum Engineers (SPE), and Nature.\n",
      "\n",
      "The references cover various topics, including:\n",
      "\n",
      "1. Artificial neural networks (ANN) and deep learning (DL) models for predicting ROP, such as those presented in references [1], [5], [8], and [19].\n",
      "2. The effects of weight material type and mud formulation on penetration rate, as discussed in reference [2].\n",
      "3. Multiple regression approaches to optimal drilling and abnormal pressure detection, as presented in reference [3].\n",
      "4. Rock drillability and interpretive methods, as discussed in references [4] and [18].\n",
      "5. Real-time prediction of rheological parameters of drilling fluids using ANN, as presented in reference [5].\n",
      "6. Estimation of oil recovery factor for water drive sandy reservoirs using artificial intelligence, as discussed in reference [6].\n",
      "7. Comparative analysis of ANN and support vector machine (SVM) models for predicting petroleum reservoir properties, as presented in reference [9].\n",
      "8. Optimization of drilling parameters and ROP prediction using intelligent systems, as discussed in references [11], [12], and [14].\n",
      "\n",
      "Technical terms and concepts mentioned in the references include:\n",
      "\n",
      "* Rate of penetration (ROP)\n",
      "* Artificial neural networks (ANN)\n",
      "* Deep learning (DL)\n",
      "* Support vector machine (SVM)\n",
      "* Multiple regression\n",
      "* Rock drillability\n",
      "* Rheological parameters\n",
      "* Drilling fluids\n",
      "* Oil recovery factor\n",
      "* Petroleum reservoir properties\n",
      "* Drilling parameters\n",
      "* Intelligent systems\n",
      "\n",
      "Overall, the references suggest that the research article is focused on developing and applying advanced machine learning and artificial intelligence techniques to improve the accuracy and efficiency of ROP prediction in drilling operations. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "The provided texts are a collection of research papers and conference presentations related to the prediction and optimization of the Rate of Penetration (ROP) in drilling operations. The ROP is a critical parameter in drilling, as it affects the efficiency and cost of drilling operations. The papers employ various techniques, including:\n",
      "\n",
      "1. **Artificial Neural Networks (ANNs)**: Many papers utilize ANNs to predict ROP, including Zhang et al. (2018), Abdulmalek et al. (2019), Ashrafi et al. (2019), and Abbas et al. (2019). ANNs are used to model the complex relationships between drilling parameters and ROP.\n",
      "2. **Hybrid Models**: Some papers propose hybrid models, combining ANNs with other techniques, such as **Convolutional Neural Networks (CNNs)** (Burgos et al., 2019) and **Stacked Generalization Ensemble Models** (Liu et al., 2021).\n",
      "3. **Response Surface Methodology (RSM)**: Moraveji et al. (2016) use RSM to optimize and predict ROP.\n",
      "4. **Bat Algorithm**: Moraveji et al. (2016) also employ the Bat Algorithm to optimize ROP.\n",
      "5. **Self-Adaptive Artificial Neural Networks**: Al-AbdulJabbar et al. (2020) use self-adaptive ANNs to predict ROP.\n",
      "6. **Hybrid Ensemble Learning**: Wang et al. (2020) propose a hybrid ensemble learning approach for ROP prediction.\n",
      "7. **Drag-Bit Model**: Hareland et al. (1994) develop a drag-bit model, including wear, to optimize ROP.\n",
      "\n",
      "The papers also discuss various drilling parameters, including:\n",
      "\n",
      "1. **In-situ Stress Bounds**: Hareland et al. (1993) use drilling parameters to predict in-situ stress bounds.\n",
      "2. **Drilling Parameters**: Iqbal (2008) uses real-time drilling parameters to optimize drilling operations.\n",
      "3. **Geothermal Drilling Parameters**: Miyora (2014) models and optimizes geothermal drilling parameters.\n",
      "\n",
      "The research covers various types of drilling operations, including:\n",
      "\n",
      "1. **Deep Shale Formation**: Abdulmalek et al. (2019) and Zhang et al. (2018) focus on deep shale formation drilling.\n",
      "2. **Horizontal Carbonate Reservoirs**: Al-AbdulJabbar et al. (2020) predict ROP in horizontal carbonate reservoirs.\n",
      "3. **High-Angled Wells**: Abbas et al. (2019) predict ROP in high-angled wells.\n",
      "4. **Paleozoic Shale Drilling**: Burgos et al. (2019) use CNNs to predict ROP in Paleozoic shale drilling.\n",
      "5. **Gas Well Drilling**: Liu et al. (2021) propose a stacked generalization ensemble model for gas well ROP prediction.\n",
      "\n",
      "Overall, the research aims to improve the accuracy and efficiency of ROP prediction, which is crucial for optimizing drilling operations and reducing costs in the oil and gas industry.\n",
      "\n",
      "The provided text appears to be a reference list for a technical paper or project, focusing on drilling engineering and machine learning applications. The key technical terms and concepts mentioned include:\n",
      "\n",
      "1. **Applied Drilling Engineering**: A textbook series by the Society of Petroleum Engineers (SPE) that covers various aspects of drilling engineering.\n",
      "2. **Decision Trees**: A machine learning technique used for classification and regression tasks, as discussed in the papers by Quinlan (1986) and SametGirgin (2019).\n",
      "3. **Machine Learning**: A subset of artificial intelligence that involves training algorithms to make predictions or decisions based on data, as overviewed by Pandey et al. (2020).\n",
      "4. **Deep Learning**: A type of machine learning that uses neural networks to analyze data, also discussed by Pandey et al. (2020).\n",
      "5. **Random Forest Algorithm**: An ensemble learning method that combines multiple decision trees to improve prediction accuracy.\n",
      "6. **Linear Regression Algorithm**: A statistical method used to model the relationship between a dependent variable and one or more independent variables.\n",
      "7. **K-Nearest Neighbour Algorithm**: A supervised learning technique that classifies new data points based on their similarity to existing data points.\n",
      "\n",
      "The text also mentions various sources, including academic papers, online tutorials (e.g., GeeksForGeeks, PursuitData), and textbooks, indicating a comprehensive review of drilling engineering and machine learning concepts. The appendix section suggests that the work employs multiple algorithms, including Random Forest, Linear Regression, and K-Nearest Neighbour, to achieve its objectives.\n",
      "\n",
      "The text references a research study by Olafadehan OA et al., published in the Journal of Petrochemical Engineering (J Petro Chem Eng), Volume 1, Issue 1. The study appears to focus on machine learning techniques, specifically mentioning three algorithms: \n",
      "\n",
      "1. **SVR Algorithm**: Support Vector Regression (SVR) algorithm, a type of supervised learning method used for regression tasks, which aims to find a hyperplane that minimizes the error between predicted and actual values.\n",
      "\n",
      "2. **Stacking Algorithm**: a meta-learning technique that combines the predictions of multiple base models to produce a single, more accurate prediction, often using a meta-model to make the final prediction.\n",
      "\n",
      "3. **Voting Algorithm**: also known as ensemble voting, this technique involves combining the predictions of multiple models, where each model's prediction is given a vote, and the final prediction is determined by the class with the most votes.\n",
      "\n",
      "These algorithms are likely applied to a problem in the field of petrochemical engineering, possibly related to prediction, classification, or regression tasks.\n",
      "\n",
      "Based on the provided text, here is a concise and detailed summary:\n",
      "\n",
      "The text appears to be referencing a research article or publication titled \"J Petro Chem Eng\" with a specific volume (Vol: 1) and issue (Iss:1) authored by Olafadehan OA, et al. The article is associated with a CNN (Convolutional Neural Network) algorithm code, which is a type of deep learning technique used for image and signal processing. The mention of \"CNN Algorithm Code\" suggests that the article may be focusing on the development, implementation, or application of Convolutional Neural Networks in the field of Petrochemical Engineering. \n",
      "\n",
      "Key technical terms captured include:\n",
      "- CNN: Convolutional Neural Network\n",
      "- Algorithm Code: a set of instructions used to implement the CNN\n",
      "- Petrochemical Engineering: the field of study related to the processing and production of petrochemicals. \n",
      "\n",
      "Please note that the provided text is limited, and a more comprehensive summary may require additional context or information. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "**Final Summary:**\n",
      "\n",
      "The document discusses the application of Machine Learning (ML) algorithms in predicting the Rate of Penetration (ROP) during drilling operations in the petroleum industry. The study evaluates the performance of seven ML algorithms, including Support Vector Machine Regression (SVR), Random Forest Regression (RF), Linear Regression (LR), K-Nearest Neighbors (KNN), Stacking technique, Voting technique, and Convolutional Neural Network (CNN). The results show that the Stacking technique has the best performance, with an accuracy of 99.8% and 97.5% on the training and testing data sets, respectively.\n",
      "\n",
      "The study highlights the potential of ML algorithms in optimizing the drilling process and reducing costs. The authors use various technical terms, including Artificial Intelligence (AI), Machine Learning (ML), Artificial Neural Network (ANN), Convolutional Neural Network (CNN), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Coefficient of Determination (R2).\n",
      "\n",
      "The key findings of the study include:\n",
      "\n",
      "1. **ML algorithms can accurately predict ROP**: The study demonstrates the effectiveness of ML algorithms in predicting ROP, with the Stacking technique achieving an accuracy of 99.8% and 97.5% on the training and testing data sets, respectively.\n",
      "2. **Comparison of ML algorithms**: The study compares the performance of seven ML algorithms, including SVR, RF, LR, KNN, Stacking technique, Voting technique, and CNN.\n",
      "3. **Importance of drilling parameters**: The study highlights the importance of drilling parameters, such as weight on bit (WOB), rotary speed (RPM), and mud properties, in predicting ROP.\n",
      "4. **Application of ML in petroleum industry**: The study demonstrates the potential of ML algorithms in optimizing the drilling process and reducing costs in the petroleum industry.\n",
      "\n",
      "The technical terms used in the study include:\n",
      "\n",
      "* Machine Learning (ML)\n",
      "* Artificial Intelligence (AI)\n",
      "* Artificial Neural Network (ANN)\n",
      "* Convolutional Neural Network (CNN)\n",
      "* Support Vector Machine Regression (SVR)\n",
      "* Random Forest Regression (RF)\n",
      "* Linear Regression (LR)\n",
      "* K-Nearest Neighbors (KNN)\n",
      "* Stacking technique\n",
      "* Voting technique\n",
      "* Mean Absolute Error (MAE)\n",
      "* Root Mean Squared Error (RMSE)\n",
      "* Coefficient of Determination (R2)\n",
      "* Rate of Penetration (ROP)\n",
      "* Weight on bit (WOB)\n",
      "* Rotary speed (RPM)\n",
      "* Mud properties\n",
      "\n",
      "Overall, the study demonstrates the potential of ML algorithms in predicting ROP and optimizing the drilling process in the petroleum industry.\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The application of artificial intelligence (AI) techniques, specifically artificial neural networks (ANNs) and deep convolutional neural networks (CNNs), has been explored to predict the rate of penetration (ROP) during drilling operations. The performance of these models has been compared to traditional ROP models, and the results indicate that AI-based models outperform traditional models in terms of accuracy and reliability.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **ANN-ROP model**: Exhibits superior performance over traditional ROP models, with a coefficient of determination (R²) of 0.99 and an average absolute percentage error (AAPE) of 5%.\n",
      "2. **CNN model**: Outperforms other machine learning models, with a mean absolute percentage error (MAPE) of 4%.\n",
      "3. **Optimization of ROP**: Using the Artificial Bee Colony (ABC) algorithm results in an approximate improvement of 20-30% in the rate of penetration.\n",
      "4. **Importance of features**: The most important features for predicting ROP are the weight on bit, rotary speed, and mud flow rate.\n",
      "\n",
      "**Technical Terms:**\n",
      "\n",
      "1. **Artificial Neural Network (ANN)**: A model used to predict ROP.\n",
      "2. **Convolutional Neural Network (CNN)**: A deep learning model used to predict ROP.\n",
      "3. **Coefficient of Determination (R²)**: A statistical measure used to evaluate the performance of the models.\n",
      "4. **Average Absolute Percentage Error (AAPE)**: A measure of the average difference between predicted and actual values.\n",
      "5. **Mean Absolute Percentage Error (MAPE)**: A loss function used to train the CNN model.\n",
      "6. **Artificial Bee Colony (ABC) algorithm**: An optimization algorithm used to optimize ROP.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The application of AI techniques, such as ANNs and CNNs, has shown promising results in predicting ROP during drilling operations. The optimization of ROP using the ABC algorithm has also shown significant improvements. The importance of features such as weight on bit, rotary speed, and mud flow rate has been highlighted. These findings have the potential to contribute to drilling planning and optimization of future wells, reducing non-productive time (NPT) and expenses in the oil and gas industry.\n",
      "\n",
      "**Final Summary:**\n",
      "\n",
      "The document discusses the application of machine learning algorithms to predict the Rate of Penetration (ROP) in drilling operations. The study employs a data-driven approach using Logging While Drilling (LWD) data and artificial intelligence (AI) techniques to overcome the limitations of physics-based approaches, such as the Bourgyone and Young model.\n",
      "\n",
      "The key technical terms in this document include:\n",
      "\n",
      "* **Bourgyone and Young model**: a physics-based approach for estimating ROP\n",
      "* **Logging While Drilling (LWD)**: a technique for collecting data during drilling operations\n",
      "* **Artificial intelligence (AI)**: a technique used for ROP estimation\n",
      "* **Rate of Penetration (ROP)**: a measure of drilling speed\n",
      "* **Daily Drilling Report (DDR)**: a report that contains data on drilling operations\n",
      "* **Data-driven approach**: an approach that uses data to estimate ROP\n",
      "* **Physics-based approach**: an approach that uses physical models to estimate ROP\n",
      "\n",
      "The study uses various data preprocessing techniques, including outlier handling, variable transformation, and feature scaling, to prepare the data for model development. The dataset includes features such as depth, lag depth, weight on bit, pump flow rate, mud weight, mud type, drill bit diameter, and wellbore trajectory.\n",
      "\n",
      "The study applies various machine learning algorithms, including Random Forest Regression, Linear Regression, and K-Nearest Neighbor (KNN), to predict the ROP variable. The optimal hyperparameters for each algorithm are determined using a randomized search algorithm.\n",
      "\n",
      "The key findings of the study include:\n",
      "\n",
      "* The importance of feature selection in machine learning model development\n",
      "* The use of mutual information as a filter method for feature selection\n",
      "* The application of Random Forest Regression, Linear Regression, and K-Nearest Neighbor (KNN) algorithms for ROP prediction\n",
      "* The optimization of hyperparameters for each algorithm using a randomized search algorithm\n",
      "\n",
      "Overall, the study aims to develop a machine learning model to predict the ROP variable using a subset of relevant features selected through the mutual information algorithm. The study demonstrates the potential of machine learning algorithms in predicting ROP and improving drilling operations. \n",
      "\n",
      "**Important Points:**\n",
      "\n",
      "1. **Data-driven approach**: The study uses a data-driven approach to estimate ROP, which overcomes the limitations of physics-based approaches.\n",
      "2. **Machine learning algorithms**: The study applies various machine learning algorithms, including Random Forest Regression, Linear Regression, and K-Nearest Neighbor (KNN), to predict the ROP variable.\n",
      "3. **Feature selection**: The study uses mutual information as a filter method for feature selection, which selects the top 50th percentile of features.\n",
      "4. **Hyperparameter optimization**: The study uses a randomized search algorithm to optimize the hyperparameters for each algorithm.\n",
      "5. **Data preprocessing**: The study uses various data preprocessing techniques, including outlier handling, variable transformation, and feature scaling, to prepare the data for model development. \n",
      "\n",
      "**Technical Terms:**\n",
      "\n",
      "1. **Bourgyone and Young model**\n",
      "2. **Logging While Drilling (LWD)**\n",
      "3. **Artificial intelligence (AI)**\n",
      "4. **Rate of Penetration (ROP)**\n",
      "5. **Daily Drilling Report (DDR)**\n",
      "6. **Data-driven approach**\n",
      "7. **Physics-based approach**\n",
      "8. **Random Forest Regression**\n",
      "9. **Linear Regression**\n",
      "10. **K-Nearest Neighbor (KNN)**\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. **Use of machine learning algorithms**: The study recommends the use of machine learning algorithms, such as Random Forest Regression, Linear Regression, and K-Nearest Neighbor (KNN), for ROP prediction.\n",
      "2. **Feature selection**: The study recommends the use of mutual information as a filter method for feature selection.\n",
      "3. **Hyperparameter optimization**: The study recommends the use of a randomized search algorithm to optimize the hyperparameters for each algorithm.\n",
      "4. **Data preprocessing**: The study recommends the use of various data preprocessing techniques, including outlier handling, variable transformation, and feature scaling, to prepare the data for model development.\n",
      "\n",
      "**Final Summary:**\n",
      "\n",
      "The document discusses the application of various machine learning algorithms and techniques for predicting the rate of penetration (ROP) in drilling operations. The study explores the use of different models, including K-Nearest Neighbor (KNN), Support Vector Machine (SVM) Regression, Stacking technique, Voting technique, Convolutional Neural Network (CNN), Random Forest, and Linear Regression. The results show that the Stacking technique outperformed all other models, followed by Random Forest and KNN.\n",
      "\n",
      "**Key Findings:**\n",
      "\n",
      "1. **Stacking Technique:** The Stacking technique, which combines the predictive power of different algorithms, outperformed all other models.\n",
      "2. **Random Forest and KNN:** Random Forest and KNN were robust and performed well on both train and test data.\n",
      "3. **CNN:** The CNN model performed well on regression-based tasks, such as ROP predictions.\n",
      "4. **Ensemble Techniques:** The study highlights the effectiveness of ensemble techniques, such as Stacking, in improving predictive power.\n",
      "5. **Base Models:** The study found that certain base models, such as Random Forest and KNN, were robust and performed well on both train and test data.\n",
      "\n",
      "**Technical Terms:**\n",
      "\n",
      "1. **Machine Learning (ML):** The study employed various ML models to predict ROP.\n",
      "2. **Artificial Neural Networks (ANN):** ANN and deep learning models were used to predict ROP.\n",
      "3. **Support Vector Machine (SVM):** SVM was used as a base model in the Stacking technique.\n",
      "4. **Convolutional Neural Network (CNN):** CNN was used to predict ROP.\n",
      "5. **Hyperparameters:** The study optimized hyperparameters using Randomized Search Algorithm.\n",
      "6. **Ensemble Voting:** Ensemble voting was used to integrate predictions from multiple independent models.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The study demonstrates the effectiveness of machine learning algorithms and techniques in predicting ROP in drilling operations. The Stacking technique, which combines the predictive power of different algorithms, outperformed all other models. The study highlights the importance of ensemble techniques and the robustness of certain base models, such as Random Forest and KNN, in predicting ROP. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "**Final Summary: Prediction and Optimization of Rate of Penetration (ROP) in Drilling Operations**\n",
      "\n",
      "The research papers and conference presentations focus on predicting and optimizing the Rate of Penetration (ROP) in drilling operations, a critical parameter affecting drilling efficiency and cost. Various techniques are employed, including:\n",
      "\n",
      "* **Artificial Neural Networks (ANNs)**: Utilized by multiple studies to predict ROP, including Zhang et al. (2018), Abdulmalek et al. (2019), and Abbas et al. (2019).\n",
      "* **Hybrid Models**: Combining ANNs with other techniques, such as Convolutional Neural Networks (CNNs) and Stacked Generalization Ensemble Models.\n",
      "* **Response Surface Methodology (RSM)**: Used by Moraveji et al. (2016) to optimize and predict ROP.\n",
      "* **Bat Algorithm**: Employed by Moraveji et al. (2016) to optimize ROP.\n",
      "\n",
      "The research covers various drilling operations, including:\n",
      "\n",
      "* **Deep Shale Formation**: Focused on by Abdulmalek et al. (2019) and Zhang et al. (2018).\n",
      "* **Horizontal Carbonate Reservoirs**: Studied by Al-AbdulJabbar et al. (2020).\n",
      "* **High-Angled Wells**: Investigated by Abbas et al. (2019).\n",
      "* **Paleozoic Shale Drilling**: Examined by Burgos et al. (2019) using CNNs.\n",
      "* **Gas Well Drilling**: Modeled by Liu et al. (2021) using a stacked generalization ensemble model.\n",
      "\n",
      "The key technical terms and concepts include:\n",
      "\n",
      "* **Applied Drilling Engineering**: A textbook series by the Society of Petroleum Engineers (SPE).\n",
      "* **Machine Learning**: A subset of artificial intelligence used for prediction and decision-making.\n",
      "* **Deep Learning**: A type of machine learning using neural networks to analyze data.\n",
      "* **Random Forest Algorithm**: An ensemble learning method combining multiple decision trees.\n",
      "* **Linear Regression Algorithm**: A statistical method modeling the relationship between variables.\n",
      "* **K-Nearest Neighbour Algorithm**: A supervised learning technique classifying new data points based on similarity.\n",
      "\n",
      "The research aims to improve ROP prediction accuracy and efficiency, crucial for optimizing drilling operations and reducing costs in the oil and gas industry. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire write-up with the important points, that are tailored towards the title of the doucment.\n",
      "**Final Summary:**\n",
      "\n",
      "The document discusses the application of Machine Learning (ML) algorithms in predicting the Rate of Penetration (ROP) during drilling operations in the petroleum industry. The study evaluates the performance of various ML algorithms, including Support Vector Machine Regression (SVR), Random Forest Regression (RF), Linear Regression (LR), K-Nearest Neighbors (KNN), Stacking technique, Voting technique, and Convolutional Neural Network (CNN). The key findings of the study include:\n",
      "\n",
      "* **ML algorithms can accurately predict ROP**: The study demonstrates the effectiveness of ML algorithms in predicting ROP, with the Stacking technique achieving an accuracy of 99.8% and 97.5% on the training and testing data sets, respectively.\n",
      "* **Comparison of ML algorithms**: The study compares the performance of various ML algorithms, including SVR, RF, LR, KNN, Stacking technique, Voting technique, and CNN.\n",
      "* **Importance of drilling parameters**: The study highlights the importance of drilling parameters, such as weight on bit (WOB), rotary speed (RPM), and mud properties, in predicting ROP.\n",
      "* **Application of ML in petroleum industry**: The study demonstrates the potential of ML algorithms in optimizing the drilling process and reducing costs in the petroleum industry.\n",
      "\n",
      "**Important Points:**\n",
      "\n",
      "1. **Data-driven approach**: The study uses a data-driven approach to estimate ROP, which overcomes the limitations of physics-based approaches.\n",
      "2. **Machine learning algorithms**: The study applies various machine learning algorithms to predict the ROP variable.\n",
      "3. **Feature selection**: The study uses mutual information as a filter method for feature selection.\n",
      "4. **Hyperparameter optimization**: The study uses a randomized search algorithm to optimize the hyperparameters for each algorithm.\n",
      "5. **Data preprocessing**: The study uses various data preprocessing techniques to prepare the data for model development.\n",
      "\n",
      "**Technical Terms:**\n",
      "\n",
      "1. **Machine Learning (ML)**\n",
      "2. **Artificial Neural Network (ANN)**\n",
      "3. **Convolutional Neural Network (CNN)**\n",
      "4. **Support Vector Machine Regression (SVR)**\n",
      "5. **Random Forest Regression (RF)**\n",
      "6. **Linear Regression (LR)**\n",
      "7. **K-Nearest Neighbors (KNN)**\n",
      "8. **Stacking technique**\n",
      "9. **Voting technique**\n",
      "10. **Rate of Penetration (ROP)**\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. **Use of machine learning algorithms**: The study recommends the use of machine learning algorithms for ROP prediction.\n",
      "2. **Feature selection**: The study recommends the use of mutual information as a filter method for feature selection.\n",
      "3. **Hyperparameter optimization**: The study recommends the use of a randomized search algorithm to optimize the hyperparameters for each algorithm.\n",
      "4. **Data preprocessing**: The study recommends the use of various data preprocessing techniques to prepare the data for model development.\n",
      "\n",
      "The study demonstrates the potential of machine learning algorithms in predicting ROP and optimizing the drilling process in the petroleum industry. The use of machine learning algorithms can help reduce costs and improve the efficiency of drilling operations.\n",
      "\n",
      "**Final Summary: Prediction and Optimization of Rate of Penetration (ROP) in Drilling Operations**\n",
      "\n",
      "This research summary focuses on predicting and optimizing the Rate of Penetration (ROP) in drilling operations, a critical parameter in drilling efficiency and cost. The key findings and important points are:\n",
      "\n",
      "* **Techniques used**: Artificial Neural Networks (ANNs), Hybrid Models, Response Surface Methodology (RSM), and Bat Algorithm are employed to predict and optimize ROP.\n",
      "* **Drilling operations covered**: Research includes deep shale formation, horizontal carbonate reservoirs, high-angled wells, Paleozoic shale drilling, and gas well drilling.\n",
      "* **Key technical terms and concepts**: Applied Drilling Engineering, Machine Learning, Deep Learning, Random Forest Algorithm, Linear Regression Algorithm, and K-Nearest Neighbour Algorithm are used to improve ROP prediction accuracy and efficiency.\n",
      "* **Research goal**: To optimize drilling operations and reduce costs in the oil and gas industry by improving ROP prediction accuracy and efficiency.\n",
      "\n",
      "Overall, this research aims to provide a comprehensive understanding of ROP prediction and optimization techniques, covering various drilling operations and employing advanced machine learning and deep learning methods to improve drilling efficiency and reduce costs. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = chain.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Final Summary: Prediction and Optimization of Rate of Penetration (ROP) in Drilling Operations**\n",
      "\n",
      "This research summary provides an overview of the application of Machine Learning (ML) algorithms in predicting the Rate of Penetration (ROP) during drilling operations in the petroleum industry. The key findings and important points are:\n",
      "\n",
      "* **ML algorithms can accurately predict ROP**: The study demonstrates the effectiveness of ML algorithms, such as Support Vector Machine Regression (SVR), Random Forest Regression (RF), Linear Regression (LR), K-Nearest Neighbors (KNN), Stacking technique, Voting technique, and Convolutional Neural Network (CNN), in predicting ROP with high accuracy.\n",
      "* **Importance of drilling parameters**: The study highlights the importance of drilling parameters, such as weight on bit (WOB), rotary speed (RPM), and mud properties, in predicting ROP.\n",
      "* **Data-driven approach**: The study uses a data-driven approach to estimate ROP, which overcomes the limitations of physics-based approaches.\n",
      "* **Optimization of drilling operations**: The study demonstrates the potential of ML algorithms in optimizing the drilling process and reducing costs in the petroleum industry.\n",
      "\n",
      "The research recommends the use of ML algorithms, feature selection using mutual information, hyperparameter optimization using a randomized search algorithm, and data preprocessing techniques to prepare the data for model development. The study aims to provide a comprehensive understanding of ROP prediction and optimization techniques, covering various drilling operations and employing advanced machine learning and deep learning methods to improve drilling efficiency and reduce costs.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "1. ML algorithms can accurately predict ROP with high accuracy.\n",
      "2. Drilling parameters, such as WOB, RPM, and mud properties, are important in predicting ROP.\n",
      "3. A data-driven approach can overcome the limitations of physics-based approaches.\n",
      "4. ML algorithms can optimize drilling operations and reduce costs in the petroleum industry.\n",
      "5. Feature selection, hyperparameter optimization, and data preprocessing are crucial in developing accurate ML models.\n",
      "\n",
      "**Technical Terms:**\n",
      "\n",
      "1. Machine Learning (ML)\n",
      "2. Artificial Neural Network (ANN)\n",
      "3. Convolutional Neural Network (CNN)\n",
      "4. Support Vector Machine Regression (SVR)\n",
      "5. Random Forest Regression (RF)\n",
      "6. Linear Regression (LR)\n",
      "7. K-Nearest Neighbors (KNN)\n",
      "8. Stacking technique\n",
      "9. Voting technique\n",
      "10. Rate of Penetration (ROP)\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. Use ML algorithms for ROP prediction.\n",
      "2. Use mutual information for feature selection.\n",
      "3. Use a randomized search algorithm for hyperparameter optimization.\n",
      "4. Use data preprocessing techniques to prepare the data for model development.\n",
      "5. Apply ML algorithms to optimize drilling operations and reduce costs in the petroleum industry.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
